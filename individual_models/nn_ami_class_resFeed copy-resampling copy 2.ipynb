{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'ml-workshop (Python 3.9.15)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOSPC: no space left on device, write"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "print('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/nn_model_script_emb_test.py - starting')\n",
    "\n",
    "from array import array\n",
    "from cmath import nan\n",
    "from pyexpat import model\n",
    "import statistics\n",
    "from tkinter.ttk import Separator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# from torchviz import make_dot\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import variable\n",
    "from itertools import chain\n",
    "from sklearn import metrics as met\n",
    "import pickle\n",
    "from icecream import ic\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from importlib import reload\n",
    "# import util\n",
    "# import model_torch_simple\n",
    "# from torchmetrics import Accuracy\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from icecream import ic\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#%%\n",
    "seed = 42\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(seed)\n",
    "# torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# train_data = np.loadtxt('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_emb/aa_data_train_gene.csv', delimiter = ',')\n",
    "# train_target = pd.read_csv('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_emb/mic_aa_train_hml.csv')\n",
    "# train_target = train_target[['EMB_MIC']]\n",
    "# # don't touch test data, split out validation data from training data during training\n",
    "# # test_data = np.loadtxt('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_EMB/aa_data_test_pca4k.csv', delimiter = ',')\n",
    "# test_data = np.loadtxt('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_emb/aa_data_test_gene.csv', delimiter = ',')\n",
    "# test_target = pd.read_csv('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_emb/mic_aa_test_hml.csv')\n",
    "# test_target = test_target[['EMB_MIC']]\n",
    "\n",
    "# all_data = np.concatenate((train_data, test_data), axis=0)\n",
    "# all_target = pd.concat((train_target, test_target), axis=0)\n",
    "\n",
    "# train_data, test_data, train_target, test_target = train_test_split(all_data, all_target, test_size=0.2, random_state=42, stratify=all_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'ml-workshop (Python 3.9.15)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOSPC: no space left on device, write"
     ]
    }
   ],
   "source": [
    "def data_split(aa_array, encoded_mic):\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Perform stratified train-test split\n",
    "    train_data, test_data, train_target, test_target = train_test_split(\n",
    "        aa_array,\n",
    "        encoded_mic,\n",
    "        test_size=0.1,  # 10% for testing\n",
    "        stratify=encoded_mic.iloc[:,0],  # Ensures the proportion of each class is preserved\n",
    "        random_state=42  # For reproducibility\n",
    "    )\n",
    "    return train_data, test_data, train_target, test_target\n",
    "\n",
    "# def is_within_doubling_dilution(pred, target, target_min, target_max):\n",
    "#     _ = np.arange(target_min-1, target_max+2, 1)\n",
    "#     index = [i for i, x in enumerate(_) if x == target][0]\n",
    "#     return (_[index-1] <= pred <= _[index+1])\n",
    "def is_within_doubling_dilution(pred, target, target_min, target_max):\n",
    "    _ = np.arange(target_min.values-1, target_max.values+2, 1)\n",
    "    index = [i for i, x in enumerate(_) if x == target][0]\n",
    "    return (_[index-1] <= pred <= _[index+1])\n",
    "\n",
    "# def is_within_doubling_dilution(pred, target, target_min, target_max):\n",
    "#     # Convert Series to scalar if needed\n",
    "#     if isinstance(pred, pd.Series):\n",
    "#         pred = pred.iloc[0]  # or pred.item()\n",
    "#     if isinstance(target, pd.Series):\n",
    "#         target = target.iloc[0]  # or target.item()\n",
    "\n",
    "#     _ = np.arange(target_min - 1, target_max + 2, 1)\n",
    "#     # Now target is guaranteed to be a scalar\n",
    "#     index = [i for i, x in enumerate(_) if x == target][0]\n",
    "#     return (_[index - 1] <= pred <= _[index + 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'ml-workshop (Python 3.9.15)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOSPC: no space left on device, write"
     ]
    }
   ],
   "source": [
    "def data_prep_(cryptic, gene_list):\n",
    "    # overlap = set(variants['sample_id']).intersection(set(cryptic['ENA_RUN'].to_list()))\n",
    "    # variants = variants[variants['drugs'].isin(['ethambutol'])]\n",
    "    # variants = variants[variants['sample_id'].isin(overlap)]\n",
    "    # variants['SNP'] = variants['gene'] + '-'+ variants['change']\n",
    "    \n",
    "    variants = pd.read_csv('../variants_full.csv')\n",
    "    variants = variants[variants['gene'] != 'PPE35']\n",
    "    variants = variants[variants['type'] != 'synonymous_variant']\n",
    "    variants = variants[variants['type'] != 'non_coding_transcript_exon_variant']\n",
    "\n",
    "    overlap = set(variants['sample_id']).intersection(set(cryptic['ENA_RUN'].to_list()))\n",
    "    # variants = variants[variants['drugs'].isin(['ethambutol'])]\n",
    "    variants = variants[variants['gene'].isin(gene_list)]\n",
    "    variants = variants[variants['sample_id'].isin(overlap)]\n",
    "    variants['SNP'] = variants['gene'] + '-'+ variants['change']\n",
    "    # print(variants.shape)\n",
    "    # print(variants['sample_id'].unique().shape)\n",
    "\n",
    "    def compare_snp_lists_with_values_optimized(set_list, query_list, values_list):\n",
    "        # Create a dictionary from query_list and values_list for direct mapping\n",
    "        query_dict = dict(zip(query_list, values_list))\n",
    "        \n",
    "        # Use list comprehension to build the output list directly\n",
    "        output_list = [query_dict.get(snp, 0) for snp in set_list]\n",
    "        \n",
    "        return output_list\n",
    "\n",
    "    # Example usage\n",
    "    # set_list = ['SNP1', 'SNP2', 'SNP3', 'SNP4']\n",
    "    # query_list = ['SNP2', 'SNP4']\n",
    "    # values_list = [5, 10]  # Corresponding values for 'SNP2' and 'SNP4'\n",
    "    # output_list = compare_snp_lists_with_values_optimized(set_list, query_list, values_list)\n",
    "    # print(output_list)  # Expected output: [0, 5, 0, 10]# Getting all snp data\n",
    "\n",
    "    aa = []\n",
    "    all_snp = variants['SNP'].unique() # here is a list of all snps values title for the row in the final table \n",
    "    print('Getting all snp data', len(all_snp))\n",
    "    for x in tqdm(overlap):\n",
    "    # for x in tqdm(variants['sample_id'].unique()):\n",
    "        if x in variants['sample_id'].tolist():\n",
    "            aa.append(compare_snp_lists_with_values_optimized(all_snp, variants[variants['sample_id']==x]['SNP'].to_list(), variants[variants['sample_id']==x]['freq'].to_list()))\n",
    "        else:\n",
    "            aa.append([0]*len(all_snp))\n",
    "        # print('SNP')\n",
    "        \n",
    "    aa_array = np.array(aa)\n",
    "    aa_array[aa_array < 0.8] = 0\n",
    "    aa_array[aa_array >= 0.8] = 1\n",
    "\n",
    "    mic_aa = cryptic[cryptic['ENA_RUN'].isin(overlap)]#.iloc[:,14:27]\n",
    "    # mic_aa = cryptic[cryptic['ENA_RUN'].isin(variants['sample_id'].unique())]#.iloc[:,14:27]\n",
    "    # print(mic_aa.shape)\n",
    "    # mic_aa['wgs_id'] = pd.Categorical(mic_aa['ENA_RUN'], categories=variants['sample_id'].unique().tolist(), ordered=True)\n",
    "    # mic_aa = mic_aa.sort_values('ENA_RUN')\n",
    "    mic_aa.ENA_RUN = mic_aa.ENA_RUN.astype('category')\n",
    "    mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(overlap)\n",
    "    # mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(variants['sample_id'].unique().tolist())\n",
    "    mic_aa = mic_aa.sort_values([\"ENA_RUN\"])  ## 'sort' changed to 'sort_values'\n",
    "    # print(mic_aa.shape)\n",
    "\n",
    "    return aa_array, mic_aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'ml-workshop (Python 3.9.15)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOSPC: no space left on device, write"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "drug = 'AMI'\n",
    "cutoff = 1  # this the cutoff for \n",
    "cutoff_mic = 2\n",
    "df = pd.read_csv('../CRyPTIC_reuse_table_20231208.csv')\n",
    "\n",
    "aa_array = np.load(f'./generated_data18122024/all_sample_snps_cryptic_{drug}.npy')\n",
    "drs = np.load(f'./generated_data18122024/all_sample_drs_cryptic_{drug}.npy')\n",
    "tbp = np.load(f'/mnt/storageG1/lwang/Projects/tb_dr_MIC3/individual_models/generated_data18122024/all_sample_drs_cryptic_{drug}-tbp.npy')\n",
    "\n",
    "encoded_mic = pd.DataFrame(drs, columns=[f'{drug}_MIC'])\n",
    "mic_series = np.log2(encoded_mic)\n",
    "mic_series += 3\n",
    "cutoff += 3\n",
    "# ordinal_encoder = OrdinalEncoder()\n",
    "# encoded_mic['INH_MIC'] = ordinal_encoder.fit_transform(encoded_mic[['INH_MIC']])\n",
    "# mic_series = encoded_mic\n",
    "# sample_ids = mic_aa['ENA_RUN']\n",
    "mic_series_bi = encoded_mic[f'{drug}_MIC'].apply(lambda x: 1 if x >= cutoff_mic else 0)\n",
    "mic_series_all = pd.merge(mic_series, mic_series_bi, left_index=True, right_index=True)\n",
    "# train_data, test_data,  test_target_y, test_target = data_split(aa_array, mic_series_all)\n",
    "mic_series_all['tbp'] = tbp\n",
    "\n",
    "train_data, test_data, train_target, test_target = data_split(aa_array, mic_series_all)\n",
    "\n",
    "target_min, target_max = mic_series.min(), mic_series.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[8753  571]\n",
      " [ 116 1471]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the absolute difference between the two columns\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(mic_series_all[f'{drug}_MIC_y'], mic_series_all['tbp'])\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MXF_MIC_x\n",
      "1.0    3581\n",
      "2.0    2380\n",
      "0.0    1929\n",
      "5.0     522\n",
      "3.0     501\n",
      "6.0     486\n",
      "4.0     420\n",
      "Name: count, dtype: int64\n",
      "Counter({1.0: 3581, 2.0: 3080, 0.0: 3000, 5.0: 2522, 3.0: 2501, 6.0: 2086, 4.0: 2020})\n",
      "(18790,)\n",
      "(18790, 782)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Assuming train_data is your feature array and train_target['EMB_MIC_x'] is your target array\n",
    "X = train_data\n",
    "y = train_target[f'{drug}_MIC_x']\n",
    "print(train_target[f'{drug}_MIC_x'].value_counts())\n",
    "\n",
    "target_counts = {\n",
    "1.0:3581,\n",
    "2.0:3080,\n",
    "0.0:3000,\n",
    "5.0: 2522,\n",
    "3.0: 2501,\n",
    "6.0: 2086,\n",
    "4.0: 2020,\n",
    "}\n",
    "# Initialize the RandomOverSampler\n",
    "ros= RandomOverSampler(sampling_strategy=target_counts, random_state=42)\n",
    "\n",
    "# ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Fit and resample the data\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# Verify the new class distribution\n",
    "from collections import Counter\n",
    "print(Counter(y_resampled))\n",
    "print(y_resampled.shape)\n",
    "print(X_resampled.shape)\n",
    "\n",
    "# train_mic_series_bi = y_resampled.apply(lambda x: 1 if x >= 4 else 0)\n",
    "# train_target = pd.DataFrame({'EMB_MIC_x': y_resampled, 'EMB_MIC_y': train_mic_series_bi})\n",
    "# train_data = X_resampled\n",
    "train_mic_series_bi = y_resampled.apply(lambda x: 1 if x >= cutoff else 0)\n",
    "train_target = pd.DataFrame({f'{drug}_MIC_x': y_resampled, f'{drug}_MIC_y': train_mic_series_bi})\n",
    "train_data = X_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cornloss weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_counts = torch.from_numpy(train_target.values).flatten()\n",
    "# train_target_counts = torch.tensor([0,1,2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 50k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(aa_array)\n",
    "\n",
    "aa_array = np.load(f'./generated_data18122024/all_sample_snps_50k_{drug}.npy')\n",
    "# Read the text file line by line into a list and convert to floats\n",
    "mic_series = np.load(f'./generated_data18122024/all_sample_drs_50k_{drug}.npy')\n",
    "\n",
    "# print(mic_series)\n",
    "mic_series_50k = mic_series\n",
    "\n",
    "aa_array_50k_pos = []\n",
    "mic_series_50k_pos = []\n",
    "for x, a in zip(mic_series_50k, aa_array):\n",
    "    if x == 1:\n",
    "        aa_array_50k_pos.append(a)\n",
    "        mic_series_50k_pos.append(x)\n",
    "aa_array_50k_pos = np.array(aa_array_50k_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Prepare your training and testing data\n",
    "# ------------------------------------------------\n",
    "\n",
    "# Assume you already have:\n",
    "#   train_data, test_data\n",
    "#   train_target, test_target\n",
    "#   aa_array_50k_pos, mic_series_50k_pos \n",
    "#   => as per your code snippet.\n",
    "\n",
    "train_target_y = train_target[f'{drug}_MIC_y'].values\n",
    "test_target_y  = test_target[f'{drug}_MIC_y'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_data, test_data, train_target_y, test_target_y\n",
    "\n",
    "# Optionally concatenate the additional data you mentioned:\n",
    "X_train = np.concatenate((X_train, aa_array_50k_pos), axis=0)\n",
    "y_train = np.concatenate((y_train, mic_series_50k_pos), axis=0)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Define a function for checking doubling dilution \n",
    "# (if needed)\n",
    "# ------------------------------------------------\n",
    "def is_within_doubling_dilution(pred, target, target_min, target_max):\n",
    "    _ = np.arange(target_min-1, target_max+2, 1)\n",
    "    index = [i for i, x in enumerate(_) if x == target][0]\n",
    "    return (_[index-1] <= pred <= _[index+1])\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Set up the XGBoost model & parameter grid\n",
    "# ------------------------------------------------\n",
    "# Create a base model\n",
    "xgb_model = xgb.XGBClassifier(random_state=42)\n",
    "\n",
    "# Define a parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.3], \n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'gamma': [0, 1, 5],\n",
    "    'min_child_weight': [1, 5, 10],\n",
    "    'subsample': [0.5, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.8, 1.0],\n",
    "    # 'reg_alpha': [0, 1, 10],       # optionally add\n",
    "    # 'reg_lambda': [0, 1, 10],     # optionally add\n",
    "}\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Run GridSearchCV\n",
    "# ------------------------------------------------\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',      # You can choose other metrics, e.g., 'roc_auc'\n",
    "    cv=3,                    # 3-fold cross-validation\n",
    "    verbose=2,\n",
    "    n_jobs=-1               # Use all available CPU cores\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model from grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Evaluate on the test set\n",
    "# ------------------------------------------------\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Binarize predictions at cutoff=4 (per your example)\n",
    "cutoff = cutoff\n",
    "test_target_bi = y_test.astype(int)\n",
    "test_predictions_bi = y_pred.astype(int)\n",
    "\n",
    "# Compute AUC\n",
    "auc = roc_auc_score(test_target_bi, test_predictions_bi)\n",
    "print(\"AUC:\", auc)\n",
    "\n",
    "# Compute confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(test_target_bi, test_predictions_bi).ravel()\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(test_target_bi, test_predictions_bi))\n",
    "\n",
    "# Compute sensitivity (recall)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "\n",
    "# Compute specificity\n",
    "specificity = tn / (tn + fp)\n",
    "print(\"Specificity:\", specificity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/storageG1/lwang/miniconda3/envs/ml-workshop/lib/python3.9/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9294871794871795\n",
      "AUC: 0.8909078040000808\n",
      "[[882  51]\n",
      " [ 26 133]]\n",
      "Sensitivity: 0.8364779874213837\n",
      "Specificity: 0.9453376205787781\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_data = np.column_stack((train_data, train_target['EMB_MIC_y'].values))\n",
    "# test_data = np.column_stack((test_data, test_target['EMB_MIC_y'].values))\n",
    "train_target_y = train_target[f'{drug}_MIC_y'].values\n",
    "test_target_y = test_target[f'{drug}_MIC_y'].values\n",
    "\n",
    "def is_within_doubling_dilution(pred, target, target_min, target_max):\n",
    "    _ = np.arange(target_min-1, target_max+2, 1)\n",
    "    index = [i for i, x in enumerate(_) if x == target][0]\n",
    "    return (_[index-1] <= pred <= _[index+1])\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_data, test_data, train_target_y, test_target_y\n",
    "X_test = test_data\n",
    "y_test = test_target[f'{drug}_MIC_y'].values\n",
    "X_train = np.concatenate((X_train, aa_array_50k_pos), axis=0)\n",
    "y_train = np.concatenate((y_train, mic_series_50k_pos), axis=0)\n",
    "# # Create the XGBoost model\n",
    "model_bi = xgb.XGBClassifier(    \n",
    "    max_depth=3,\n",
    "    learning_rate=0.9,\n",
    "    n_estimators=4,\n",
    "    # gamma=0.1,\n",
    "    # min_child_weight=24,\n",
    "    # subsample=0.2,\n",
    "    # colsample_bytree=1,\n",
    "    # reg_alpha=15, reg_lambda=15,\n",
    "    random_state=42 \n",
    "    )\n",
    "# # Create the XGBoost model\n",
    "# model_bi = xgb.XGBClassifier(colsample_bytree= 0.5, gamma= 0.1, learning_rate= 0.01, max_depth= 4, min_child_weight= 1, n_estimators= 200, subsample= 0.8,random_state=42)\n",
    "# model_bi = xgb.XGBClassifier()\n",
    "\n",
    "model_bi.fit(X_train, y_train)\n",
    "\n",
    "# model_bi = pickle.load(open(\"xgb_bi_mix1.pkl\", \"rb\"))\n",
    "# model_bi = pickle.load(open(\"xgb_bi_mix.pkl\", \"rb\"))\n",
    "# model_bi = pickle.load(open(\"xgb_bi_50kbalanced.pkl\", \"rb\"))\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model_bi.predict(X_test)\n",
    "\n",
    "# Evaluate the model_bi\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "#testing\n",
    "cutoff = cutoff\n",
    "test_target_bi = y_test.astype(int) #(target_mic_list  >= cutoff).astype(int)\n",
    "test_predictions_bi = y_pred.astype(int)  #(np.array(pred_mic_list) >= cutoff).astype(int)\n",
    "\n",
    "auc = roc_auc_score(test_target_bi, test_predictions_bi)\n",
    "print(\"AUC:\", auc)\n",
    "\n",
    "# Calculate confusion matrix components\n",
    "tn, fp, fn, tp = confusion_matrix(test_target_bi, test_predictions_bi).ravel()\n",
    "print(confusion_matrix(test_target_bi, test_predictions_bi))\n",
    "# Calculate sensitivity (recall)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print(\"Sensitivity:\", sensitivity)  \n",
    "\n",
    "# Calculate specificity\n",
    "specificity = tn / (tn + fp)\n",
    "print(\"Specificity:\", specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9569041336851363\n",
      "AUC: 0.932873675643259\n",
      "[[775   1]\n",
      " [ 48 313]]\n",
      "Sensitivity: 0.8670360110803325\n",
      "Specificity: 0.9987113402061856\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Define training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_data, test_data, train_target_y, test_target_y\n",
    "X_test = test_data\n",
    "y_test = test_target[f'{drug}_MIC_y'].values\n",
    "X_train = np.concatenate((X_train, aa_array_50k_pos), axis=0)\n",
    "y_train = np.concatenate((y_train, mic_series_50k_pos), axis=0)\n",
    "\n",
    "# Apply RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Create the XGBoost model\n",
    "model_bi = xgb.XGBClassifier(\n",
    "    max_depth=3,\n",
    "    learning_rate=0.9,\n",
    "    n_estimators=4,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model using the resampled dataset\n",
    "model_bi.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model_bi.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Compute AUC\n",
    "cutoff = cutoff\n",
    "test_target_bi = y_test.astype(int)\n",
    "test_predictions_bi = y_pred.astype(int)\n",
    "auc = roc_auc_score(test_target_bi, test_predictions_bi)\n",
    "print(\"AUC:\", auc)\n",
    "\n",
    "# Calculate confusion matrix and performance metrics\n",
    "tn, fp, fn, tp = confusion_matrix(test_target_bi, test_predictions_bi).ravel()\n",
    "print(confusion_matrix(test_target_bi, test_predictions_bi))\n",
    "\n",
    "sensitivity = tp / (tp + fn)  # Recall\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "\n",
    "specificity = tn / (tn + fp)\n",
    "print(\"Specificity:\", specificity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_bi.save_model('/mnt/storageG1/lwang/Projects/tb_dr_MIC3/individual_models/saved_model1115/xgb_model_bi.json')  # or \"xgb_model.bin\"\n",
    "# loaded_model.load_model('/mnt/storageG1/lwang/Projects/tb_dr_MIC3/individual_models/saved_model1115/xgb_model.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running with xgb predictions\n",
    "test_target[f'{drug}_MIC_y'] = test_predictions_bi\n",
    "# runninng with tbp predictions\n",
    "# test_target[f'{drug}_MIC_y'] = test_target['tbp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "from collections import Counter\n",
    "\n",
    "N_samples = train_data.shape[0]\n",
    "DRUGS = train_target.columns\n",
    "# LOCI = train_data.columns\n",
    "assert set(DRUGS) == set(train_target.columns)\n",
    "N_drugs = len(DRUGS)\n",
    "#%%\n",
    "\n",
    "def my_padding(seq_tuple):\n",
    "    list_x_ = list(seq_tuple)\n",
    "    max_len = len(max(list_x_, key=len))\n",
    "    for i, x in enumerate(list_x_):\n",
    "        list_x_[i] = x + \"N\"*(max_len-len(x))\n",
    "    return list_x_\n",
    "\n",
    "#! faster than my_padding try to incorporate\n",
    "def collate_padded_batch(batch):\n",
    "    # get max length of seqs in batch\n",
    "    max_len = max([x[0].shape[1] for x in batch])\n",
    "    return torch.utils.data.default_collate(\n",
    "        [(F.pad(x[0], (0, max_len - x[0].shape[1])), x[1]) for x in batch] #how does F.pad work\n",
    "    )\n",
    "\n",
    "# Julian's code - implement this, might be faster\n",
    "class Dataset(torch.utils.data.Dataset): #? what's the difference between using inheritance and not?\n",
    "    def __init__(\n",
    "        self,\n",
    "        seq_df,\n",
    "        res_df,\n",
    "        # target_loci=LOCI,\n",
    "        target_mic,\n",
    "        target_res,\n",
    "        one_hot_dtype=torch.int8,\n",
    "        transform=None,\n",
    "    ):\n",
    "        self.transform = transform\n",
    "        # self.seq_df = seq_df[target_loci]\n",
    "        self.seq_df = seq_df\n",
    "        self.res_df = res_df[target_res]\n",
    "        self.mic_df = res_df[target_mic]\n",
    "        # if not self.seq_df.index.equals(self.res_df.index):\n",
    "        #     raise ValueError(\n",
    "        #         \"Indices of sequence and resistance dataframes don't match up\"\n",
    "        #     )\n",
    "        self.one_hot_dtype = one_hot_dtype\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        numerical index --> get `index`-th sample\n",
    "        string index --> get sample with name `index`\n",
    "        \"\"\"\n",
    "        index = int(index)\n",
    "        if isinstance(index, int):\n",
    "            seqs_comb = self.seq_df[index]\n",
    "            res = self.res_df.iloc[index]\n",
    "            mic = self.mic_df.iloc[index]\n",
    "        elif isinstance(index, str):\n",
    "            seqs_comb = self.seq_df[int(index)]\n",
    "            res = self.res_df.loc[index]\n",
    "            mic = self.mic_df.loc[index]\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Index needs to be an integer or a sample name present in the dataset\"\n",
    "            )\n",
    "\n",
    "        if self.transform:\n",
    "            res = np.log(res)\n",
    "            \n",
    "            # self.res_mean = self.res_df.mean()\n",
    "            # self.res_std = self.res_df.std()\n",
    "            # res = (res - self.res_mean) / self.res_std\n",
    "            # res = self.transform(res)\n",
    "        return torch.unsqueeze(torch.tensor(seqs_comb).float(), 0), torch.tensor(mic).long().flatten().squeeze(), torch.tensor(res).long().flatten().squeeze()\n",
    "    def __len__(self):\n",
    "        return self.res_df.shape[0]\n",
    "\n",
    "training_dataset = Dataset(train_data, train_target, f'{drug}_MIC_x',f'{drug}_MIC_y', one_hot_dtype=torch.float, transform=False)\n",
    "# train_dataset, val_dataset = random_split(training_dataset, [int(len(training_dataset)*0.9), len(training_dataset)-int(len(training_dataset)*0.9)])\n",
    "\n",
    "# test_data = np.load('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/individual_models/snps_crypticTest_emb.npy')\n",
    "# train_data = np.load('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/individual_models/drs_crypticTest_emb.npy')\n",
    "testing_dataset = Dataset(test_data, test_target, f'{drug}_MIC_x',f'{drug}_MIC_y',one_hot_dtype=torch.float, transform=False)\n",
    "\n",
    "train_idx, validation_idx = train_test_split(np.arange(len(train_data)),\n",
    "                                             test_size=0.1,\n",
    "                                             random_state=42,\n",
    "                                             shuffle=True,\n",
    "                                             stratify=train_target)\n",
    "\n",
    "# Subset dataset for train and val\n",
    "train_dataset = Subset(training_dataset, train_idx)\n",
    "val_dataset = Subset(training_dataset, validation_idx)\n",
    "\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# # device = 'cpu'\n",
    "\n",
    "y_true = train_target\n",
    "# y_true = pd.concat([train_target, test_target])\n",
    "\n",
    "column_weight_maps = {}\n",
    "\n",
    "for column in y_true.columns:\n",
    "    column_values = y_true[column].dropna().values\n",
    "    values, counts = np.unique(column_values, return_counts=True)\n",
    "    frequency = counts / len(column_values)\n",
    "    \n",
    "    # Calculate weights as the inverse of frequencies\n",
    "    weights_inverse = 1/frequency\n",
    "    # weights_inverse = 1 - frequency\n",
    "    \n",
    "    # Normalize weights to ensure they sum up to 1\n",
    "    weights_normalized = weights_inverse / np.sum(weights_inverse)\n",
    "    \n",
    "    # Map each MIC value to its corresponding weight\n",
    "    weight_map = {value: weight for value, weight in zip(values, weights_normalized)}\n",
    "    \n",
    "    column_weight_maps[column] = weight_map\n",
    "\n",
    "def get_weighted_masked_cross_entropy_loss(column_weight_maps):\n",
    "    \"\"\"\n",
    "    Creates a loss function that computes a weighted cross entropy loss, taking into account class imbalances.\n",
    "    :param column_weight_maps: Dictionary mapping column names to their corresponding class weight maps.\n",
    "    \"\"\"\n",
    "    def weighted_masked_cross_entropy_loss(y_pred, y_true):\n",
    "        # weighted_losses = torch.Tensor().to(device)\n",
    "        weighted_losses = []\n",
    "        col_weight_map = column_weight_maps\n",
    "        # print(col_weight_map)\n",
    "        mean_weight = np.mean(list(col_weight_map.values())) # just in case if a number is not recognised and the loss doesn't go crazy\n",
    "\n",
    "        # print(y_pred.size())\n",
    "        # Assuming y_true is a tensor of class indices for each column and y_pred are the logits\n",
    "        weights_col = [col_weight_map.get(y.item(), mean_weight) for y in y_true]\n",
    "        # print(weights_col)\n",
    "        # CrossEntropyLoss expects class indices as y_true, and logits as y_pred\n",
    "        loss_fn = F.cross_entropy\n",
    "        col_loss = loss_fn(y_pred, y_true, reduction = 'none').to(device)\n",
    "        \n",
    "        # loss_fn = nn.CrossEntropyLoss(reduction = 'none')\n",
    "        # col_loss = loss_fn(y_pred, y_true)\n",
    "        # print(y_true.dtype)\n",
    "        # print(col_loss)\n",
    "        weights_col = torch.Tensor(weights_col).to(device)\n",
    "        # print(weights_col)\n",
    "        # print(col_loss)\n",
    "        weighted_col_loss = weights_col * col_loss\n",
    "        # print(weighted_col_loss)\n",
    "        weighted_losses.append(weighted_col_loss.mean())\n",
    "\n",
    "        total_weighted_loss = torch.stack(weighted_losses).mean()\n",
    "        \n",
    "        # for i, column in enumerate(column_weight_maps.keys()):\n",
    "        #     col_weight_map = column_weight_maps[column]\n",
    "        #     print(y_pred.size())\n",
    "        #     # Assuming y_true is a tensor of class indices for each column and y_pred are the logits\n",
    "        #     weights_col = torch.tensor([col_weight_map[y.item()] for y in y_true[:, i]], dtype=torch.float32, device=y_true.device)\n",
    "        #     print(weights_col)\n",
    "        #     # CrossEntropyLoss expects class indices as y_true, and logits as y_pred\n",
    "        #     loss_fn = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "        #     col_loss = loss_fn(y_pred[:, i,], y_true[:, i])\n",
    "            \n",
    "        #     weighted_col_loss = weights_col * col_loss\n",
    "        #     weighted_losses.append(weighted_col_loss.mean())\n",
    "        \n",
    "        # total_weighted_loss = torch.stack(weighted_losses).mean()\n",
    "        return total_weighted_loss\n",
    "\n",
    "    return weighted_masked_cross_entropy_loss\n",
    "\n",
    "# Also assuming `columns` is a list of your target column names corresponding to y_true and y_pred\n",
    "weighted_cross_entropy_loss_fn = get_weighted_masked_cross_entropy_loss(column_weight_maps[f'{drug}_MIC_x'])\n",
    "# loss = weighted_cross_entropy_loss_fn(y_true_tensor, y_pred_logits, columns)\n",
    "\n",
    "def save_to_file(file_path, appendix, epoch, lr, cnndr, fcdr, l2, train_loss, test_loss, optimizer, model):\n",
    "    train_loss = [float(arr) for arr in train_loss]\n",
    "    test_loss = [float(arr) for arr in test_loss]\n",
    "    with open(file_path, \"a\") as f:\n",
    "        f.write(f\"#>> {appendix}, Epoch: {epoch}, LR: {lr}, fcDR: {fcdr}\\n\")\n",
    "        f.write(f\"Train_Loss= {train_loss}\\n\")\n",
    "        f.write(f\"Test_Loss= {test_loss}\\n\")\n",
    "        f.write(f\"lossGraph(Train_Loss, Test_Loss, '{appendix}-Epoch-{epoch}-LR-{lr}-fcDR-{fcdr}')\\n\")\n",
    "\n",
    "    torch.save({\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'model': model.state_dict(),\n",
    "    }, f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/saved_models/seq-{appendix}-{epoch}-{lr}-{cnndr}-{fcdr}-{l2}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test_data = np.load('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/individual_models/snps_crypticTest_emb.npy')\n",
    "# test_target = np.load('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/individual_models/drs_crypticTest_emb.npy')\n",
    "# testing_dataset = Dataset(test_data, test_target, 'EMB_MIC_x','EMB_MIC_y',one_hot_dtype=torch.float, transform=False)\n",
    "# testing_loader1 = DataLoader(dataset=testing_dataset, batch_size=1, num_workers=1, shuffle=True, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "       \n",
    "from torch.optim.lr_scheduler import CyclicLR\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels=1,\n",
    "        num_classes=6,\n",
    "        num_filters=64,\n",
    "        filter_length=25,\n",
    "        num_conv_layers=2,\n",
    "        filter_scaling_factor=1,  # New parameter\n",
    "        num_dense_neurons=256,\n",
    "        num_dense_layers=2,\n",
    "        conv_dropout_rate=0.0,\n",
    "        dense_dropout_rate=0.2,\n",
    "        l1_strength = 0.1,\n",
    "        return_logits=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.num_classes = num_classes\n",
    "        self.num_filters = num_filters\n",
    "        self.filter_length = filter_length\n",
    "        self.num_conv_layers = num_conv_layers\n",
    "        self.num_dense_layers = num_dense_layers\n",
    "        self.conv_dropout_rate = conv_dropout_rate\n",
    "        self.dense_dropout_rate = dense_dropout_rate\n",
    "        self.return_logits = return_logits\n",
    "        \n",
    "        # now define the actual model\n",
    "        # self.feature_extraction_layer = self._conv_layer(\n",
    "            # in_channels, num_filters, filter_length\n",
    "        # )\n",
    "        self.feature_extraction_layer = self._conv_layer_extract(\n",
    "            in_channels, num_filters, filter_length\n",
    "        )\n",
    "        #dynamic filter scaling from deepram\n",
    "        current_num_filters1 = num_filters\n",
    "        self.conv_layers1 = nn.ModuleList()\n",
    "        for i in range(num_conv_layers):\n",
    "            layer = self._conv_layer(current_num_filters1, int(current_num_filters1 * filter_scaling_factor), 3)\n",
    "            self.conv_layers1.append(layer)\n",
    "            current_num_filters1 = int(current_num_filters1 * filter_scaling_factor)\n",
    "            \n",
    "        current_num_filters2 = 32\n",
    "        self.conv_layers2 = nn.ModuleList()\n",
    "        for i in range(num_conv_layers):\n",
    "            layer = self._conv_layer(current_num_filters1, int(current_num_filters2 * filter_scaling_factor), 3)\n",
    "            self.conv_layers2.append(layer)\n",
    "            current_num_filters1 = current_num_filters2\n",
    "            \n",
    "        self.dense_layers = nn.ModuleList(\n",
    "            self._dense_layer(input_dim, num_dense_neurons)\n",
    "            for input_dim in [23872]\n",
    "            + [num_dense_neurons] * (num_dense_layers - 1) #how does this work?\n",
    "        )\n",
    "        \n",
    "        # self.dense_layers = nn.ModuleList(\n",
    "            # self._dense_layer(input_dim, num_dense_neurons)\n",
    "            # for input_dim in [current_num_filters2]\n",
    "            # + [num_dense_neurons] * (num_dense_layers - 1) #how does this work?\n",
    "        # )\n",
    "        \n",
    "        # self.prediction_layer = (\n",
    "        #     nn.Linear(num_dense_neurons, num_classes)\n",
    "        #     if return_logits\n",
    "        #     else nn.Sequential(nn.Linear(num_dense_neurons, num_classes), nn.ReLU()) #difference between sequential and nn.moduleList?\n",
    "        # )\n",
    "        \n",
    "        dense_output_size = num_dense_neurons  # Assuming dense layer output is num_dense_neurons\n",
    "        additional_input_size = 1  # Assuming additional input is a single value\n",
    "        total_input_size = dense_output_size + additional_input_size  # Total input size for the prediction layer\n",
    "\n",
    "        self.prediction_layer = (\n",
    "            nn.Linear(total_input_size, num_classes)  # If logits are returned directly\n",
    "            if return_logits\n",
    "            else nn.Sequential(\n",
    "                nn.Linear(total_input_size, int(total_input_size * 0.7)),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(p=self.dense_dropout_rate),  # Dropout layer after the first ReLU activation\n",
    "                nn.Linear(int(total_input_size * 0.7), int(total_input_size * 0.5)),  # Optional additional layer with reduced size\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(p=self.dense_dropout_rate),  # Dropout layer after the second ReLU activation\n",
    "                nn.Linear(int(total_input_size * 0.5), num_classes)  # Final layer to match the number of classes\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.m = nn.MaxPool1d(3, stride=1)\n",
    "        \n",
    "        self.apply(self.init_weights)    \n",
    "    \n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def _conv_layer(self, in_channels, out_channels, kernel_size):\n",
    "        return nn.Sequential(\n",
    "            nn.Dropout(p=self.conv_dropout_rate),\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def _conv_layer_extract(self, in_channels, out_channels, kernel_size):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def _dense_layer(self, n_in, n_out):\n",
    "        return nn.Sequential(\n",
    "            nn.Dropout(p=self.dense_dropout_rate),\n",
    "            nn.Linear(n_in, n_out),\n",
    "            nn.BatchNorm1d(n_out),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def l1_regularization(self):\n",
    "        l1_loss_example = 0\n",
    "        for param in self.parameters():\n",
    "            l1_loss_example += torch.sum(torch.abs(param))\n",
    "        return self.l1_strength * l1_loss_example\n",
    "\n",
    "    def forward(self, x, additional_input):\n",
    "        # Feature extraction\n",
    "        x = self.feature_extraction_layer(x)\n",
    "\n",
    "        # Convolutional layers\n",
    "        for layer in self.conv_layers1:\n",
    "            x = layer(x)\n",
    "        x = self.m(x)\n",
    "        for layer in self.conv_layers2:\n",
    "            x = layer(x)\n",
    "        x = self.m(x)\n",
    "        \n",
    "        # Flatten the tensor to [batch_size, features]\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Dense layers\n",
    "        for layer in self.dense_layers:\n",
    "            x = layer(x)\n",
    "            \n",
    "        additional_input = additional_input.unsqueeze(1)\n",
    "        # Concatenate additional input value\n",
    "        x = torch.cat((x, additional_input), dim=1)  # Concatenate along the feature dimension\n",
    "\n",
    "        # Prediction layer\n",
    "        x = self.prediction_layer(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# def l1loss(layer): # https://stackoverflow.com/questions/50054049/lack-of-sparse-solution-with-l1-regularization-in-pytorch\n",
    "#     return torch.norm(layer.weight, p=1)\n",
    "\n",
    "# def l1loss(sequence):\n",
    "#     l1_regularization = 0\n",
    "#     for module in sequence.modules():\n",
    "#         if isinstance(module, nn.Conv1d):  # Check if the module is a Conv1d layer\n",
    "#             l1_regularization += torch.norm(module.weight, p=1)\n",
    "#     return l1_regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 50/500 [05:08<55:27,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50\n",
      "Training loss: 0.1836533397436142\n",
      "Validation loss: 0.17540746927261353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 100/500 [12:51<1:03:08,  9.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100\n",
      "Training loss: 0.16681234538555145\n",
      "Validation loss: 0.16415879130363464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 150/500 [20:47<55:00,  9.43s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150\n",
      "Training loss: 0.16104988753795624\n",
      "Validation loss: 0.15770719945430756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 197/500 [28:18<48:27,  9.60s/it]"
     ]
    }
   ],
   "source": [
    "# input parameter\n",
    "lr = 1e-4\n",
    "epoch = 500\n",
    "conv_dropout_rate=0.4\n",
    "dense_dropout_rate=0.7\n",
    "weight_decay=1e-4\n",
    "######################################\n",
    "\n",
    "model = Model(\n",
    "num_classes=len(np.unique(drs)),\n",
    "num_filters=64,\n",
    "num_conv_layers=2,\n",
    "# num_dense_neurons=256, # batch_size = 64\n",
    "num_dense_neurons=128, # batch_size = 64\n",
    "num_dense_layers=2,\n",
    "return_logits=False,\n",
    "conv_dropout_rate=conv_dropout_rate,\n",
    "dense_dropout_rate=dense_dropout_rate\n",
    ").to(device)\n",
    "\n",
    "# model = Model( #! way too memory intensive\n",
    "# num_classes=13,\n",
    "# num_filters=128,\n",
    "# num_conv_layers=2,\n",
    "# num_dense_neurons=64, # batch_size = 64\n",
    "\n",
    "# num_dense_layers=2,\n",
    "# return_logits=True,\n",
    "# conv_dropout_rate=0,\n",
    "# dense_dropout_rate=0\n",
    "# ).to(device)\n",
    "## early stopping\n",
    "best_val_loss = float('inf')\n",
    "patience = 8  # How many epochs to wait after last time validation loss improved.\n",
    "patience_counter = 0\n",
    "lmbda = torch.tensor(1e-4, dtype = torch.float32)\n",
    "\n",
    "batch_size = 64\n",
    "# lr = 0.0085\n",
    "# lr = 0.00002\n",
    "lr = lr\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True ,num_workers=8, drop_last=True)\n",
    "test_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, num_workers=8, shuffle=True, drop_last=True)\n",
    "\n",
    "# train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_padded_batch ,num_workers=8, drop_last=True)\n",
    "# test_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, collate_fn=collate_padded_batch, num_workers=8, shuffle=True, drop_last=True)\n",
    "# criterion = nn.MSELoss()\n",
    "# criterion = masked_weighted_MAE\n",
    "# criterion = masked_weighted_MSE\n",
    "criterion = weighted_cross_entropy_loss_fn\n",
    "# criterion = masked_MAE\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr,  weight_decay=weight_decay)\n",
    "# scheduler = CyclicLR(optimizer, base_lr=1e-8, max_lr=1e-4, step_size_up=200, mode='triangular', cycle_momentum=False)\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbo\n",
    "#%%\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "import gc; gc.collect()\n",
    "# ic.enable()\n",
    "ic.disable()\n",
    "\n",
    "train_epoch_loss = []\n",
    "test_epoch_loss = []\n",
    "\n",
    "for e in tqdm(range(1, epoch+1)):\n",
    "    model.train()\n",
    "    train_batch_loss = []\n",
    "    test_batch_loss = []\n",
    "    # print(f'Epoch {e}')\n",
    "    for x_train, y_train, y_train_res in train_loader:\n",
    "        x_batch = torch.squeeze(x_train, 0).to(device)\n",
    "        y_batch = y_train.to(device).long()  # Convert to torch.long\n",
    "        y_batch_res = y_train_res.to(device)\n",
    "        \n",
    "        x_batch = x_batch.float()\n",
    "        pred = model(x_batch.float(),y_batch_res.float())\n",
    "        \n",
    "        pred = pred.float()  # Convert predictions to float if necessary\n",
    "        y_batch = y_batch.long()  # Ensure targets are long integers\n",
    "        # break\n",
    "        # loss_train = loss_corn(pred, y_batch, 3, class_weights)\n",
    "        # print(pred, y_batch)\n",
    "        loss_train = criterion(pred,y_batch)\n",
    "        # print(pred)\n",
    "        # print(y_batch)\n",
    "        # print(loss_train)\n",
    "        train_batch_loss.append(loss_train)        \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        # scheduler.step()  # Update the learning rate\n",
    "        # break\n",
    "    train_epoch_loss.append(torch.mean(torch.stack(train_batch_loss)).detach().cpu().numpy())\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # print('>> test')\n",
    "        for x_test, y_test, y_test_res in test_loader:\n",
    "            x_batch = torch.squeeze(x_test, 0).to(device)\n",
    "            x_batch = x_batch.float()\n",
    "            y_batch = y_test.to(device)\n",
    "            y_batch_res = y_test_res.to(device)\n",
    "            # print(x_batch.size())\n",
    "            # y_batch = torch.Tensor.float(y).to(device)\n",
    "            # x_batch = x_batch.permute(0, 3, 1, 2).to(device)\n",
    "            pred = model(x_batch.float(), y_batch_res.float())\n",
    "            loss_test = criterion(pred,y_batch)\n",
    "            # pred = pred.unsqueeze(0)\n",
    "            # print(pred[:10])\n",
    "            # print(y_batch[:10])\n",
    "\n",
    "            # loss_test = loss_corn(pred, y_batch, 3, class_weights)\n",
    "            test_batch_loss.append(loss_test)\n",
    "        test_epoch_loss.append(torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy())\n",
    "    if e%50 == 0:\n",
    "        print(f'Epoch {e}')\n",
    "        print(f\"Training loss: {torch.mean(torch.stack(train_batch_loss)).detach().cpu().numpy()}\")\n",
    "        print(f\"Validation loss: {torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy()}\") \n",
    "    # scheduler.step(torch.mean(torch.stack(test_batch_loss)))\n",
    "    # print(train_batch_loss)\n",
    "    # print(test_batch_loss)\n",
    "    # print(f\"Training loss: {np.mean(train_batch_loss)}\")\n",
    "    # print(f\"Validation loss: {np.mean(test_batch_loss)}\")\n",
    "    # #! implementing early stopping\n",
    "    # current_val_loss = torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy()\n",
    "    # print(f'Current val loss: {current_val_loss}')\n",
    "    # print(f'Best val loss: {best_val_loss}')\n",
    "    # if current_val_loss < best_val_loss:\n",
    "    #     best_val_loss = current_val_loss\n",
    "    #     patience_counter = 0  # reset patience counter\n",
    "    #     # Save the best model\n",
    "    #     # torch.save(model.state_dict(), '/mnt/storageG1/lwang/Projects/tb_dr_MIC/saved_models/aa-model_final.pth')\n",
    "\n",
    "    # else:\n",
    "    #     patience_counter += 1\n",
    "    #     if patience_counter >= patience:\n",
    "    #         print(\"Early stopping triggered\")\n",
    "    #         torch.save({\n",
    "    #         'optimizer': optimizer.state_dict(),\n",
    "    #         'model': model.state_dict(),\n",
    "    #     }, '/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/saved_models/aa-model_weighted_balanced_binned_aa_newdata.pth')\n",
    "    #         break  # Early stopping\n",
    "    \n",
    "print('==='*10)\n",
    "# torch.save(model.state_dict(), '/mnt/storageG1/lwang/Projects/tb_dr_MIC/saved_models/final_seq_model1-44ep.pt')\n",
    "save_to_file('trials3.txt', 'aa-training_weighted_balance-MXF' ,epoch, lr=lr, fcdr=dense_dropout_rate, l2=weight_decay, cnndr=conv_dropout_rate, \n",
    "             train_loss = train_epoch_loss, test_loss = test_epoch_loss, optimizer=optimizer, model = model)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x = np.arange(1, epoch+1, 1)\n",
    "ax.plot(x, train_epoch_loss,label='Training')\n",
    "ax.plot(x, test_epoch_loss,label='Validation')\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Number of Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_xticks(np.arange(0, epoch+1, 10))\n",
    "ax.set_title(f'Loss: Learning_rate:{lr}')\n",
    "# ax_2 = ax.twinx()\n",
    "# ax_2.plot(history[\"lr\"], \"k--\", lw=1)\n",
    "# ax_2.set_yscale(\"log\")\n",
    "# ax.set_ylim(ax.get_ylim()[0], history[\"training_losses\"][0])\n",
    "ax.grid(axis=\"x\")\n",
    "fig.tight_layout()\n",
    "fig.show()\n",
    "fig.savefig(f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/graphs3/aa-loss_lr_{lr}_weighted_balanced-{drug}.png')\n",
    "print(f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/graphs3/aa-loss_lr_{lr}_weighted_balanced.png-{drug}')\n",
    "\n",
    "#%%\n",
    "# testing_dataset = Dataset(test_data, test_target, 'EMB_MIC_x','EMB_MIC_y',one_hot_dtype=torch.float, transform=False)\n",
    "# testing_loader1 = DataLoader(dataset=testing_dataset, batch_size=1, num_workers=1, shuffle=True, drop_last=True)\n",
    "# testing_dataset = Dataset(test_data, test_target, 'EMB_MIC_x','EMB_MIC_y',one_hot_dtype=torch.float, transform=False)\n",
    "testing_loader1 = DataLoader(dataset=testing_dataset, batch_size=1, num_workers=1, shuffle=True, drop_last=True)\n",
    "\n",
    "# Ensure the model is on the same device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "ic.disable()\n",
    "model.eval()\n",
    "pred_list = []\n",
    "target_list  = []\n",
    "mse_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_test, y_test, y_test_res in testing_loader1:\n",
    "        # Move input and target data to the correct device\n",
    "        x_test = x_test.to(device).float()\n",
    "        y_test = y_test.to(device).float()\n",
    "        y_test_res = y_test_res.to(device).float()\n",
    "        \n",
    "        # Forward pass\n",
    "        pred = model(x_test, y_test_res)\n",
    "        \n",
    "        # Append predictions and targets to lists\n",
    "        pred_list.append(np.argmax(pred.detach().cpu().numpy())) \n",
    "        target_list.append(y_test.detach().cpu().numpy())\n",
    "        \n",
    "# Flatten the target list\n",
    "target_list = np.array(target_list).flatten()\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, mean_absolute_error\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "def calculate_metrics(true_labels, predictions):\n",
    "    \"\"\"\n",
    "    Calculates accuracy, F1 score, confusion matrix, and MAE for the given true and predicted labels.\n",
    "\n",
    "    Parameters:\n",
    "    - true_labels: List or array of true labels\n",
    "    - predictions: List or array of predicted labels\n",
    "\n",
    "    Returns:\n",
    "    - accuracy: Overall accuracy of predictions\n",
    "    - f1: Weighted average F1 score\n",
    "    - conf_matrix: Multiclass confusion matrix\n",
    "    - mae: Mean Absolute Error of predictions\n",
    "    \"\"\"\n",
    "    # Ensure inputs are numpy arrays for consistency\n",
    "    true_labels = np.array(true_labels)\n",
    "    predictions = np.array(predictions)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "\n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "    # Calculate MAE\n",
    "    mae = mean_absolute_error(true_labels, predictions)\n",
    "\n",
    "    return accuracy, f1, conf_matrix, mae\n",
    "\n",
    "# Example usage\n",
    "# true_labels = [0, 1, 2, 1, 0, 2, 1, 0]\n",
    "# predictions = [0, 2, 2, 1, 0, 0, 1, 0]\n",
    "\n",
    "accuracy, f1, conf_matrix, mae = calculate_metrics(target_list, pred_list)\n",
    "\n",
    "print(\"======================\")\n",
    "# print(\"Model's Named Parameters:\")\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(f\"Name: {name}\")\n",
    "#     print(f\"Shape: {param.size()}\")\n",
    "#     print(f\"Requires grad: {param.requires_grad}\")\n",
    "#     print('-----')\n",
    "print(\"Optimizer details:\")\n",
    "print(optimizer)\n",
    "for param_group in optimizer.param_groups:\n",
    "    print(\"Learning rate:\", param_group['lr'])\n",
    "    print(\"Weight decay:\", param_group.get('weight_decay', 'Not set'))\n",
    "    \n",
    "print(\"======================\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Mae: {mae}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"conf_matrix: {conf_matrix}\")\n",
    "print(\"======================\")\n",
    "\n",
    "def is_within_doubling_dilution(pred, target, target_min, target_max):\n",
    "    _ = np.arange(target_min.values-1, target_max.values+2, 1)\n",
    "    index = [i for i, x in enumerate(_) if x == target][0]\n",
    "    return (_[index-1] <= pred <= _[index+1])\n",
    "\n",
    "doubling_dilution_accuracy = np.mean([is_within_doubling_dilution(pred, true, target_min, target_max) for pred, true in zip(pred_list, target_list)])\n",
    "print(\"Doubling Dilution Accuracy:\", doubling_dilution_accuracy)\n",
    "\n",
    "# Calculate AUC\n",
    "cutoff = cutoff\n",
    "test_target_bi = (target_list >= cutoff).astype(int)\n",
    "test_predictions_bi = (np.array(pred_list) >= cutoff).astype(int)\n",
    "\n",
    "auc = roc_auc_score(test_target_bi, test_predictions_bi)\n",
    "print(\"AUC:\", auc)\n",
    "\n",
    "# Calculate confusion matrix components\n",
    "tn, fp, fn, tp = confusion_matrix(test_target_bi, test_predictions_bi).ravel()\n",
    "\n",
    "# Calculate sensitivity (recall)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "\n",
    "# Calculate specificity\n",
    "specificity = tn / (tn + fp)\n",
    "print(\"Specificity:\", specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction dtype: torch.float32\n",
      "Target dtype: torch.int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction dtype:\", pred.dtype)\n",
    "print(\"Target dtype:\", y_batch.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doubling Dilution Accuracy: 0.8935795954265612\n"
     ]
    }
   ],
   "source": [
    "def is_within_doubling_dilution(pred, target, target_min, target_max):\n",
    "    _ = np.arange(target_min.values-1, target_max.values+2, 1)\n",
    "    index = [i for i, x in enumerate(_) if x == target][0]\n",
    "    return (_[index-1] <= pred <= _[index+1])\n",
    "\n",
    "doubling_dilution_accuracy = np.mean([is_within_doubling_dilution(pred, true, target_min, target_max) for pred, true in zip(pred_list, target_list)])\n",
    "print(\"Doubling Dilution Accuracy:\", doubling_dilution_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8741451008695054\n",
      "Sensitivity: 0.9453551912568307\n",
      "Specificity: 0.8029350104821803\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate AUC\n",
    "cutoff = cutoff\n",
    "test_target_bi = (target_list >= cutoff).astype(int)\n",
    "test_predictions_bi = (np.array(pred_list) >= cutoff).astype(int)\n",
    "\n",
    "auc = roc_auc_score(test_target_bi, test_predictions_bi)\n",
    "print(\"AUC:\", auc)\n",
    "\n",
    "# Calculate confusion matrix components\n",
    "tn, fp, fn, tp = confusion_matrix(test_target_bi, test_predictions_bi).ravel()\n",
    "\n",
    "# Calculate sensitivity (recall)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "\n",
    "# Calculate specificity\n",
    "specificity = tn / (tn + fp)\n",
    "print(\"Specificity:\", specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = './saved_model1115/emb_resFeed_working17122024.pth'\n",
    "# torch.save(model.state_dict(), PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred, true in zip(pred_list, target_list):\n",
    "    print(pred, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_y = []\n",
    "errors_y_ = []\n",
    "for y_, y in zip(pred_list, target_list):\n",
    "    # if y_ != y:\n",
    "    if y not in [y_, y_+1, y_-1]:\n",
    "        errors_y.append(y)\n",
    "        errors_y_.append(y_)\n",
    "        \n",
    "for a, b in zip(errors_y, errors_y_):\n",
    "    print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 7.,  0., 48.,  0.,  2.,  0.,  3.,  0., 51., 12.]),\n",
       " array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(errors_y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint = []\n",
    "for a, b in zip(errors_y, errors_y_):\n",
    "    joint.append(f'{a}_{b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
       " [Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, '')])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "\n",
    "figure(figsize=(15, 6), dpi=80)\n",
    "plt.hist(joint, width=0.8)\n",
    "plt.xticks(rotation=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([13.,  0.,  9.,  0., 44.,  0., 42.,  0.,  9.,  6.]),\n",
       " array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ],\n",
       "       dtype=float32),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(errors_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0 1\n",
      "2.0 4\n",
      "2.0 5\n",
      "3.0 5\n",
      "3.0 1\n",
      "2.0 4\n",
      "2.0 4\n",
      "2.0 4\n",
      "5.0 1\n",
      "4.0 1\n",
      "3.0 1\n",
      "0.0 4\n",
      "2.0 0\n",
      "3.0 1\n",
      "4.0 1\n",
      "2.0 0\n",
      "3.0 1\n",
      "2.0 0\n",
      "5.0 1\n",
      "3.0 1\n",
      "2.0 4\n",
      "5.0 1\n",
      "3.0 1\n",
      "3.0 1\n",
      "0.0 5\n",
      "1.0 5\n",
      "2.0 4\n",
      "0.0 3\n",
      "0.0 4\n",
      "2.0 4\n",
      "1.0 4\n",
      "1.0 4\n",
      "3.0 1\n",
      "0.0 3\n",
      "3.0 1\n",
      "2.0 4\n",
      "0.0 2\n",
      "3.0 1\n",
      "0.0 4\n",
      "1.0 3\n",
      "4.0 1\n",
      "3.0 1\n",
      "0.0 4\n",
      "3.0 1\n",
      "2.0 4\n",
      "2.0 4\n",
      "3.0 5\n",
      "2.0 4\n",
      "4.0 1\n",
      "2.0 4\n",
      "2.0 4\n",
      "3.0 1\n",
      "3.0 1\n",
      "3.0 1\n",
      "3.0 1\n",
      "2.0 4\n",
      "2.0 0\n",
      "4.0 1\n",
      "2.0 4\n",
      "3.0 5\n",
      "0.0 4\n",
      "2.0 4\n",
      "0.0 4\n",
      "2.0 4\n",
      "2.0 4\n",
      "3.0 1\n",
      "2.0 4\n",
      "2.0 4\n",
      "3.0 1\n",
      "5.0 0\n",
      "3.0 1\n",
      "2.0 4\n",
      "2.0 4\n",
      "2.0 4\n",
      "0.0 5\n",
      "3.0 1\n",
      "2.0 4\n",
      "3.0 1\n",
      "3.0 1\n",
      "3.0 1\n",
      "2.0 4\n",
      "2.0 4\n",
      "3.0 5\n",
      "2.0 4\n",
      "3.0 1\n",
      "3.0 1\n",
      "1.0 4\n",
      "2.0 5\n",
      "3.0 5\n",
      "3.0 1\n",
      "2.0 0\n",
      "2.0 4\n",
      "3.0 0\n",
      "0.0 4\n",
      "1.0 4\n",
      "3.0 1\n",
      "3.0 5\n",
      "4.0 1\n",
      "3.0 1\n",
      "2.0 4\n",
      "3.0 1\n",
      "2.0 4\n",
      "3.0 1\n",
      "4.0 1\n",
      "3.0 5\n",
      "3.0 1\n",
      "3.0 1\n",
      "3.0 1\n",
      "2.0 4\n",
      "2.0 4\n",
      "4.0 1\n",
      "2.0 4\n",
      "3.0 1\n",
      "2.0 4\n",
      "0.0 2\n",
      "1.0 4\n",
      "2.0 4\n",
      "1.0 4\n",
      "4.0 1\n",
      "5.0 1\n",
      "2.0 4\n",
      "2.0 4\n",
      "1.0 4\n"
     ]
    }
   ],
   "source": [
    "for a, b in zip(errors_y, errors_y_):\n",
    "    print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './saved_model1115/resFeed1.pth'\n",
    "torch.save(model.state_dict(), PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================\n",
      "Optimizer details:\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "Learning rate: 0.0001\n",
      "Weight decay: 0.0001\n",
      "======================\n",
      "Accuracy: 0.5224274406332454\n",
      "Mae: 0.503957783641161\n",
      "F1 Score: 0.48083488925470447\n",
      "conf_matrix: [[ 18  86   8   0   0   0]\n",
      " [ 48 330  19   0   0   0]\n",
      " [ 15 230  51   0   0   0]\n",
      " [  0   0   0 104  44   1]\n",
      " [  0   0   0  52  65  20]\n",
      " [  0   0   0   6  14  26]]\n",
      "======================\n",
      "Doubling Dilution Accuracy: 0.9736147757255936\n",
      "AUC: 0.8179451489844314\n",
      "Sensitivity: 0.6830601092896175\n",
      "Specificity: 0.9528301886792453\n"
     ]
    }
   ],
   "source": [
    "testing_loader1 = DataLoader(dataset=testing_dataset, batch_size=1, num_workers=1, shuffle=True, drop_last=True)\n",
    "\n",
    "# Ensure the model is on the same device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "ic.disable()\n",
    "model.eval()\n",
    "pred_list = []\n",
    "target_list  = []\n",
    "mse_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_test, y_test, y_test_res in testing_loader1:\n",
    "        # Move input and target data to the correct device\n",
    "        x_test = x_test.to(device).float()\n",
    "        y_test = y_test.to(device).float()\n",
    "        y_test_res = y_test_res.to(device).float()\n",
    "        \n",
    "        # Forward pass\n",
    "        pred = model(x_test, y_test_res)\n",
    "        \n",
    "        # Append predictions and targets to lists\n",
    "        pred_list.append(np.argmax(pred.detach().cpu().numpy())) \n",
    "        target_list.append(y_test.detach().cpu().numpy())\n",
    "        \n",
    "# Flatten the target list\n",
    "target_list = np.array(target_list).flatten()\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, mean_absolute_error\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "def calculate_metrics(true_labels, predictions):\n",
    "    \"\"\"\n",
    "    Calculates accuracy, F1 score, confusion matrix, and MAE for the given true and predicted labels.\n",
    "\n",
    "    Parameters:\n",
    "    - true_labels: List or array of true labels\n",
    "    - predictions: List or array of predicted labels\n",
    "\n",
    "    Returns:\n",
    "    - accuracy: Overall accuracy of predictions\n",
    "    - f1: Weighted average F1 score\n",
    "    - conf_matrix: Multiclass confusion matrix\n",
    "    - mae: Mean Absolute Error of predictions\n",
    "    \"\"\"\n",
    "    # Ensure inputs are numpy arrays for consistency\n",
    "    true_labels = np.array(true_labels)\n",
    "    predictions = np.array(predictions)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "\n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "    # Calculate MAE\n",
    "    mae = mean_absolute_error(true_labels, predictions)\n",
    "\n",
    "    return accuracy, f1, conf_matrix, mae\n",
    "\n",
    "# Example usage\n",
    "# true_labels = [0, 1, 2, 1, 0, 2, 1, 0]\n",
    "# predictions = [0, 2, 2, 1, 0, 0, 1, 0]\n",
    "\n",
    "accuracy, f1, conf_matrix, mae = calculate_metrics(target_list, pred_list)\n",
    "\n",
    "print(\"======================\")\n",
    "# print(\"Model's Named Parameters:\")\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(f\"Name: {name}\")\n",
    "#     print(f\"Shape: {param.size()}\")\n",
    "#     print(f\"Requires grad: {param.requires_grad}\")\n",
    "#     print('-----')\n",
    "print(\"Optimizer details:\")\n",
    "print(optimizer)\n",
    "for param_group in optimizer.param_groups:\n",
    "    print(\"Learning rate:\", param_group['lr'])\n",
    "    print(\"Weight decay:\", param_group.get('weight_decay', 'Not set'))\n",
    "    \n",
    "print(\"======================\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Mae: {mae}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"conf_matrix: {conf_matrix}\")\n",
    "print(\"======================\")\n",
    "doubling_dilution_accuracy = np.mean([is_within_doubling_dilution(pred, true, target_min, target_max) for pred, true in zip(pred_list, target_list)])\n",
    "print(\"Doubling Dilution Accuracy:\", doubling_dilution_accuracy)\n",
    "\n",
    "\n",
    "# Calculate AUC\n",
    "cutoff = cutoff\n",
    "test_target_bi = (target_list >= cutoff).astype(int)\n",
    "test_predictions_bi = (np.array(pred_list) >= cutoff).astype(int)\n",
    "\n",
    "auc = roc_auc_score(test_target_bi, test_predictions_bi)\n",
    "print(\"AUC:\", auc)\n",
    "\n",
    "# Calculate confusion matrix components\n",
    "tn, fp, fn, tp = confusion_matrix(test_target_bi, test_predictions_bi).ravel()\n",
    "\n",
    "# Calculate sensitivity (recall)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "\n",
    "# Calculate specificity\n",
    "specificity = tn / (tn + fp)\n",
    "print(\"Specificity:\", specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypterparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 50/400 [02:56<20:30,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50\n",
      "Training loss: 0.1510869264602661\n",
      "Validation loss: 0.13646160066127777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 100/400 [05:52<17:28,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100\n",
      "Training loss: 0.12380748987197876\n",
      "Validation loss: 0.11622773110866547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 114/400 [06:41<16:51,  3.54s/it]"
     ]
    }
   ],
   "source": [
    "#input parameter\n",
    "for _ in [1e-4, 5e-4,1e-3, 5e-3,1e-2]:\n",
    "    lr = 1e-4\n",
    "    epoch = 400\n",
    "    conv_dropout_rate=0.4\n",
    "    dense_dropout_rate=0.7\n",
    "    weight_decay= _ #1e-4\n",
    "    ######################################\n",
    "\n",
    "    model = Model(\n",
    "    num_classes=6,\n",
    "    num_filters=64,\n",
    "    num_conv_layers=2,\n",
    "    # num_dense_neurons=256, # batch_size = 64\n",
    "    num_dense_neurons=128, # batch_size = 64\n",
    "    num_dense_layers=2,\n",
    "    return_logits=False,\n",
    "    conv_dropout_rate=conv_dropout_rate,\n",
    "    dense_dropout_rate=dense_dropout_rate\n",
    "    ).to(device)\n",
    "\n",
    "    # model = Model( #! way too memory intensive\n",
    "    # num_classes=13,\n",
    "    # num_filters=128,\n",
    "    # num_conv_layers=2,\n",
    "    # num_dense_neurons=64, # batch_size = 64\n",
    "\n",
    "    # num_dense_layers=2,\n",
    "    # return_logits=True,\n",
    "    # conv_dropout_rate=0,\n",
    "    # dense_dropout_rate=0\n",
    "    # ).to(device)\n",
    "    ## early stopping\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 8  # How many epochs to wait after last time validation loss improved.\n",
    "    patience_counter = 0\n",
    "    lmbda = torch.tensor(1e-4, dtype = torch.float32)\n",
    "\n",
    "    batch_size = 64\n",
    "    # lr = 0.0085\n",
    "    # lr = 0.00002\n",
    "    lr = lr\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True ,num_workers=8, drop_last=True)\n",
    "    test_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, num_workers=8, shuffle=True, drop_last=True)\n",
    "\n",
    "    # train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_padded_batch ,num_workers=8, drop_last=True)\n",
    "    # test_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, collate_fn=collate_padded_batch, num_workers=8, shuffle=True, drop_last=True)\n",
    "    # criterion = nn.MSELoss()\n",
    "    # criterion = masked_weighted_MAE\n",
    "    # criterion = masked_weighted_MSE\n",
    "    criterion = weighted_cross_entropy_loss_fn\n",
    "    # criterion = masked_MAE\n",
    "\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr,  weight_decay=weight_decay)\n",
    "    # scheduler = CyclicLR(optimizer, base_lr=1e-8, max_lr=1e-4, step_size_up=200, mode='triangular', cycle_momentum=False)\n",
    "\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    # optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbo\n",
    "    #%%\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    import gc; gc.collect()\n",
    "    # ic.enable()\n",
    "    ic.disable()\n",
    "\n",
    "    train_epoch_loss = []\n",
    "    test_epoch_loss = []\n",
    "\n",
    "    for e in tqdm(range(1, epoch+1)):\n",
    "        model.train()\n",
    "        train_batch_loss = []\n",
    "        test_batch_loss = []\n",
    "        # print(f'Epoch {e}')\n",
    "        for x_train, y_train, y_train_res in train_loader:\n",
    "            x_batch = torch.squeeze(x_train, 0).to(device)\n",
    "            y_batch = y_train.to(device)\n",
    "            y_batch_res = y_train_res.to(device)\n",
    "            \n",
    "            x_batch = x_batch.float()\n",
    "            pred = model(x_batch.float(),y_batch_res.float())\n",
    "\n",
    "            # break\n",
    "            # loss_train = loss_corn(pred, y_batch, 3, class_weights)\n",
    "            # print(pred, y_batch)\n",
    "            loss_train = criterion(pred,y_batch)\n",
    "            # print(pred)\n",
    "            # print(y_batch)\n",
    "            # print(loss_train)\n",
    "            train_batch_loss.append(loss_train)        \n",
    "            optimizer.zero_grad()\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "            # scheduler.step()  # Update the learning rate\n",
    "            # break\n",
    "        train_epoch_loss.append(torch.mean(torch.stack(train_batch_loss)).detach().cpu().numpy())\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # print('>> test')\n",
    "            for x_test, y_test, y_test_res in test_loader:\n",
    "                x_batch = torch.squeeze(x_test, 0).to(device)\n",
    "                x_batch = x_batch.float()\n",
    "                y_batch = y_test.to(device)\n",
    "                y_batch_res = y_test_res.to(device)\n",
    "                # print(x_batch.size())\n",
    "                # y_batch = torch.Tensor.float(y).to(device)\n",
    "                # x_batch = x_batch.permute(0, 3, 1, 2).to(device)\n",
    "                pred = model(x_batch.float(), y_batch_res.float())\n",
    "                loss_test = criterion(pred,y_batch)\n",
    "                # pred = pred.unsqueeze(0)\n",
    "                # print(pred[:10])\n",
    "                # print(y_batch[:10])\n",
    "\n",
    "                # loss_test = loss_corn(pred, y_batch, 3, class_weights)\n",
    "                test_batch_loss.append(loss_test)\n",
    "            test_epoch_loss.append(torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy())\n",
    "        if e%50 == 0:\n",
    "            print(f'Epoch {e}')\n",
    "            print(f\"Training loss: {torch.mean(torch.stack(train_batch_loss)).detach().cpu().numpy()}\")\n",
    "            print(f\"Validation loss: {torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy()}\") \n",
    "        # scheduler.step(torch.mean(torch.stack(test_batch_loss)))\n",
    "        # print(train_batch_loss)\n",
    "        # print(test_batch_loss)\n",
    "        # print(f\"Training loss: {np.mean(train_batch_loss)}\")\n",
    "        # print(f\"Validation loss: {np.mean(test_batch_loss)}\")\n",
    "        # #! implementing early stopping\n",
    "        # current_val_loss = torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy()\n",
    "        # print(f'Current val loss: {current_val_loss}')\n",
    "        # print(f'Best val loss: {best_val_loss}')\n",
    "        # if current_val_loss < best_val_loss:\n",
    "        #     best_val_loss = current_val_loss\n",
    "        #     patience_counter = 0  # reset patience counter\n",
    "        #     # Save the best model\n",
    "        #     # torch.save(model.state_dict(), '/mnt/storageG1/lwang/Projects/tb_d