{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/nn_model_script_emb_test.py - starting\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa0e6e4c950>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%\n",
    "print('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/nn_model_script_emb_test.py - starting')\n",
    "\n",
    "from array import array\n",
    "from cmath import nan\n",
    "from pyexpat import model\n",
    "import statistics\n",
    "from tkinter.ttk import Separator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchviz import make_dot\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import variable\n",
    "from itertools import chain\n",
    "from sklearn import metrics as met\n",
    "import pickle\n",
    "from icecream import ic\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from importlib import reload\n",
    "# import util\n",
    "# import model_torch_simple\n",
    "# from torchmetrics import Accuracy\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from icecream import ic\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#%%\n",
    "seed = 42\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(seed)\n",
    "# torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# train_data = np.loadtxt('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_emb/aa_data_train_gene.csv', delimiter = ',')\n",
    "# train_target = pd.read_csv('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_emb/mic_aa_train_hml.csv')\n",
    "# train_target = train_target[['EMB_MIC']]\n",
    "# # don't touch test data, split out validation data from training data during training\n",
    "# # test_data = np.loadtxt('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_EMB/aa_data_test_pca4k.csv', delimiter = ',')\n",
    "# test_data = np.loadtxt('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_emb/aa_data_test_gene.csv', delimiter = ',')\n",
    "# test_target = pd.read_csv('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_emb/mic_aa_test_hml.csv')\n",
    "# test_target = test_target[['EMB_MIC']]\n",
    "\n",
    "# all_data = np.concatenate((train_data, test_data), axis=0)\n",
    "# all_target = pd.concat((train_target, test_target), axis=0)\n",
    "\n",
    "# train_data, test_data, train_target, test_target = train_test_split(all_data, all_target, test_size=0.2, random_state=42, stratify=all_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(cryptic, gene_list):\n",
    "    # overlap = set(variants['sample_id']).intersection(set(cryptic['ENA_RUN'].to_list()))\n",
    "    # variants = variants[variants['drugs'].isin(['ethambutol'])]\n",
    "    # variants = variants[variants['sample_id'].isin(overlap)]\n",
    "    # variants['SNP'] = variants['gene'] + '-'+ variants['change']\n",
    "\n",
    "    variants = pd.read_csv('../variants_full.csv')\n",
    "    variants = variants[variants['gene'] != 'PPE35']\n",
    "    variants = variants[variants['type'] != 'synonymous_variant']\n",
    "    overlap = set(variants['sample_id']).intersection(set(cryptic['ENA_RUN'].to_list()))\n",
    "    # variants = variants[variants['drugs'].isin(['ethambutol'])]\n",
    "    variants = variants[variants['gene'].isin(gene_list)]\n",
    "    variants = variants[variants['sample_id'].isin(overlap)]\n",
    "    variants['SNP'] = variants['gene'] + '-'+ variants['change']\n",
    "\n",
    "    def compare_snp_lists_with_values_optimized(set_list, query_list, values_list):\n",
    "        # Create a dictionary from query_list and values_list for direct mapping\n",
    "        query_dict = dict(zip(query_list, values_list))\n",
    "        \n",
    "        # Use list comprehension to build the output list directly\n",
    "        output_list = [query_dict.get(snp, 0) for snp in set_list]\n",
    "        \n",
    "        return output_list\n",
    "\n",
    "    # Example usage\n",
    "    # set_list = ['SNP1', 'SNP2', 'SNP3', 'SNP4']\n",
    "    # query_list = ['SNP2', 'SNP4']\n",
    "    # values_list = [5, 10]  # Corresponding values for 'SNP2' and 'SNP4'\n",
    "    # output_list = compare_snp_lists_with_values_optimized(set_list, query_list, values_list)\n",
    "    # print(output_list)  # Expected output: [0, 5, 0, 10]# Getting all snp data\n",
    "\n",
    "    aa = []\n",
    "    all_snp = variants['SNP'].unique() # here is a list of all snps values title for the row in the final table \n",
    "    for x in tqdm(variants['sample_id'].unique()):\n",
    "        aa.append(compare_snp_lists_with_values_optimized(all_snp, variants[variants['sample_id']==x]['SNP'].to_list(), variants[variants['sample_id']==x]['freq'].to_list()))\n",
    "        # print('SNP')\n",
    "        \n",
    "    aa_array = np.array(aa)\n",
    "    aa_array[aa_array < 0.8] = 0\n",
    "    aa_array[aa_array >= 0.8] = 1\n",
    "\n",
    "    mic_aa = cryptic[cryptic['ENA_RUN'].isin(variants['sample_id'].unique())]#.iloc[:,14:27]\n",
    "    # mic_aa['wgs_id'] = pd.Categorical(mic_aa['ENA_RUN'], categories=variants['sample_id'].unique().tolist(), ordered=True)\n",
    "    # mic_aa = mic_aa.sort_values('ENA_RUN')\n",
    "    mic_aa.ENA_RUN = mic_aa.ENA_RUN.astype('category')\n",
    "    mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(variants['sample_id'].unique().tolist())\n",
    "    mic_aa = mic_aa.sort_values([\"ENA_RUN\"])  ## 'sort' changed to 'sort_values'\n",
    "\n",
    "    return aa_array, mic_aa\n",
    "\n",
    "def data_split(aa_array, encoded_mic):\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Perform stratified train-test split\n",
    "    train_data, test_data, train_target, test_target = train_test_split(\n",
    "        aa_array,\n",
    "        encoded_mic,\n",
    "        test_size=0.1,  # 10% for testing\n",
    "        stratify=encoded_mic,  # Ensures the proportion of each class is preserved\n",
    "        random_state=42  # For reproducibility\n",
    "    )\n",
    "    return train_data, test_data, train_target, test_target\n",
    "\n",
    "def is_within_doubling_dilution(pred, target, target_min, target_max):\n",
    "    _ = np.arange(target_min-1, target_max+2, 1)\n",
    "    index = [i for i, x in enumerate(_) if x == target][0]\n",
    "    return (_[index-1] <= pred <= _[index+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep_(cryptic, gene_list):\n",
    "    # overlap = set(variants['sample_id']).intersection(set(cryptic['ENA_RUN'].to_list()))\n",
    "    # variants = variants[variants['drugs'].isin(['ethambutol'])]\n",
    "    # variants = variants[variants['sample_id'].isin(overlap)]\n",
    "    # variants['SNP'] = variants['gene'] + '-'+ variants['change']\n",
    "    \n",
    "    variants = pd.read_csv('../variants_full.csv')\n",
    "    variants = variants[variants['gene'] != 'PPE35']\n",
    "    variants = variants[variants['type'] != 'synonymous_variant']\n",
    "    variants = variants[variants['type'] != 'non_coding_transcript_exon_variant']\n",
    "\n",
    "    overlap = set(variants['sample_id']).intersection(set(cryptic['ENA_RUN'].to_list()))\n",
    "    # variants = variants[variants['drugs'].isin(['ethambutol'])]\n",
    "    variants = variants[variants['gene'].isin(gene_list)]\n",
    "    variants = variants[variants['sample_id'].isin(overlap)]\n",
    "    variants['SNP'] = variants['gene'] + '-'+ variants['change']\n",
    "    # print(variants.shape)\n",
    "    # print(variants['sample_id'].unique().shape)\n",
    "\n",
    "    def compare_snp_lists_with_values_optimized(set_list, query_list, values_list):\n",
    "        # Create a dictionary from query_list and values_list for direct mapping\n",
    "        query_dict = dict(zip(query_list, values_list))\n",
    "        \n",
    "        # Use list comprehension to build the output list directly\n",
    "        output_list = [query_dict.get(snp, 0) for snp in set_list]\n",
    "        \n",
    "        return output_list\n",
    "\n",
    "    # Example usage\n",
    "    # set_list = ['SNP1', 'SNP2', 'SNP3', 'SNP4']\n",
    "    # query_list = ['SNP2', 'SNP4']\n",
    "    # values_list = [5, 10]  # Corresponding values for 'SNP2' and 'SNP4'\n",
    "    # output_list = compare_snp_lists_with_values_optimized(set_list, query_list, values_list)\n",
    "    # print(output_list)  # Expected output: [0, 5, 0, 10]# Getting all snp data\n",
    "\n",
    "    aa = []\n",
    "    all_snp = variants['SNP'].unique() # here is a list of all snps values title for the row in the final table \n",
    "    for x in tqdm(overlap):\n",
    "    # for x in tqdm(variants['sample_id'].unique()):\n",
    "        if x in variants['sample_id'].tolist():\n",
    "            aa.append(compare_snp_lists_with_values_optimized(all_snp, variants[variants['sample_id']==x]['SNP'].to_list(), variants[variants['sample_id']==x]['freq'].to_list()))\n",
    "        else:\n",
    "            aa.append([0]*len(all_snp))\n",
    "            \n",
    "        # print('SNP')\n",
    "        \n",
    "    aa_array = np.array(aa)\n",
    "    aa_array[aa_array < 0.8] = 0\n",
    "    aa_array[aa_array >= 0.8] = 1\n",
    "\n",
    "    mic_aa = cryptic[cryptic['ENA_RUN'].isin(overlap)]#.iloc[:,14:27]\n",
    "    # mic_aa = cryptic[cryptic['ENA_RUN'].isin(variants['sample_id'].unique())]#.iloc[:,14:27]\n",
    "    # print(mic_aa.shape)\n",
    "    # mic_aa['wgs_id'] = pd.Categorical(mic_aa['ENA_RUN'], categories=variants['sample_id'].unique().tolist(), ordered=True)\n",
    "    # mic_aa = mic_aa.sort_values('ENA_RUN')\n",
    "    mic_aa.ENA_RUN = mic_aa.ENA_RUN.astype('category')\n",
    "    mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(overlap)\n",
    "    # mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(variants['sample_id'].unique().tolist())\n",
    "    mic_aa = mic_aa.sort_values([\"ENA_RUN\"])  ## 'sort' changed to 'sort_values'\n",
    "    # print(mic_aa.shape)\n",
    "\n",
    "    return aa_array, mic_aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23683/1923663030.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '16'\n",
      "/tmp/ipykernel_23683/1923663030.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb['EMB_MIC'] = df_emb['EMB_MIC'].astype('float')\n",
      "100%|██████████| 11362/11362 [01:03<00:00, 177.67it/s]\n",
      "/tmp/ipykernel_23683/619452980.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.astype('category')\n",
      "/tmp/ipykernel_23683/619452980.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(overlap)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('../CRyPTIC_reuse_table_20231208.csv')\n",
    "gene_list = ['embB', 'embA', 'embC']\n",
    "df_emb = df[df['EMB_MIC'].isin(['>8','8.0', '4.0', '2.0', '1.0', '0.5'])]\n",
    "# df_emb = df_emb[~df_emb['ENA_RUN'].isin(to_be_dropped)]\n",
    "for i, row in df_emb.iterrows():\n",
    "    x = 'EMB_MIC'\n",
    "    if row[x] == '>8' :\n",
    "        df_emb.loc[i, f'{x}'] = '16'\n",
    "    elif row[x] == '<=0.25':\n",
    "        df_emb.loc[i, f'{x}'] = '0.125'\n",
    "        \n",
    "df_emb['EMB_MIC'] = df_emb['EMB_MIC'].astype('float') \n",
    "# df_emb = df_emb[~df_emb['ENA_RUN'].isin(to_be_dropped)]\n",
    "\n",
    "# variants = pd.read_csv('variants_full.csv')\n",
    "# variants = variants[variants['type'] != 'synonymous_variant']\n",
    "# df_emb = df_emb[~df_emb['EMB_PHENOTYPE_QUALITY'].isin(['LOW','MEDIUM'])]  # remove low and med quality\n",
    "# df_emb = df_emb[~df_emb['EMB_PHENOTYPE_QUALITY'].isin(['MEDIUM'])]  # remove low and med quality\n",
    "# df_emb = df_emb[df_emb['ENA_RUN'].isin(samples)]\n",
    "cryptic = df_emb\n",
    "aa_array, mic_aa = data_prep_(cryptic, gene_list)\n",
    "# encoded_mic = np.array([0 if value < 4 else 1 for value in mic_aa['EMB_MIC'].to_list()])\n",
    "\n",
    "encoded_mic = mic_aa['EMB_MIC'].to_list()\n",
    "\n",
    "# train_data, test_data, train_target, test_target = data_split(aa_array, encoded_mic)\n",
    "\n",
    "mic_series = np.log2(mic_aa['EMB_MIC'])\n",
    "mic_series += 1\n",
    "sample_ids = mic_aa['ENA_RUN']\n",
    "\n",
    "mic_series_bi = mic_aa['EMB_MIC'].apply(lambda x: 1 if x >= 8 else 0)\n",
    "mic_series_all = pd.merge(mic_series, mic_series_bi, left_index=True, right_index=True)\n",
    "train_data, test_data, train_target, test_target = data_split(aa_array, mic_series_all)\n",
    "target_min, target_max = mic_series.min(), mic_series.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EMB_MIC_x\n",
       "1.0    3571\n",
       "2.0    2661\n",
       "3.0    1344\n",
       "4.0    1229\n",
       "0.0    1005\n",
       "5.0     415\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target['EMB_MIC_x'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10225, 1710)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1.0: 3571, 2.0: 2661, 3.0: 2000, 4.0: 2000, 0.0: 2000, 5.0: 2000})\n",
      "(14232,)\n",
      "(14232, 1710)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Assuming train_data is your feature array and train_target['EMB_MIC_x'] is your target array\n",
    "X = train_data\n",
    "y = train_target['EMB_MIC_x']\n",
    "\n",
    "target_counts = {\n",
    "    1.0: 3571,  # Keep the majority class as is\n",
    "    2.0: 2661,  # Bring other classes closer\n",
    "    3.0: 2000,\n",
    "    4.0: 2000,\n",
    "    0.0: 2000,\n",
    "    5.0: 2000\n",
    "}\n",
    "# Initialize the RandomOverSampler\n",
    "ros= RandomOverSampler(sampling_strategy=target_counts, random_state=42)\n",
    "# ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Fit and resample the data\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# Verify the new class distribution\n",
    "from collections import Counter\n",
    "print(Counter(y_resampled))\n",
    "print(y_resampled.shape)\n",
    "print(X_resampled.shape)\n",
    "\n",
    "# train_mic_series_bi = y_resampled.apply(lambda x: 1 if x >= 4 else 0)\n",
    "# train_target = pd.DataFrame({'EMB_MIC_x': y_resampled, 'EMB_MIC_y': train_mic_series_bi})\n",
    "# train_data = X_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mic_series_bi = y_resampled.apply(lambda x: 1 if x >= 4 else 0)\n",
    "train_target = pd.DataFrame({'EMB_MIC_x': y_resampled, 'EMB_MIC_y': train_mic_series_bi})\n",
    "train_data = X_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21426, 1710)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cornloss weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_counts = torch.from_numpy(train_target.values).flatten()\n",
    "# train_target_counts = torch.tensor([0,1,2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 50k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Read the CSV file into a NumPy array\n",
    "aa_array = np.loadtxt('aa_array_50k.csv', delimiter=',').astype(float)  # Ensure all elements are floats\n",
    "# print(aa_array)\n",
    "\n",
    "\n",
    "# Read the text file line by line into a list and convert to floats\n",
    "with open('dr_target_50k.txt', 'r') as f:\n",
    "    mic_series = [float(line.strip()) for line in f]  # Convert each line to float\n",
    "\n",
    "# print(mic_series)\n",
    "mic_series_50k = mic_series\n",
    "\n",
    "aa_array_50k_pos = []\n",
    "mic_series_50k_pos = []\n",
    "for x, a in zip(mic_series_50k, aa_array):\n",
    "    if x == 1:\n",
    "        aa_array_50k_pos.append(a)\n",
    "        mic_series_50k_pos.append(x)\n",
    "aa_array_50k_pos = np.array(aa_array_50k_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### xgb training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8469656992084432\n",
      "AUC: 0.877891191531773\n",
      "[[794 160]\n",
      " [ 14 169]]\n",
      "Sensitivity: 0.9234972677595629\n",
      "Specificity: 0.8322851153039832\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, accuracy_score\n",
    "\n",
    "# train_data = np.column_stack((train_data, train_target['EMB_MIC_y'].values))\n",
    "# test_data = np.column_stack((test_data, test_target['EMB_MIC_y'].values))\n",
    "train_target_y = train_target['EMB_MIC_y'].values\n",
    "test_target_y = test_target['EMB_MIC_y'].values\n",
    "\n",
    "def is_within_doubling_dilution(pred, target, target_min, target_max):\n",
    "    _ = np.arange(target_min-1, target_max+2, 1)\n",
    "    index = [i for i, x in enumerate(_) if x == target][0]\n",
    "    return (_[index-1] <= pred <= _[index+1])\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_data, test_data, train_target_y, test_target_y\n",
    "# X_train = np.concatenate((X_train, aa_array_50k_pos), axis=0)\n",
    "# y_train = np.concatenate((y_train, mic_series_50k_pos), axis=0)\n",
    "# # Create the XGBoost model\n",
    "# model_bi = xgb.XGBClassifier()\n",
    "# model_bi.fit(X_train, y_train)\n",
    "model_bi = pickle.load(open(\"xgb_bi_mix.pkl\", \"rb\"))\n",
    "# model_bi = pickle.load(open(\"xgb_bi_50kbalanced.pkl\", \"rb\"))\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model_bi.predict(X_test)\n",
    "\n",
    "# Evaluate the model_bi\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "#testing\n",
    "cutoff = 4\n",
    "test_target_bi = y_test.astype(int) #(target_mic_list  >= cutoff).astype(int)\n",
    "test_predictions_bi = y_pred.astype(int)  #(np.array(pred_mic_list) >= cutoff).astype(int)\n",
    "\n",
    "auc = roc_auc_score(test_target_bi, test_predictions_bi)\n",
    "print(\"AUC:\", auc)\n",
    "\n",
    "# Calculate confusion matrix components\n",
    "tn, fp, fn, tp = confusion_matrix(test_target_bi, test_predictions_bi).ravel()\n",
    "print(confusion_matrix(test_target_bi, test_predictions_bi))\n",
    "# Calculate sensitivity (recall)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print(\"Sensitivity:\", sensitivity)  \n",
    "\n",
    "# Calculate specificity\n",
    "specificity = tn / (tn + fp)\n",
    "print(\"Specificity:\", specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target['EMB_MIC_y'] = test_predictions_bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21426"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "from collections import Counter\n",
    "\n",
    "N_samples = train_data.shape[0]\n",
    "DRUGS = train_target.columns\n",
    "# LOCI = train_data.columns\n",
    "assert set(DRUGS) == set(train_target.columns)\n",
    "N_drugs = len(DRUGS)\n",
    "#%%\n",
    "\n",
    "def my_padding(seq_tuple):\n",
    "    list_x_ = list(seq_tuple)\n",
    "    max_len = len(max(list_x_, key=len))\n",
    "    for i, x in enumerate(list_x_):\n",
    "        list_x_[i] = x + \"N\"*(max_len-len(x))\n",
    "    return list_x_\n",
    "\n",
    "#! faster than my_padding try to incorporate\n",
    "def collate_padded_batch(batch):\n",
    "    # get max length of seqs in batch\n",
    "    max_len = max([x[0].shape[1] for x in batch])\n",
    "    return torch.utils.data.default_collate(\n",
    "        [(F.pad(x[0], (0, max_len - x[0].shape[1])), x[1]) for x in batch] #how does F.pad work\n",
    "    )\n",
    "\n",
    "# Julian's code - implement this, might be faster\n",
    "class Dataset(torch.utils.data.Dataset): #? what's the difference between using inheritance and not?\n",
    "    def __init__(\n",
    "        self,\n",
    "        seq_df,\n",
    "        res_df,\n",
    "        # target_loci=LOCI,\n",
    "        target_mic,\n",
    "        target_res,\n",
    "        one_hot_dtype=torch.int8,\n",
    "        transform=None,\n",
    "    ):\n",
    "        self.transform = transform\n",
    "        # self.seq_df = seq_df[target_loci]\n",
    "        self.seq_df = seq_df\n",
    "        self.res_df = res_df[target_res]\n",
    "        self.mic_df = res_df[target_mic]\n",
    "        # if not self.seq_df.index.equals(self.res_df.index):\n",
    "        #     raise ValueError(\n",
    "        #         \"Indices of sequence and resistance dataframes don't match up\"\n",
    "        #     )\n",
    "        self.one_hot_dtype = one_hot_dtype\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        numerical index --> get `index`-th sample\n",
    "        string index --> get sample with name `index`\n",
    "        \"\"\"\n",
    "        index = int(index)\n",
    "        if isinstance(index, int):\n",
    "            seqs_comb = self.seq_df[index]\n",
    "            res = self.res_df.iloc[index]\n",
    "            mic = self.mic_df.iloc[index]\n",
    "        elif isinstance(index, str):\n",
    "            seqs_comb = self.seq_df[int(index)]\n",
    "            res = self.res_df.loc[index]\n",
    "            mic = self.mic_df.loc[index]\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Index needs to be an integer or a sample name present in the dataset\"\n",
    "            )\n",
    "\n",
    "        if self.transform:\n",
    "            res = np.log(res)\n",
    "            \n",
    "            # self.res_mean = self.res_df.mean()\n",
    "            # self.res_std = self.res_df.std()\n",
    "            # res = (res - self.res_mean) / self.res_std\n",
    "            # res = self.transform(res)\n",
    "        return torch.unsqueeze(torch.tensor(seqs_comb).float(), 0), torch.tensor(mic).long().flatten().squeeze(), torch.tensor(res).long().flatten().squeeze()\n",
    "    def __len__(self):\n",
    "        return self.res_df.shape[0]\n",
    "\n",
    "training_dataset = Dataset(train_data, train_target, 'EMB_MIC_x','EMB_MIC_y', one_hot_dtype=torch.float, transform=False)\n",
    "# train_dataset, val_dataset = random_split(training_dataset, [int(len(training_dataset)*0.9), len(training_dataset)-int(len(training_dataset)*0.9)])\n",
    "\n",
    "# test_data = np.load('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/individual_models/snps_crypticTest_emb.npy')\n",
    "# train_data = np.load('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/individual_models/drs_crypticTest_emb.npy')\n",
    "testing_dataset = Dataset(test_data, test_target, 'EMB_MIC_x','EMB_MIC_y',one_hot_dtype=torch.float, transform=False)\n",
    "\n",
    "train_idx, validation_idx = train_test_split(np.arange(len(train_data)),\n",
    "                                             test_size=0.1,\n",
    "                                             random_state=42,\n",
    "                                             shuffle=True,\n",
    "                                             stratify=train_target)\n",
    "\n",
    "# Subset dataset for train and val\n",
    "train_dataset = Subset(training_dataset, train_idx)\n",
    "val_dataset = Subset(training_dataset, validation_idx)\n",
    "\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# # device = 'cpu'\n",
    "\n",
    "y_true = train_target\n",
    "# y_true = pd.concat([train_target, test_target])\n",
    "\n",
    "column_weight_maps = {}\n",
    "\n",
    "for column in y_true.columns:\n",
    "    column_values = y_true[column].dropna().values\n",
    "    values, counts = np.unique(column_values, return_counts=True)\n",
    "    frequency = counts / len(column_values)\n",
    "    \n",
    "    # Calculate weights as the inverse of frequencies\n",
    "    weights_inverse = 1/frequency\n",
    "    # weights_inverse = 1 - frequency\n",
    "    \n",
    "    # Normalize weights to ensure they sum up to 1\n",
    "    weights_normalized = weights_inverse / np.sum(weights_inverse)\n",
    "    \n",
    "    # Map each MIC value to its corresponding weight\n",
    "    weight_map = {value: weight for value, weight in zip(values, weights_normalized)}\n",
    "    \n",
    "    column_weight_maps[column] = weight_map\n",
    "\n",
    "def get_weighted_masked_cross_entropy_loss(column_weight_maps):\n",
    "    \"\"\"\n",
    "    Creates a loss function that computes a weighted cross entropy loss, taking into account class imbalances.\n",
    "    :param column_weight_maps: Dictionary mapping column names to their corresponding class weight maps.\n",
    "    \"\"\"\n",
    "    def weighted_masked_cross_entropy_loss(y_pred, y_true):\n",
    "        # weighted_losses = torch.Tensor().to(device)\n",
    "        weighted_losses = []\n",
    "        col_weight_map = column_weight_maps\n",
    "        # print(col_weight_map)\n",
    "        mean_weight = np.mean(list(col_weight_map.values())) # just in case if a number is not recognised and the loss doesn't go crazy\n",
    "\n",
    "        # print(y_pred.size())\n",
    "        # Assuming y_true is a tensor of class indices for each column and y_pred are the logits\n",
    "        weights_col = [col_weight_map.get(y.item(), mean_weight) for y in y_true]\n",
    "        # print(weights_col)\n",
    "        # CrossEntropyLoss expects class indices as y_true, and logits as y_pred\n",
    "        loss_fn = F.cross_entropy\n",
    "        col_loss = loss_fn(y_pred, y_true, reduction = 'none').to(device)\n",
    "        \n",
    "        # loss_fn = nn.CrossEntropyLoss(reduction = 'none')\n",
    "        # col_loss = loss_fn(y_pred, y_true)\n",
    "        # print(y_true.dtype)\n",
    "        # print(col_loss)\n",
    "        weights_col = torch.Tensor(weights_col).to(device)\n",
    "        # print(weights_col)\n",
    "        # print(col_loss)\n",
    "        weighted_col_loss = weights_col * col_loss\n",
    "        # print(weighted_col_loss)\n",
    "        weighted_losses.append(weighted_col_loss.mean())\n",
    "\n",
    "        total_weighted_loss = torch.stack(weighted_losses).mean()\n",
    "        \n",
    "        # for i, column in enumerate(column_weight_maps.keys()):\n",
    "        #     col_weight_map = column_weight_maps[column]\n",
    "        #     print(y_pred.size())\n",
    "        #     # Assuming y_true is a tensor of class indices for each column and y_pred are the logits\n",
    "        #     weights_col = torch.tensor([col_weight_map[y.item()] for y in y_true[:, i]], dtype=torch.float32, device=y_true.device)\n",
    "        #     print(weights_col)\n",
    "        #     # CrossEntropyLoss expects class indices as y_true, and logits as y_pred\n",
    "        #     loss_fn = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "        #     col_loss = loss_fn(y_pred[:, i,], y_true[:, i])\n",
    "            \n",
    "        #     weighted_col_loss = weights_col * col_loss\n",
    "        #     weighted_losses.append(weighted_col_loss.mean())\n",
    "        \n",
    "        # total_weighted_loss = torch.stack(weighted_losses).mean()\n",
    "        return total_weighted_loss\n",
    "\n",
    "    return weighted_masked_cross_entropy_loss\n",
    "\n",
    "# Also assuming `columns` is a list of your target column names corresponding to y_true and y_pred\n",
    "weighted_cross_entropy_loss_fn = get_weighted_masked_cross_entropy_loss(column_weight_maps['EMB_MIC_x'])\n",
    "# loss = weighted_cross_entropy_loss_fn(y_true_tensor, y_pred_logits, columns)\n",
    "\n",
    "def save_to_file(file_path, appendix, epoch, lr, cnndr, fcdr, l2, train_loss, test_loss, optimizer, model):\n",
    "    train_loss = [float(arr) for arr in train_loss]\n",
    "    test_loss = [float(arr) for arr in test_loss]\n",
    "    with open(file_path, \"a\") as f:\n",
    "        f.write(f\"#>> {appendix}, Epoch: {epoch}, LR: {lr}, fcDR: {fcdr}\\n\")\n",
    "        f.write(f\"Train_Loss= {train_loss}\\n\")\n",
    "        f.write(f\"Test_Loss= {test_loss}\\n\")\n",
    "        f.write(f\"lossGraph(Train_Loss, Test_Loss, '{appendix}-Epoch-{epoch}-LR-{lr}-fcDR-{fcdr}')\\n\")\n",
    "\n",
    "    torch.save({\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'model': model.state_dict(),\n",
    "    }, f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/saved_models/seq-{appendix}-{epoch}-{lr}-{cnndr}-{fcdr}-{l2}.pth')\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test_data = np.load('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/individual_models/snps_crypticTest_emb.npy')\n",
    "# test_target = np.load('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/individual_models/drs_crypticTest_emb.npy')\n",
    "# testing_dataset = Dataset(test_data, test_target, 'EMB_MIC_x','EMB_MIC_y',one_hot_dtype=torch.float, transform=False)\n",
    "# testing_loader1 = DataLoader(dataset=testing_dataset, batch_size=1, num_workers=1, shuffle=True, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "       \n",
    "from torch.optim.lr_scheduler import CyclicLR\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels=1,\n",
    "        num_classes=6,\n",
    "        num_filters=64,\n",
    "        filter_length=25,\n",
    "        num_conv_layers=2,\n",
    "        filter_scaling_factor=1,  # New parameter\n",
    "        num_dense_neurons=256,\n",
    "        num_dense_layers=2,\n",
    "        conv_dropout_rate=0.0,\n",
    "        dense_dropout_rate=0.2,\n",
    "        l1_strength = 0.1,\n",
    "        return_logits=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.num_classes = num_classes\n",
    "        self.num_filters = num_filters\n",
    "        self.filter_length = filter_length\n",
    "        self.num_conv_layers = num_conv_layers\n",
    "        self.num_dense_layers = num_dense_layers\n",
    "        self.conv_dropout_rate = conv_dropout_rate\n",
    "        self.dense_dropout_rate = dense_dropout_rate\n",
    "        self.return_logits = return_logits\n",
    "        \n",
    "        # now define the actual model\n",
    "        # self.feature_extraction_layer = self._conv_layer(\n",
    "            # in_channels, num_filters, filter_length\n",
    "        # )\n",
    "        self.feature_extraction_layer = self._conv_layer_extract(\n",
    "            in_channels, num_filters, filter_length\n",
    "        )\n",
    "        #dynamic filter scaling from deepram\n",
    "        current_num_filters1 = num_filters\n",
    "        self.conv_layers1 = nn.ModuleList()\n",
    "        for i in range(num_conv_layers):\n",
    "            layer = self._conv_layer(current_num_filters1, int(current_num_filters1 * filter_scaling_factor), 3)\n",
    "            self.conv_layers1.append(layer)\n",
    "            current_num_filters1 = int(current_num_filters1 * filter_scaling_factor)\n",
    "            \n",
    "        current_num_filters2 = 32\n",
    "        self.conv_layers2 = nn.ModuleList()\n",
    "        for i in range(num_conv_layers):\n",
    "            layer = self._conv_layer(current_num_filters1, int(current_num_filters2 * filter_scaling_factor), 3)\n",
    "            self.conv_layers2.append(layer)\n",
    "            current_num_filters1 = current_num_filters2\n",
    "            \n",
    "        self.dense_layers = nn.ModuleList(\n",
    "            self._dense_layer(input_dim, num_dense_neurons)\n",
    "            for input_dim in [53568]\n",
    "            + [num_dense_neurons] * (num_dense_layers - 1) #how does this work?\n",
    "        )\n",
    "        \n",
    "        # self.dense_layers = nn.ModuleList(\n",
    "            # self._dense_layer(input_dim, num_dense_neurons)\n",
    "            # for input_dim in [current_num_filters2]\n",
    "            # + [num_dense_neurons] * (num_dense_layers - 1) #how does this work?\n",
    "        # )\n",
    "        \n",
    "        # self.prediction_layer = (\n",
    "        #     nn.Linear(num_dense_neurons, num_classes)\n",
    "        #     if return_logits\n",
    "        #     else nn.Sequential(nn.Linear(num_dense_neurons, num_classes), nn.ReLU()) #difference between sequential and nn.moduleList?\n",
    "        # )\n",
    "        \n",
    "        dense_output_size = num_dense_neurons  # Assuming dense layer output is num_dense_neurons\n",
    "        additional_input_size = 1  # Assuming additional input is a single value\n",
    "        total_input_size = dense_output_size + additional_input_size  # Total input size for the prediction layer\n",
    "\n",
    "        self.prediction_layer = (\n",
    "            nn.Linear(total_input_size, num_classes)  # If logits are returned directly\n",
    "            if return_logits\n",
    "            else nn.Sequential(\n",
    "                nn.Linear(total_input_size, int(total_input_size * 0.7)),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(p=self.dense_dropout_rate),  # Dropout layer after the first ReLU activation\n",
    "                nn.Linear(int(total_input_size * 0.7), int(total_input_size * 0.5)),  # Optional additional layer with reduced size\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(p=self.dense_dropout_rate),  # Dropout layer after the second ReLU activation\n",
    "                nn.Linear(int(total_input_size * 0.5), num_classes)  # Final layer to match the number of classes\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.m = nn.MaxPool1d(3, stride=1)\n",
    "        \n",
    "        self.apply(self.init_weights)    \n",
    "    \n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def _conv_layer(self, in_channels, out_channels, kernel_size):\n",
    "        return nn.Sequential(\n",
    "            nn.Dropout(p=self.conv_dropout_rate),\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def _conv_layer_extract(self, in_channels, out_channels, kernel_size):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def _dense_layer(self, n_in, n_out):\n",
    "        return nn.Sequential(\n",
    "            nn.Dropout(p=self.dense_dropout_rate),\n",
    "            nn.Linear(n_in, n_out),\n",
    "            nn.BatchNorm1d(n_out),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def l1_regularization(self):\n",
    "        l1_loss_example = 0\n",
    "        for param in self.parameters():\n",
    "            l1_loss_example += torch.sum(torch.abs(param))\n",
    "        return self.l1_strength * l1_loss_example\n",
    "\n",
    "    def forward(self, x, additional_input):\n",
    "        # Feature extraction\n",
    "        x = self.feature_extraction_layer(x)\n",
    "\n",
    "        # Convolutional layers\n",
    "        for layer in self.conv_layers1:\n",
    "            x = layer(x)\n",
    "        x = self.m(x)\n",
    "        for layer in self.conv_layers2:\n",
    "            x = layer(x)\n",
    "        x = self.m(x)\n",
    "        \n",
    "        # Flatten the tensor to [batch_size, features]\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Dense layers\n",
    "        for layer in self.dense_layers:\n",
    "            x = layer(x)\n",
    "            \n",
    "        additional_input = additional_input.unsqueeze(1)\n",
    "        # Concatenate additional input value\n",
    "        x = torch.cat((x, additional_input), dim=1)  # Concatenate along the feature dimension\n",
    "\n",
    "        # Prediction layer\n",
    "        x = self.prediction_layer(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "# def l1loss(layer): # https://stackoverflow.com/questions/50054049/lack-of-sparse-solution-with-l1-regularization-in-pytorch\n",
    "#     return torch.norm(layer.weight, p=1)\n",
    "\n",
    "# def l1loss(sequence):\n",
    "#     l1_regularization = 0\n",
    "#     for module in sequence.modules():\n",
    "#         if isinstance(module, nn.Conv1d):  # Check if the module is a Conv1d layer\n",
    "#             l1_regularization += torch.norm(module.weight, p=1)\n",
    "#     return l1_regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 50/300 [03:35<17:49,  4.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50\n",
      "Training loss: 0.19468477368354797\n",
      "Validation loss: 0.17073309421539307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 100/300 [07:11<14:25,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100\n",
      "Training loss: 0.16453878581523895\n",
      "Validation loss: 0.15410445630550385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 150/300 [10:46<10:45,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150\n",
      "Training loss: 0.1564233899116516\n",
      "Validation loss: 0.1504707783460617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 200/300 [14:21<07:08,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200\n",
      "Training loss: 0.15228013694286346\n",
      "Validation loss: 0.1452111005783081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 250/300 [17:58<03:37,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250\n",
      "Training loss: 0.14907820522785187\n",
      "Validation loss: 0.14268019795417786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [21:34<00:00,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300\n",
      "Training loss: 0.14705590903759003\n",
      "Validation loss: 0.14178884029388428\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/graphs3/aa-loss_lr_0.0001_weighted_balanced.png-emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23683/3335070910.py:168: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================\n",
      "Optimizer details:\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "Learning rate: 0.0001\n",
      "Weight decay: 0.0001\n",
      "======================\n",
      "Accuracy: 0.5496921723834652\n",
      "Mae: 0.5083553210202286\n",
      "F1 Score: 0.4559127808145174\n",
      "conf_matrix: [[  8  98   0   6   0   0]\n",
      " [ 19 366   3   9   0   0]\n",
      " [  9 253   5  29   0   0]\n",
      " [  3  30   0 116   0   0]\n",
      " [  0   0   0   0 108  29]\n",
      " [  0   0   0   0  24  22]]\n",
      "======================\n",
      "Doubling Dilution Accuracy: 0.9498680738786279\n",
      "AUC: 1.0\n",
      "Sensitivity: 1.0\n",
      "Specificity: 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#input parameter\n",
    "lr = 1e-4\n",
    "epoch = 300\n",
    "conv_dropout_rate=0.4\n",
    "dense_dropout_rate=0.7\n",
    "weight_decay=1e-4\n",
    "######################################\n",
    "\n",
    "model = Model(\n",
    "num_classes=6,\n",
    "num_filters=64,\n",
    "num_conv_layers=2,\n",
    "# num_dense_neurons=256, # batch_size = 64\n",
    "num_dense_neurons=128, # batch_size = 64\n",
    "num_dense_layers=2,\n",
    "return_logits=False,\n",
    "conv_dropout_rate=conv_dropout_rate,\n",
    "dense_dropout_rate=dense_dropout_rate\n",
    ").to(device)\n",
    "\n",
    "# model = Model( #! way too memory intensive\n",
    "# num_classes=13,\n",
    "# num_filters=128,\n",
    "# num_conv_layers=2,\n",
    "# num_dense_neurons=64, # batch_size = 64\n",
    "\n",
    "# num_dense_layers=2,\n",
    "# return_logits=True,\n",
    "# conv_dropout_rate=0,\n",
    "# dense_dropout_rate=0\n",
    "# ).to(device)\n",
    "## early stopping\n",
    "best_val_loss = float('inf')\n",
    "patience = 8  # How many epochs to wait after last time validation loss improved.\n",
    "patience_counter = 0\n",
    "lmbda = torch.tensor(1e-4, dtype = torch.float32)\n",
    "\n",
    "batch_size = 64\n",
    "# lr = 0.0085\n",
    "# lr = 0.00002\n",
    "lr = lr\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True ,num_workers=8, drop_last=True)\n",
    "test_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, num_workers=8, shuffle=True, drop_last=True)\n",
    "\n",
    "# train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_padded_batch ,num_workers=8, drop_last=True)\n",
    "# test_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, collate_fn=collate_padded_batch, num_workers=8, shuffle=True, drop_last=True)\n",
    "# criterion = nn.MSELoss()\n",
    "# criterion = masked_weighted_MAE\n",
    "# criterion = masked_weighted_MSE\n",
    "criterion = weighted_cross_entropy_loss_fn\n",
    "# criterion = masked_MAE\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr,  weight_decay=weight_decay)\n",
    "# scheduler = CyclicLR(optimizer, base_lr=1e-8, max_lr=1e-4, step_size_up=200, mode='triangular', cycle_momentum=False)\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbo\n",
    "#%%\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "import gc; gc.collect()\n",
    "# ic.enable()\n",
    "ic.disable()\n",
    "\n",
    "train_epoch_loss = []\n",
    "test_epoch_loss = []\n",
    "\n",
    "for e in tqdm(range(1, epoch+1)):\n",
    "    model.train()\n",
    "    train_batch_loss = []\n",
    "    test_batch_loss = []\n",
    "    # print(f'Epoch {e}')\n",
    "    for x_train, y_train, y_train_res in train_loader:\n",
    "        x_batch = torch.squeeze(x_train, 0).to(device)\n",
    "        y_batch = y_train.to(device)\n",
    "        y_batch_res = y_train_res.to(device)\n",
    "        \n",
    "        x_batch = x_batch.float()\n",
    "        pred = model(x_batch.float(),y_batch_res.float())\n",
    "\n",
    "        # break\n",
    "        # loss_train = loss_corn(pred, y_batch, 3, class_weights)\n",
    "        # print(pred, y_batch)\n",
    "        loss_train = criterion(pred,y_batch)\n",
    "        # print(pred)\n",
    "        # print(y_batch)\n",
    "        # print(loss_train)\n",
    "        train_batch_loss.append(loss_train)        \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        # scheduler.step()  # Update the learning rate\n",
    "        # break\n",
    "    train_epoch_loss.append(torch.mean(torch.stack(train_batch_loss)).detach().cpu().numpy())\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # print('>> test')\n",
    "        for x_test, y_test, y_test_res in test_loader:\n",
    "            x_batch = torch.squeeze(x_test, 0).to(device)\n",
    "            x_batch = x_batch.float()\n",
    "            y_batch = y_test.to(device)\n",
    "            y_batch_res = y_test_res.to(device)\n",
    "            # print(x_batch.size())\n",
    "            # y_batch = torch.Tensor.float(y).to(device)\n",
    "            # x_batch = x_batch.permute(0, 3, 1, 2).to(device)\n",
    "            pred = model(x_batch.float(), y_batch_res.float())\n",
    "            loss_test = criterion(pred,y_batch)\n",
    "            # pred = pred.unsqueeze(0)\n",
    "            # print(pred[:10])\n",
    "            # print(y_batch[:10])\n",
    "\n",
    "            # loss_test = loss_corn(pred, y_batch, 3, class_weights)\n",
    "            test_batch_loss.append(loss_test)\n",
    "        test_epoch_loss.append(torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy())\n",
    "    if e%50 == 0:\n",
    "        print(f'Epoch {e}')\n",
    "        print(f\"Training loss: {torch.mean(torch.stack(train_batch_loss)).detach().cpu().numpy()}\")\n",
    "        print(f\"Validation loss: {torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy()}\") \n",
    "    # scheduler.step(torch.mean(torch.stack(test_batch_loss)))\n",
    "    # print(train_batch_loss)\n",
    "    # print(test_batch_loss)\n",
    "    # print(f\"Training loss: {np.mean(train_batch_loss)}\")\n",
    "    # print(f\"Validation loss: {np.mean(test_batch_loss)}\")\n",
    "    # #! implementing early stopping\n",
    "    # current_val_loss = torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy()\n",
    "    # print(f'Current val loss: {current_val_loss}')\n",
    "    # print(f'Best val loss: {best_val_loss}')\n",
    "    # if current_val_loss < best_val_loss:\n",
    "    #     best_val_loss = current_val_loss\n",
    "    #     patience_counter = 0  # reset patience counter\n",
    "    #     # Save the best model\n",
    "    #     # torch.save(model.state_dict(), '/mnt/storageG1/lwang/Projects/tb_dr_MIC/saved_models/aa-model_final.pth')\n",
    "\n",
    "    # else:\n",
    "    #     patience_counter += 1\n",
    "    #     if patience_counter >= patience:\n",
    "    #         print(\"Early stopping triggered\")\n",
    "    #         torch.save({\n",
    "    #         'optimizer': optimizer.state_dict(),\n",
    "    #         'model': model.state_dict(),\n",
    "    #     }, '/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/saved_models/aa-model_weighted_balanced_binned_aa_newdata.pth')\n",
    "    #         break  # Early stopping\n",
    "    \n",
    "print('==='*10)\n",
    "# torch.save(model.state_dict(), '/mnt/storageG1/lwang/Projects/tb_dr_MIC/saved_models/final_seq_model1-44ep.pt')\n",
    "save_to_file('trials3.txt', 'aa-training_weighted_balanced_ce-binned-EMB_newdata_corn_corn' ,epoch, lr=lr, fcdr=dense_dropout_rate, l2=weight_decay, cnndr=conv_dropout_rate, \n",
    "             train_loss = train_epoch_loss, test_loss = test_epoch_loss, optimizer=optimizer, model = model)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x = np.arange(1, epoch+1, 1)\n",
    "ax.plot(x, train_epoch_loss,label='Training')\n",
    "ax.plot(x, test_epoch_loss,label='Validation')\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Number of Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_xticks(np.arange(0, epoch+1, 10))\n",
    "ax.set_title(f'Loss: Learning_rate:{lr}')\n",
    "# ax_2 = ax.twinx()\n",
    "# ax_2.plot(history[\"lr\"], \"k--\", lw=1)\n",
    "# ax_2.set_yscale(\"log\")\n",
    "# ax.set_ylim(ax.get_ylim()[0], history[\"training_losses\"][0])\n",
    "ax.grid(axis=\"x\")\n",
    "fig.tight_layout()\n",
    "fig.show()\n",
    "fig.savefig(f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/graphs3/aa-loss_lr_{lr}_weighted_balanced-emb.png')\n",
    "print(f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/graphs3/aa-loss_lr_{lr}_weighted_balanced.png-emb')\n",
    "\n",
    "#%%\n",
    "# testing_dataset = Dataset(test_data, test_target, 'EMB_MIC_x','EMB_MIC_y',one_hot_dtype=torch.float, transform=False)\n",
    "# testing_loader1 = DataLoader(dataset=testing_dataset, batch_size=1, num_workers=1, shuffle=True, drop_last=True)\n",
    "# testing_dataset = Dataset(test_data, test_target, 'EMB_MIC_x','EMB_MIC_y',one_hot_dtype=torch.float, transform=False)\n",
    "testing_loader1 = DataLoader(dataset=testing_dataset, batch_size=1, num_workers=1, shuffle=True, drop_last=True)\n",
    "\n",
    "# Ensure the model is on the same device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "ic.disable()\n",
    "model.eval()\n",
    "pred_list = []\n",
    "target_list  = []\n",
    "mse_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_test, y_test, y_test_res in testing_loader1:\n",
    "        # Move input and target data to the correct device\n",
    "        x_test = x_test.to(device).float()\n",
    "        y_test = y_test.to(device).float()\n",
    "        y_test_res = y_test_res.to(device).float()\n",
    "        \n",
    "        # Forward pass\n",
    "        pred = model(x_test, y_test_res)\n",
    "        \n",
    "        # Append predictions and targets to lists\n",
    "        pred_list.append(np.argmax(pred.detach().cpu().numpy())) \n",
    "        target_list.append(y_test.detach().cpu().numpy())\n",
    "        \n",
    "# Flatten the target list\n",
    "target_list = np.array(target_list).flatten()\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, mean_absolute_error\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "def calculate_metrics(true_labels, predictions):\n",
    "    \"\"\"\n",
    "    Calculates accuracy, F1 score, confusion matrix, and MAE for the given true and predicted labels.\n",
    "\n",
    "    Parameters:\n",
    "    - true_labels: List or array of true labels\n",
    "    - predictions: List or array of predicted labels\n",
    "\n",
    "    Returns:\n",
    "    - accuracy: Overall accuracy of predictions\n",
    "    - f1: Weighted average F1 score\n",
    "    - conf_matrix: Multiclass confusion matrix\n",
    "    - mae: Mean Absolute Error of predictions\n",
    "    \"\"\"\n",
    "    # Ensure inputs are numpy arrays for consistency\n",
    "    true_labels = np.array(true_labels)\n",
    "    predictions = np.array(predictions)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "\n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "    # Calculate MAE\n",
    "    mae = mean_absolute_error(true_labels, predictions)\n",
    "\n",
    "    return accuracy, f1, conf_matrix, mae\n",
    "\n",
    "# Example usage\n",
    "# true_labels = [0, 1, 2, 1, 0, 2, 1, 0]\n",
    "# predictions = [0, 2, 2, 1, 0, 0, 1, 0]\n",
    "\n",
    "accuracy, f1, conf_matrix, mae = calculate_metrics(target_list, pred_list)\n",
    "\n",
    "print(\"======================\")\n",
    "# print(\"Model's Named Parameters:\")\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(f\"Name: {name}\")\n",
    "#     print(f\"Shape: {param.size()}\")\n",
    "#     print(f\"Requires grad: {param.requires_grad}\")\n",
    "#     print('-----')\n",
    "print(\"Optimizer details:\")\n",
    "print(optimizer)\n",
    "for param_group in optimizer.param_groups:\n",
    "    print(\"Learning rate:\", param_group['lr'])\n",
    "    print(\"Weight decay:\", param_group.get('weight_decay', 'Not set'))\n",
    "    \n",
    "print(\"======================\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Mae: {mae}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"conf_matrix: {conf_matrix}\")\n",
    "print(\"======================\")\n",
    "doubling_dilution_accuracy = np.mean([is_within_doubling_dilution(pred, true, target_min, target_max) for pred, true in zip(pred_list, target_list)])\n",
    "print(\"Doubling Dilution Accuracy:\", doubling_dilution_accuracy)\n",
    "\n",
    "# Calculate AUC\n",
    "cutoff = 4\n",
    "test_target_bi = (target_list >= cutoff).astype(int)\n",
    "test_predictions_bi = (np.array(pred_list) >= cutoff).astype(int)\n",
    "\n",
    "auc = roc_auc_score(test_target_bi, test_predictions_bi)\n",
    "print(\"AUC:\", auc)\n",
    "\n",
    "# Calculate confusion matrix components\n",
    "tn, fp, fn, tp = confusion_matrix(test_target_bi, test_predictions_bi).ravel()\n",
    "\n",
    "# Calculate sensitivity (recall)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "\n",
    "# Calculate specificity\n",
    "specificity = tn / (tn + fp)\n",
    "print(\"Specificity:\", specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1137"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './saved_model1115/emb_resFeed_working1.pth'\n",
    "torch.save(model.state_dict(), PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_y = []\n",
    "errors_y_ = []\n",
    "for y_, y in zip(pred_list, target_list):\n",
    "    # if y_ != y:\n",
    "    if y not in [y_, y_+1, y_-1]:\n",
    "        errors_y.append(y)\n",
    "        errors_y_.append(y_)\n",
    "        \n",
    "for a, b in zip(errors_y, errors_y_):\n",
    "    print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 7.,  0., 48.,  0.,  2.,  0.,  3.,  0., 51., 12.]),\n",
       " array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(errors_y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint = []\n",
    "for a, b in zip(errors_y, errors_y_):\n",
    "    joint.append(f'{a}_{b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
       " [Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, '')])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8cAAAGaCAYAAAAigDFaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAxOAAAMTgF/d4wjAAAl+UlEQVR4nO3de7hkd1kn+u9LOgRIY5AQCNAJzSU4ilzCVQTCRcFhUEfBgcMzyDGjHHQUkAiHiHBwvAyBR3McnkGFgTPc1EHuR8Lg5YhyE0ExDB49JIBNbG4CwkiLASLv+WPVJkXTnezdu/auXfX7fJ6nnt61qmrv9+3fqlXru1attaq7AwAAACO7zrILAAAAgGUTjgEAABiecAwAAMDwhGMAAACGJxwDAAAwPOEYAACA4e1b1h8+5ZRT+owzzljWnwcAAGAwH/3oR7/U3acc67GlheMzzjgjhw8fXtafBwAAYDBV9anjPeZr1QAAAAxPOAYAAGB4wjEAAADDE44BAAAYnnAMAADA8IRjAAAAhiccAwAAMDzhGAAAgOEJxwAAAAxPOAYAAGB4wjEAAADDE44BAAAYnnAMAADA8IRjAAAAhiccAwAAMLx9yy5grzt44SXLLmHLDl30sGWXAAAAsFLsOQYAAGB4wjEAAADDE44BAAAYnnAMAADA8IRjAAAAhiccAwAAMDzhGAAAgOEJxwAAAAxv37ILALbn4IWXLLuELTt00cOWXQIAAHwNe44BAAAYnnAMAADA8IRjAAAAhiccAwAAMLwth+OqOr+quqq+b3b/plX15qq6vKr+sqrOW3iVAAAAsIO2FI6r6mCSxyV519zki5K8q7vPSXJ+kt+sqpMXViEAAADssE2H46q6TpIXJXlCki/OPfTIJL+eJN39niQfS3L/BdYIAAAAO2ore44vSPKO7v7zjQlVdXqSk7v7E3PPO5Tk7KNfXFUXVNXhjduRI0dOtGYAAABYqE2F46r61iSPSPILJ/qHuvvi7j6wcdu/f/+J/ioAAABYqM3uOb5fkoNJLq+qQ0m+LckLM32l+qqqOnPuuQeTXLG4EgEAAGBnbSocd/evdffNu/tgdx/MdEKu/627fy3Jq5L8aJJU1T2S3DLJH+9QvQAAALBw+xbwO56W5OVVdXmSLyV5THd/eQG/FwAAAHbFCYXj7n7A3M+fTPKQRRUEAAAAu21L1zkGAACAdSQcAwAAMDzhGAAAgOEJxwAAAAxPOAYAAGB4wjEAAADDE44BAAAYnnAMAADA8IRjAAAAhiccAwAAMDzhGAAAgOEJxwAAAAxPOAYAAGB4wjEAAADDE44BAAAYnnAMAADA8IRjAAAAhiccAwAAMDzhGAAAgOEJxwAAAAxPOAYAAGB4wjEAAADDE44BAAAYnnAMAADA8IRjAAAAhiccAwAAMDzhGAAAgOEJxwAAAAxPOAYAAGB4wjEAAADDE44BAAAYnnAMAADA8PZt9olV9XtJzkzylSSfT/LE7v6LqjqU5ItJ/mn21Gd39ysXXSgAAADslE2H4ySP7O7PJUlVfX+SlyS58+yxR3X3pQutDAAAAHbJpr9WvRGMZ05L0guvBgAAAJZgK3uOU1UvS/LA2d1/NffQy6qqkrw7yYXd/aljvPaCJBds3D/ttNO2Xi0AAADsgC2dkKu7H9vdZyV5RpLnzCaf1913SnLXJJ9O8tLjvPbi7j6wcdu/f/926gYAAICFOaGzVXf3S5M8sKpO7+4rZtO+nORXktxvceUBAADAzttUOK6qG1XVLebuf1+SzyS5sqpuNPfURyf5i0UWCAAAADtts8ccn5bkVVV1/UyXcvpUku9OcrMkr6mqk5JUkg8neexOFAoAAAA7ZVPhuLs/kuSex3n43MWVAwAAALvvhI45BgAAgHUiHAMAADA84RgAAIDhCccAAAAMTzgGAABgeMIxAAAAwxOOAQAAGJ5wDAAAwPCEYwAAAIYnHAMAADA84RgAAIDhCccAAAAMTzgGAABgeMIxAAAAwxOOAQAAGJ5wDAAAwPCEYwAAAIYnHAMAADA84RgAAIDhCccAAAAMTzgGAABgeMIxAAAAwxOOAQAAGJ5wDAAAwPCEYwAAAIYnHAMAADA84RgAAIDhCccAAAAMTzgGAABgeMIxAAAAwxOOAQAAGJ5wDAAAwPA2HY6r6veq6n9U1aVV9baqOnc2/ZyqemdVXVZV76mqO+xcuQAAALB4W9lz/MjuvlN33yXJxUleMpv+giQv7O7bJ3nO3HQAAABYCZsOx939ubm7pyXpqrppkrsnecVs+muSnFVVt1tYhQAAALDD9m3lyVX1siQPnN39V0nOSvLx7r4qSbq7q+qKJGcn+eBRr70gyQUb90877bRtlA0AAACLs6UTcnX3Y7v7rCTPyPQV6q289uLuPrBx279//1ZeDgAAADvmhM5W3d0vzbQH+XCSm1fVviSpqsq01/iKhVUIAAAAO2xT4biqblRVt5i7/31JPpPk75K8N8ljZg89Isnh7v7g1/0SAAAA2KM2e8zxaUleVVXXT/KVJJ9K8t2zY4wfn+QlVfX0JP+Q5PydKRUAAAB2xqbCcXd/JMk9j/PYB5Lce5FFAQAAwG46oWOOAQAAYJ0IxwAAAAxPOAYAAGB4wjEAAADDE44BAAAYnnAMAADA8IRjAAAAhiccAwAAMDzhGAAAgOEJxwAAAAxPOAYAAGB4wjEAAADDE44BAAAYnnAMAADA8IRjAAAAhiccAwAAMDzhGAAAgOEJxwAAAAxPOAYAAGB4wjEAAADDE44BAAAYnnAMAADA8IRjAAAAhiccAwAAMDzhGAAAgOEJxwAAAAxPOAYAAGB4wjEAAADDE44BAAAYnnAMAADA8IRjAAAAhiccAwAAMLxNheOqul5Vvb6qLquq91XV71fV7WaP/VFV/U1VXTq7PXlnSwYAAIDF2reF574wyX/v7q6qn0jyoiQPmD325O5+/YJrAwAAgF2xqT3H3X1ld7+pu3s26V1JDu5YVQAAALCLTvSY4yclecPc/Yuq6v1V9cqqus2xXlBVF1TV4Y3bkSNHTvBPAwAAwGJtORxX1dOT3C7JT88m/WB3/4skd0rytiRvPNbruvvi7j6wcdu/f/+J1gwAAAALtaVwXFVPSfLwJA/t7i8kSXf/7ezf7u7/nOQ2VXX6wisFAACAHbLpcFxVFyR5dJIHd/fnZtP2VdXN5p7ziCSf7O7PLLpQAAAA2CmbOlt1VR1I8stJPpzkLVWVJF9M8qAkl1TVKUm+kuTTSb53Z0oFAACAnbGpcNzdh5PUcR6+++LKAQAAgN13omerBgAAgLUhHAMAADA84RgAAIDhCccAAAAMTzgGAABgeMIxAAAAwxOOAQAAGJ5wDAAAwPCEYwAAAIYnHAMAADA84RgAAIDhCccAAAAMTzgGAABgeMIxAAAAwxOOAQAAGJ5wDAAAwPCEYwAAAIYnHAMAADA84RgAAIDhCccAAAAMTzgGAABgeMIxAAAAwxOOAQAAGJ5wDAAAwPCEYwAAAIYnHAMAADA84RgAAIDhCccAAAAMTzgGAABgeMIxAAAAwxOOAQAAGJ5wDAAAwPA2FY6r6npV9fqquqyq3ldVv19Vt5s9dtOqenNVXV5Vf1lV5+1syQAAALBYW9lz/MIk39Tdd07yhiQvmk2/KMm7uvucJOcn+c2qOnmxZQIAAMDO2VQ47u4ru/tN3d2zSe9KcnD28yOT/Prsee9J8rEk919wnQAAALBjTvSY4ycleUNVnZ7k5O7+xNxjh5KcffQLquqCqjq8cTty5MgJ/mkAAABYrC2H46p6epLbJfnprbyuuy/u7gMbt/3792/1TwMAAMCO2FI4rqqnJHl4kod29xe6+zNJrqqqM+eedjDJFYsrEQAAAHbWpsNxVV2Q5NFJHtzdn5t76FVJfnT2nHskuWWSP15gjQAAALCj9m3mSVV1IMkvJ/lwkrdUVZJ8sbvvleRpSV5eVZcn+VKSx3T3l3eoXgAAAFi4TYXj7j6cpI7z2CeTPGSRRQEAAMBuOtGzVQMAAMDaEI4BAAAYnnAMAADA8IRjAAAAhiccAwAAMDzhGAAAgOEJxwAAAAxPOAYAAGB4wjEAAADDE44BAAAYnnAMAADA8IRjAAAAhiccAwAAMDzhGAAAgOEJxwAAAAxPOAYAAGB4wjEAAADDE44BAAAYnnAMAADA8IRjAAAAhiccAwAAMDzhGAAAgOEJxwAAAAxPOAYAAGB4wjEAAADDE44BAAAYnnAMAADA8IRjAAAAhiccAwAAMDzhGAAAgOEJxwAAAAxPOAYAAGB4mwrHVfW8qjpUVV1Vd5mbfqiqPlBVl85uj9qxSgEAAGCH7Nvk816d5LlJ3n6Mxx7V3ZcurCIAAADYZZsKx9391iSpqp2tBgAAAJZgEcccv6yq3l9VL66qM473pKq6oKoOb9yOHDmygD8NAAAA27fdcHxed98pyV2TfDrJS4/3xO6+uLsPbNz279+/zT8NAAAAi7HZY46PqbuvmP375ar6lSSXLaIoAAAA2E0nvOe4qk6tqhvNTXp0kr/YdkUAAACwyza157iqXpDkYUnOTPK7VfX5JA9J8pqqOilJJflwksfuVKEAAACwUzZ7turHH+ehcxdYCwAAACzFIs5WDQAAACtNOAYAAGB4wjEAAADDE44BAAAYnnAMAADA8IRjAAAAhiccAwAAMDzhGAAAgOEJxwAAAAxPOAYAAGB4wjEAAADDE44BAAAYnnAMAADA8IRjAAAAhiccAwAAMDzhGAAAgOEJxwAAAAxPOAYAAGB4wjEAAADD27fsAgBYbwcvvGTZJWzZoYsetuwSAIBdZs8xAAAAwxOOAQAAGJ5wDAAAwPCEYwAAAIYnHAMAADA84RgAAIDhCccAAAAMTzgGAABgeMIxAAAAwxOOAQAAGJ5wDAAAwPCEYwAAAIa3qXBcVc+rqkNV1VV1l7np51TVO6vqsqp6T1XdYccqBQAAgB2y2T3Hr05y3yQfOWr6C5K8sLtvn+Q5SV6yuNIAAABgd2wqHHf3W7v78Py0qrppkrsnecVs0muSnFVVt1tsiQAAALCztnPM8VlJPt7dVyVJd3eSK5KcfawnV9UFVXV443bkyJFt/GkAAABYnF07IVd3X9zdBzZu+/fv360/DQAAANdoO+H4b5PcvKr2JUlVVaa9xlcsojAAAADYLSccjrv775K8N8ljZpMekeRwd39wEYUBAADAbtnspZxeUFWHkxxI8rtVtRGAH5/k8VV1WZILk5y/M2UCAADAztm3mSd19+OPM/0DSe690IoAAABgl+3aCbkAAABgrxKOAQAAGJ5wDAAAwPA2dcwxwEgOXnjJskvYskMXPWzZJQAArDR7jgEAABiecAwAAMDwhGMAAACGJxwDAAAwPOEYAACA4QnHAAAADE84BgAAYHjCMQAAAMMTjgEAABiecAwAAMDwhGMAAACGJxwDAAAwPOEYAACA4QnHAAAADE84BgAAYHj7ll0AAADr5eCFlyy7hC07dNHDll0CsGT2HAMAADA84RgAAIDhCccAAAAMTzgGAABgeMIxAAAAwxOOAQAAGJ5wDAAAwPCEYwAAAIYnHAMAADA84RgAAIDhCccAAAAMTzgGAABgePsW8Uuq6lCSLyb5p9mkZ3f3KxfxuwEAAGCnLSQczzyquy9d4O8DAACAXeFr1QAAAAxvkeH4ZVX1/qp6cVWdcfSDVXVBVR3euB05cmSBfxoAAABO3KLC8Xndfackd03y6SQvPfoJ3X1xdx/YuO3fv39BfxoAAAC2ZyHHHHf3FbN/v1xVv5LkskX8XgAAANgN295zXFWnVtWN5iY9OslfbPf3AgAAwG5ZxJ7jmyV5TVWdlKSSfDjJYxfwewEAAGBXbDscd/eHk5y7gFoAAABgKVzKCQAAgOEJxwAAAAxPOAYAAGB4wjEAAADDE44BAAAYnnAMAADA8IRjAAAAhiccAwAAMDzhGAAAgOEJxwAAAAxPOAYAAGB4+5ZdAADAMh288JJll3BCDl30sGWXwC5axfnUPMqqsecYAACA4QnHAAAADE84BgAAYHjCMQAAAMMTjgEAABiecAwAAMDwhGMAAACG5zrH7DrX6QPYHstRgO2xHOVY7DkGAABgeMIxAAAAwxOOAQAAGJ5wDAAAwPCEYwAAAIYnHAMAADA84RgAAIDhCccAAAAMTzgGAABgeMIxAAAAwxOOAQAAGJ5wDAAAwPAWEo6r6pyqemdVXVZV76mqOyzi9wIAAMBuWNSe4xckeWF33z7Jc5K8ZEG/FwAAAHbctsNxVd00yd2TvGI26TVJzqqq2233dwMAAMBuWMSe47OSfLy7r0qS7u4kVyQ5ewG/GwAAAHZcTVl2G7+g6m5JfrO7v2lu2ruTXNjdfzg37YIkF8y99Mwkn9jWH98d+5McWXYRO2zde9Tf6lv3HvW3+ta9R/2tvnXvcd37S9a/R/2tvlXp8YzuPuVYDywiHN80yQeT3Li7r6qqSvLxJPft7g9u65fvAVV1uLsPLLuOnbTuPepv9a17j/pbfeveo/5W37r3uO79Jevfo/5W3zr0uO2vVXf33yV5b5LHzCY9IsnhdQjGAAAAjGHfgn7P45O8pKqenuQfkpy/oN8LAAAAO24h4bi7P5Dk3ov4XXvQxcsuYBese4/6W33r3qP+Vt+696i/1bfuPa57f8n696i/1bfyPW77mGMAAABYdYu4lBMAAACsNOEYAACA4QnHAAAADE84BgAAYHjCMdeqqu647Bp2UlXda9k17LR1H0NWX1XdZtk17KSq+oZl17CTLGNWX1Wdsuwa2J6qqmXXwPZU1cnLrmEnrUJ/wvE2VNV5VfW4qjptdn/tFkpV9cYkl1TVfWb316bHqrpPVf1ukh+vqlOXXc9OqKr7VtXvJTm/qq6/7HoWbd3fg1V1/6r6P6rqzNn9tepvQ1W9NcnLNgLWOvVZVQ+oqnclefFsXt2/7JoWad2XMclXPyt+sapuvOxadsJsDP8gyX+qqn87m7Y278Hkq58V/6Gqbjq7v2793beq/nuSX6qq7192PTuhqu5dVQ9a18/D2WfFO5I8v6r+zbLrWbRV6m8h1zkezWzr6tOTPDPJ25N8LMklvUbXxaqqfd19VZIjSS5J8sNJ3rEOPVbV9ZI8J8m/TvKk7n7DkktauFnY/+Uk90/yzO5+9ZJLWqh1fw9W1b4kP5XkZ5P8WZJPJ/nVdelvQ1WdlOS6SSrJ+5J8X5L3r0ufVXW3JM/NNI5fSvLUJOdU1S909z8ss7btWvdlTJLMVsKfneSbk/xSd//9kktaqNmGmouS3CvJLyW5KsmrqupN3f3ZpRa3eE9NciDJJ7NGy9KqukGm9ZlvT/J/JjklySuq6vbd/dGlFrcgVXXzJL+Y5Nwk703ywCS3WZcxTJKq+o5My9NnZRrDC6vqJkle0t3/tNTiFmDV+rPn+MTsT3IoyR2TvDPJeVV1drI+W7K6+6rZCvqpSf4kyalzW5RXfb45fXb77Y1gXFV3rarTl1vWQh3ItEL3vI2V1qq6/eyDdB3m03V/D14vyWVJ7p3k5UnuUVV3Stbi/fdV3f3Psx8/mWk8z6mq70zWZhy/Icnfd/ebuvsPMq3EnpHkh5Za1WKs9TKmqs5K8uokZ3b3tx0d/le9v5nTk1za3ffo7lcmeWOmntfqGwCzdZkbJ3lzkrtU1V3npq+6M5J8Psm3dfcruvvFmTaoPmK5ZS1GVR1IcnGSK7r73O7+4STX2TgcbtXfh3P13zjJu7v7Dd3920mel+SeSR66tOIWYFX7W5uVrN3U3Z9J8jvd/f8m+d0kt8609TzrtCUryVlJ/jbJa5O8Ncn3VNUPJVnpYwNnW1Nfl+Qbq+q/zL7m8bQkf1pV37sOXw3s7g8keX2SO1bVs2c9/nyS91TVPVd9Pl3392B3H0nyh919aaaNU1/MtFc13f2V5VW2I85N8tEkL5z9+6Cqenim8LXqbpLk4xtfA8w0ln+aaWPH2csra/sGWMb8babx+pOqOqOqvr+qfqGqfriqTl71/pKkuz/S3S9Kkqp6SKYNVLdI8sqq+s51+CycbUw8Jclbkvw/mb6l8qDZwyu/LO3ujyR5YXd/uapOrul4zn/ItJxZed19OMlPdffPJklV/ViSzyb5lqq6/qq/D+fqP5hp3tzwukwbje+5yodzrGp/wvEJ6u5Pz/59S5IPJPn2ja2Ra+SzSW42W1E/kuQBSX4uyZWruvdqbivWH2Tq6dZJntLdj0ry/CSPS3LDJZW3EHM9/kaSWya5e5InJ/lfkvxOkv+4pNIWat3fg939P2f/vj/JezLtVf2Xy61qR3wiyfVn/X4uyY9k+urVl1d1r8Bc3X+a5C5J7lxVNfv62KWZvhmw509KcjzrvoyZ+3x7Wabe3pHkxzKFxx9L8oKquu5yqlu82XjeKMm/7u77JvmtTON52jLrWoTZxsQbJ3ng7Nsbb0zyHVX1tsw2OK667j40+/fLs0k3TbI2hwB098eq6qSqelymMfulJN+V5HlVddulFrdNc8vS1yd5eFV9S5LMDrv5kyR3SPKPy6lu+1a1v1rxjS47brZCc8z/pKq6Tnd/parukOn4xzcl+eMkt0vy1lXfw1NVD0ryhCQfT/LgTMd2npHkR2db81bSxphW1cEkn5w/3qGqPpTku7v7r5dW4BYdax6d6/FbkvzNRo+zrzz+VZLzuvuKJZS7ZYO/B+fn1X+faYPOyzMFrj/cCNB73bWM4Q8keXSSjyT5nkzz50eT/MwqH/c4N2/+fJJvTXJBd//N7LH/L8mjuvt9Sy1ykwZfxvy7TDtA/uvs/s2T/HWSu3X3h3axzG05Xo/XMP1DSb539u2cPe9axvBWSf5ddz+rql6b6ZjVdyd56Ow9etzX7iXX0uPG+/FBSZ7b3Xev6VCxb8l0vpg9/1l4beNQVTfr7k/Ofr5JpjF8THe/c7dq3K7jLEs3PitelGlj43f37JCjqjqU5EHd/eHdr3br1qW/ldz7t9Oq6seq6klVdfbGIB9rD8bGwmb24fG2TCdduTzJffbygqiqnlhVPze/l+04e2jem2mr+Ze6+5xMW5I/kuRuu1Ppibm2/jbGtLsPHRWM//ckf57pq+R72rXNo3M9/lV/7ckOfirJH2YKH3uW9+Bkfl7NFPp/MNOK+Z33ejDe7Bgm+R+Zjj06abac+ZkkN8h0PPmetYkx3FhB+LlMX998VlV9R1U9IdMJ5D61e9Vu3bovY5Kkqm6dHPtQjLleX7YRjGf+PtNXdK/a+Qq3ZzPvweP0/tRMn4Uf2Z1KT9w1jeGcU5M8s6quSPLBTN8Q+0ymjXJ7+lCcLXwWbvRwxySvq6rzk7wr00acPftZmGx6DLMRjGc/fzrTt3A+v6PFLcAWPgt/PMmZSX6xqu5SVRdk+nz8u10sd8vWsT97judU1S2TvCHJFZn20Nwgye939ws2tnwc53V3yLTH6n1JfnKvbQHZUNP3+t+UaaXlQ5n2Zry7u3+2qk7qq0+OM7+l54bd/fnZtJOSnNLdX1hG/ddmK/3Nvea6SX4gyU8k+Zskz9jYu7MXncg8WtNJRx6b5PzZ635mFrb2HO/Br59HZ6+7baYV8kuzh/tLtj6GNR0jd4ONsD+bX2/Qe/Rszie4HL1Nkock+d7Mzlrd3Zcvofxrte7LmOSr31Z4epL/mek41N/p7vdd03tw9rqHJnlGpuXME3u6osOec4JjeGqmMXxMpq+P7/XPwk2PYU1XN/jhTP8Hl8/WZR6V5PdmIWvP2cZn4ZsznX/j1Umetcc/K7b0PpwFrlMy7fn/mUyHU/14d1+5i2Vv2lbGcKPnqrpnku/MdKKqT2f6rPjgEsq/VmvdX3e7zW6ZjmX47dnPJ2e61M+HktxqNu06x3ndfZM8YO7+SZlteNhLtyTnJXnt3P27J7kyyTdv1H2c111nvvdMB9WvU38/meQ75/tddi/X0OOJzqPPTvJd82O47F4W3N+6vwdvm+S+e72/bY7h1y1nlt3LIsdw9tg3zve77F4WPH6rsoy5TaY92/dMcudMxy++baOvY9U9+8x7QaZjjx+87B52cAyfleQhc/f36jy65TGce+2+Zde/w2P4f+Wo9Zm9+F7cxvvwVzMd4re278PZY2fOj+Gyexmtv6UXsJdumbZmvD3JDTcGLNMZVF95nOcf68173BWjZd9mC6DLk9xobtrzk7z9Gl6z52baRfV3rN728vjN6tvqPPp1/ezlMfUe3NTv2LP9ncgYbjxn2XXv5BjmqBXyvTyGAyxj7pPksrn735jpjPcXHav2jWVMktuuUI/G8Nivq2u6v5duCxrDvbycOdH34cGjpu/l+fREPgtPuqb7e+m2zv0Ne8xxVd3sGJO/ktlZb5OvHs/4K0nOrqpvPur11+nZyM7u75u95rhfydoDvpBpy/fD56Y9NcmB2VcdvqpmZ+uc/R+kVuOSDlvqr7/2Kx+nJnt+/JKtz6PzX/G87txr9qq1eQ9W1f5jTN7ye3Du/vWTvdPfNdjSGM49Z+PQjb3uRJajV83uX292fy+P4bovYz6V5M+raqO/z2ba6/3wqrpFz07QNPf8jTH8UPL18+weZQznxnBuzHr+lxx9f49ZxBju5eXMib4PDyV77324iEwxe87GiapOmr+/R61tf8OF46p6UFW9JcmDj175zHQCqiuT3Keuvi7lFzJ9L/7k2etrPlhV1UOq6iVJjvXG2HWz/l5e07UY7zibtnHJkI9mOovofWp2AoRMM/c7Ml3q4Fj9PbiqfivTJY+Wbgf7u9WuNnINZj2+tqqevLGyPdfjdubRM3azj+PZwf72ynvwjKr6qyRPrKobzqZtfMiv/Hsw+er/+Rur6glVdZfZtI3l6XbG8MzsATu4nNkT14jfwfHbE8uY5OoNEcdwZabj4+5dV2/0/cskf5bpK57p7p7rcWNl7tyqOrCHVsaN4ebHcKPHc6tqz1w/3RiuxftwpzLFXvos3In1tT3R3/EME46r6mZV9apMZ7P9te5+xVF7Dqu7P5fkkiS3SPLEuZeflmmw05OvVNWtqurlmU7y8PTuXuqZOavqJlX135L8fKaFy7mZrtGYni4Of52eTqT1B0n+afa8ZJpBb53kw7PnHt3fj2S6APtf7W5HX2vd+0uSqjpz1uPPZpoPz0zykuRrevxcVnceXev+5twqyc2TnJPpMhpf/ZBf9Xk0SarqJ5JcnOR1ma6n+ZqqOrixPF3lMRxkObO245ckVXWwqv4oyXPqGN9E6OnyUn+a6fqa/3I27dNJTk9yePY7Tjqqx1dkOh73s7vUxjUyhsZw9hxjuCQDZIpR1teOrffAd7t345bkYZnOEnqgr/5u/I3nHt839/O9Mm0ReUOSTyZ5wtxjlenseu9Jcs9l9zVX132TvGDu/i2TvDXJvY7x3FtkWii9PtMlRS446vGnZbqMg/52t8dvT/LMufsPTfLcXH2szarPo2vd31x9d8p0+Z5XJbkoyekbda/6PDqr7blJvmfu/m9lOknKzY563sqN4SDLmXUev2/MtLL22kyX7LnnUY9vLGu+IclTMp11+pGZNnL8SZJz5p57UpJfzHRM3Z7p0RgaQ2O4/FvWP1MMsb523P6XXcAuD/YlmVZaHzd7o/1GpjP73fAYzz0j0wkDbnLU9FtlOk3+njsJQJKz536+baYVt1OP89xvyLRX6/Sjpt8401da9LfcXn8w05a3Nyd58dEfmLPnrNw8OkJ/mULRk5LcJdMexvslucfRy5lVnUdnPV04d/+2ma6n+V3HeO7KjeG6L2cGGL/7zf59fqYNVDeYe6zma850OZ/nJ3nFfI9JbpLk1zPt5diLPRpDY2gMl9/jWmeKuRrXdn3tuD0vu4BdHuC7JPlikv870xlH757kjUl+c/b4HZM8KMc4m1qyd89qeJxe7z1b+F5vbtrtM130/rr627u3JNdL8h+T3DXJqUlemunaccm0V3Kl59F17S9Xb1H9oSSPmP38ukzXcPxvs76/adXn0Uwnovrro957v5zk9as+hsfode2WM+s+fhsrYZn2Xn0wyQ8c4zk3mvv55PkeN37H/PS9djOGxnDZ9RvDMTJF1nR97dpuwxxznCTdfWmSB2dacX1fd/9Zpq1Vp82ecv8kV/ZRZ0/r7n/u2YjvdTU7Y2+mi6Qf6u4rZ8cO3CjJwSSHu/tL86/R394xO47jyu5+ene/t7v/MclzktxidtzO/bLC8+g69zdX362S3K+q/lOSb810/NRvd/eVmfYyXrHK82imsPjXmY5F2vDyXL0cXdkx3LDmy5m1Hr+ejm87qaez3/5akguqaqO3VNVjkvxoXX2Fgi/Ppn/1pD/d/ZWN6XuUMTSGe9oIY7jumWKd19euTa14/dtWVf8lyYe6+6Jl17JIVfWrmb7ycSDJTyd5Sne/erlVLc669zevqi5O8qXuvnDZteyEdeuvqh6f5JlJfqO7n1ZVT05yXpIf6e7PLLe6xaiqe2W6JuUPZlrJe26Sf+7un1xmXYu2rsuZUcYvSarqrZmOhbtVkkOZjin/x6UWtQDG0BiuknUdw6Ota6bYsG7ra8czXDiuqsq0y//8JP9rkg9lWuH51FILW6Carrf2vkynVH97pjPDHV5uVYszQH+VZH+Sf5vpQ/PyTMcmfWKphS3IAP3dNMlV3f33s/vXS7K/pzNxro3ZRoD7JLlbkvdnOiHVx5Zb1eIMsJxZ6/HbUFX/Ocm/z/TVxyd190dm07/mWveryBgaw1WxrmO47pli3dfXjme4cJwkVXXzTF8N+K/d/ZbZtFr1rwFsqKpvyLQAekZ3v3027TqZnVV9qcUtwLr3l0yn0U/yC0le0d1/NJu2TvPoWveXXH29yr76+n4rvRJwLLOvVt26uz84u782PQ6ynFnb8UuSqnpqpmM7f3qNlzPGcMUZw9U2QKZY+/W1ow0Zjo+2bguiebOtPqW/1bbO82iy/v2NYJ3HcITlzDqOX1XdsLs/P/t54wy5/3wtL1tZxnD1GcPVt45jOG/d+0sGD8frPsCzkyGs8wJorftLhphH17o/Vt8Iy5l1ZwxXnzFcfes+huu+PrPu/c0bOhwDAABAkrEu5QQAAADHIhwDAAAwPOEYAACA4QnHAAAADE84BgAAYHjCMQAAAMP7/wFEGxwv2rtpjQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "\n",
    "figure(figsize=(15, 6), dpi=80)\n",
    "plt.hist(joint, width=0.8)\n",
    "plt.xticks(rotation=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([13.,  0.,  9.,  0., 44.,  0., 42.,  0.,  9.,  6.]),\n",
       " array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ],\n",
       "       dtype=float32),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(errors_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0 1\n",
      "2.0 4\n",
      "2.0 5\n",
      "3.0 5\n",
      "3.0 1\n",
      "2.0 4\n",
      "2.0 4\n",
      "2.0 4\n",
      "5.0 1\n",
      "4.0 1\n",
      "3.0 1\n",
      "0.0 4\n",
      "2.0 0\n",
      "3.0 1\n",
      "4.0 1\n",
      "2.0 0\n",
      "3.0 1\n",
      "2.0 0\n",
      "5.0 1\n",
      "3.0 1\n",
      "2.0 4\n",
      "5.0 1\n",
      "3.0 1\n",
      "3.0 1\n",
      "0.0 5\n",
      "1.0 5\n",
      "2.0 4\n",
      "0.0 3\n",
      "0.0 4\n",
      "2.0 4\n",
      "1.0 4\n",
      "1.0 4\n",
      "3.0 1\n",
      "0.0 3\n",
      "3.0 1\n",
      "2.0 4\n",
      "0.0 2\n",
      "3.0 1\n",
      "0.0 4\n",
      "1.0 3\n",
      "4.0 1\n",
      "3.0 1\n",
      "0.0 4\n",
      "3.0 1\n",
      "2.0 4\n",
      "2.0 4\n",
      "3.0 5\n",
      "2.0 4\n",
      "4.0 1\n",
      "2.0 4\n",
      "2.0 4\n",
      "3.0 1\n",
      "3.0 1\n",
      "3.0 1\n",
      "3.0 1\n",
      "2.0 4\n",
      "2.0 0\n",
      "4.0 1\n",
      "2.0 4\n",
      "3.0 5\n",
      "0.0 4\n",
      "2.0 4\n",
      "0.0 4\n",
      "2.0 4\n",
      "2.0 4\n",
      "3.0 1\n",
      "2.0 4\n",
      "2.0 4\n",
      "3.0 1\n",
      "5.0 0\n",
      "3.0 1\n",
      "2.0 4\n",
      "2.0 4\n",
      "2.0 4\n",
      "0.0 5\n",
      "3.0 1\n",
      "2.0 4\n",
      "3.0 1\n",
      "3.0 1\n",
      "3.0 1\n",
      "2.0 4\n",
      "2.0 4\n",
      "3.0 5\n",
      "2.0 4\n",
      "3.0 1\n",
      "3.0 1\n",
      "1.0 4\n",
      "2.0 5\n",
      "3.0 5\n",
      "3.0 1\n",
      "2.0 0\n",
      "2.0 4\n",
      "3.0 0\n",
      "0.0 4\n",
      "1.0 4\n",
      "3.0 1\n",
      "3.0 5\n",
      "4.0 1\n",
      "3.0 1\n",
      "2.0 4\n",
      "3.0 1\n",
      "2.0 4\n",
      "3.0 1\n",
      "4.0 1\n",
      "3.0 5\n",
      "3.0 1\n",
      "3.0 1\n",
      "3.0 1\n",
      "2.0 4\n",
      "2.0 4\n",
      "4.0 1\n",
      "2.0 4\n",
      "3.0 1\n",
      "2.0 4\n",
      "0.0 2\n",
      "1.0 4\n",
      "2.0 4\n",
      "1.0 4\n",
      "4.0 1\n",
      "5.0 1\n",
      "2.0 4\n",
      "2.0 4\n",
      "1.0 4\n"
     ]
    }
   ],
   "source": [
    "for a, b in zip(errors_y, errors_y_):\n",
    "    print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './saved_model1115/resFeed1.pth'\n",
    "torch.save(model.state_dict(), PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================\n",
      "Optimizer details:\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "Learning rate: 0.0001\n",
      "Weight decay: 0.0001\n",
      "======================\n",
      "Accuracy: 0.5224274406332454\n",
      "Mae: 0.503957783641161\n",
      "F1 Score: 0.48083488925470447\n",
      "conf_matrix: [[ 18  86   8   0   0   0]\n",
      " [ 48 330  19   0   0   0]\n",
      " [ 15 230  51   0   0   0]\n",
      " [  0   0   0 104  44   1]\n",
      " [  0   0   0  52  65  20]\n",
      " [  0   0   0   6  14  26]]\n",
      "======================\n",
      "Doubling Dilution Accuracy: 0.9736147757255936\n",
      "AUC: 0.8179451489844314\n",
      "Sensitivity: 0.6830601092896175\n",
      "Specificity: 0.9528301886792453\n"
     ]
    }
   ],
   "source": [
    "testing_loader1 = DataLoader(dataset=testing_dataset, batch_size=1, num_workers=1, shuffle=True, drop_last=True)\n",
    "\n",
    "# Ensure the model is on the same device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "ic.disable()\n",
    "model.eval()\n",
    "pred_list = []\n",
    "target_list  = []\n",
    "mse_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_test, y_test, y_test_res in testing_loader1:\n",
    "        # Move input and target data to the correct device\n",
    "        x_test = x_test.to(device).float()\n",
    "        y_test = y_test.to(device).float()\n",
    "        y_test_res = y_test_res.to(device).float()\n",
    "        \n",
    "        # Forward pass\n",
    "        pred = model(x_test, y_test_res)\n",
    "        \n",
    "        # Append predictions and targets to lists\n",
    "        pred_list.append(np.argmax(pred.detach().cpu().numpy())) \n",
    "        target_list.append(y_test.detach().cpu().numpy())\n",
    "        \n",
    "# Flatten the target list\n",
    "target_list = np.array(target_list).flatten()\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, mean_absolute_error\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "def calculate_metrics(true_labels, predictions):\n",
    "    \"\"\"\n",
    "    Calculates accuracy, F1 score, confusion matrix, and MAE for the given true and predicted labels.\n",
    "\n",
    "    Parameters:\n",
    "    - true_labels: List or array of true labels\n",
    "    - predictions: List or array of predicted labels\n",
    "\n",
    "    Returns:\n",
    "    - accuracy: Overall accuracy of predictions\n",
    "    - f1: Weighted average F1 score\n",
    "    - conf_matrix: Multiclass confusion matrix\n",
    "    - mae: Mean Absolute Error of predictions\n",
    "    \"\"\"\n",
    "    # Ensure inputs are numpy arrays for consistency\n",
    "    true_labels = np.array(true_labels)\n",
    "    predictions = np.array(predictions)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "\n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "    # Calculate MAE\n",
    "    mae = mean_absolute_error(true_labels, predictions)\n",
    "\n",
    "    return accuracy, f1, conf_matrix, mae\n",
    "\n",
    "# Example usage\n",
    "# true_labels = [0, 1, 2, 1, 0, 2, 1, 0]\n",
    "# predictions = [0, 2, 2, 1, 0, 0, 1, 0]\n",
    "\n",
    "accuracy, f1, conf_matrix, mae = calculate_metrics(target_list, pred_list)\n",
    "\n",
    "print(\"======================\")\n",
    "# print(\"Model's Named Parameters:\")\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(f\"Name: {name}\")\n",
    "#     print(f\"Shape: {param.size()}\")\n",
    "#     print(f\"Requires grad: {param.requires_grad}\")\n",
    "#     print('-----')\n",
    "print(\"Optimizer details:\")\n",
    "print(optimizer)\n",
    "for param_group in optimizer.param_groups:\n",
    "    print(\"Learning rate:\", param_group['lr'])\n",
    "    print(\"Weight decay:\", param_group.get('weight_decay', 'Not set'))\n",
    "    \n",
    "print(\"======================\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Mae: {mae}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"conf_matrix: {conf_matrix}\")\n",
    "print(\"======================\")\n",
    "doubling_dilution_accuracy = np.mean([is_within_doubling_dilution(pred, true, target_min, target_max) for pred, true in zip(pred_list, target_list)])\n",
    "print(\"Doubling Dilution Accuracy:\", doubling_dilution_accuracy)\n",
    "\n",
    "\n",
    "# Calculate AUC\n",
    "cutoff = 4\n",
    "test_target_bi = (target_list >= cutoff).astype(int)\n",
    "test_predictions_bi = (np.array(pred_list) >= cutoff).astype(int)\n",
    "\n",
    "auc = roc_auc_score(test_target_bi, test_predictions_bi)\n",
    "print(\"AUC:\", auc)\n",
    "\n",
    "# Calculate confusion matrix components\n",
    "tn, fp, fn, tp = confusion_matrix(test_target_bi, test_predictions_bi).ravel()\n",
    "\n",
    "# Calculate sensitivity (recall)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "\n",
    "# Calculate specificity\n",
    "specificity = tn / (tn + fp)\n",
    "print(\"Specificity:\", specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypterparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 50/400 [02:56<20:30,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50\n",
      "Training loss: 0.1510869264602661\n",
      "Validation loss: 0.13646160066127777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 100/400 [05:52<17:28,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100\n",
      "Training loss: 0.12380748987197876\n",
      "Validation loss: 0.11622773110866547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 114/400 [06:41<16:51,  3.54s/it]"
     ]
    }
   ],
   "source": [
    "#input parameter\n",
    "for _ in [1e-4, 5e-4,1e-3, 5e-3,1e-2]:\n",
    "    lr = 1e-4\n",
    "    epoch = 400\n",
    "    conv_dropout_rate=0.4\n",
    "    dense_dropout_rate=0.7\n",
    "    weight_decay= _ #1e-4\n",
    "    ######################################\n",
    "\n",
    "    model = Model(\n",
    "    num_classes=6,\n",
    "    num_filters=64,\n",
    "    num_conv_layers=2,\n",
    "    # num_dense_neurons=256, # batch_size = 64\n",
    "    num_dense_neurons=128, # batch_size = 64\n",
    "    num_dense_layers=2,\n",
    "    return_logits=False,\n",
    "    conv_dropout_rate=conv_dropout_rate,\n",
    "    dense_dropout_rate=dense_dropout_rate\n",
    "    ).to(device)\n",
    "\n",
    "    # model = Model( #! way too memory intensive\n",
    "    # num_classes=13,\n",
    "    # num_filters=128,\n",
    "    # num_conv_layers=2,\n",
    "    # num_dense_neurons=64, # batch_size = 64\n",
    "\n",
    "    # num_dense_layers=2,\n",
    "    # return_logits=True,\n",
    "    # conv_dropout_rate=0,\n",
    "    # dense_dropout_rate=0\n",
    "    # ).to(device)\n",
    "    ## early stopping\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 8  # How many epochs to wait after last time validation loss improved.\n",
    "    patience_counter = 0\n",
    "    lmbda = torch.tensor(1e-4, dtype = torch.float32)\n",
    "\n",
    "    batch_size = 64\n",
    "    # lr = 0.0085\n",
    "    # lr = 0.00002\n",
    "    lr = lr\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True ,num_workers=8, drop_last=True)\n",
    "    test_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, num_workers=8, shuffle=True, drop_last=True)\n",
    "\n",
    "    # train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_padded_batch ,num_workers=8, drop_last=True)\n",
    "    # test_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, collate_fn=collate_padded_batch, num_workers=8, shuffle=True, drop_last=True)\n",
    "    # criterion = nn.MSELoss()\n",
    "    # criterion = masked_weighted_MAE\n",
    "    # criterion = masked_weighted_MSE\n",
    "    criterion = weighted_cross_entropy_loss_fn\n",
    "    # criterion = masked_MAE\n",
    "\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr,  weight_decay=weight_decay)\n",
    "    # scheduler = CyclicLR(optimizer, base_lr=1e-8, max_lr=1e-4, step_size_up=200, mode='triangular', cycle_momentum=False)\n",
    "\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    # optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbo\n",
    "    #%%\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    import gc; gc.collect()\n",
    "    # ic.enable()\n",
    "    ic.disable()\n",
    "\n",
    "    train_epoch_loss = []\n",
    "    test_epoch_loss = []\n",
    "\n",
    "    for e in tqdm(range(1, epoch+1)):\n",
    "        model.train()\n",
    "        train_batch_loss = []\n",
    "        test_batch_loss = []\n",
    "        # print(f'Epoch {e}')\n",
    "        for x_train, y_train, y_train_res in train_loader:\n",
    "            x_batch = torch.squeeze(x_train, 0).to(device)\n",
    "            y_batch = y_train.to(device)\n",
    "            y_batch_res = y_train_res.to(device)\n",
    "            \n",
    "            x_batch = x_batch.float()\n",
    "            pred = model(x_batch.float(),y_batch_res.float())\n",
    "\n",
    "            # break\n",
    "            # loss_train = loss_corn(pred, y_batch, 3, class_weights)\n",
    "            # print(pred, y_batch)\n",
    "            loss_train = criterion(pred,y_batch)\n",
    "            # print(pred)\n",
    "            # print(y_batch)\n",
    "            # print(loss_train)\n",
    "            train_batch_loss.append(loss_train)        \n",
    "            optimizer.zero_grad()\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "            # scheduler.step()  # Update the learning rate\n",
    "            # break\n",
    "        train_epoch_loss.append(torch.mean(torch.stack(train_batch_loss)).detach().cpu().numpy())\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # print('>> test')\n",
    "            for x_test, y_test, y_test_res in test_loader:\n",
    "                x_batch = torch.squeeze(x_test, 0).to(device)\n",
    "                x_batch = x_batch.float()\n",
    "                y_batch = y_test.to(device)\n",
    "                y_batch_res = y_test_res.to(device)\n",
    "                # print(x_batch.size())\n",
    "                # y_batch = torch.Tensor.float(y).to(device)\n",
    "                # x_batch = x_batch.permute(0, 3, 1, 2).to(device)\n",
    "                pred = model(x_batch.float(), y_batch_res.float())\n",
    "                loss_test = criterion(pred,y_batch)\n",
    "                # pred = pred.unsqueeze(0)\n",
    "                # print(pred[:10])\n",
    "                # print(y_batch[:10])\n",
    "\n",
    "                # loss_test = loss_corn(pred, y_batch, 3, class_weights)\n",
    "                test_batch_loss.append(loss_test)\n",
    "            test_epoch_loss.append(torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy())\n",
    "        if e%50 == 0:\n",
    "            print(f'Epoch {e}')\n",
    "            print(f\"Training loss: {torch.mean(torch.stack(train_batch_loss)).detach().cpu().numpy()}\")\n",
    "            print(f\"Validation loss: {torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy()}\") \n",
    "        # scheduler.step(torch.mean(torch.stack(test_batch_loss)))\n",
    "        # print(train_batch_loss)\n",
    "        # print(test_batch_loss)\n",
    "        # print(f\"Training loss: {np.mean(train_batch_loss)}\")\n",
    "        # print(f\"Validation loss: {np.mean(test_batch_loss)}\")\n",
    "        # #! implementing early stopping\n",
    "        # current_val_loss = torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy()\n",
    "        # print(f'Current val loss: {current_val_loss}')\n",
    "        # print(f'Best val loss: {best_val_loss}')\n",
    "        # if current_val_loss < best_val_loss:\n",
    "        #     best_val_loss = current_val_loss\n",
    "        #     patience_counter = 0  # reset patience counter\n",
    "        #     # Save the best model\n",
    "        #     # torch.save(model.state_dict(), '/mnt/storageG1/lwang/Projects/tb_dr_MIC/saved_models/aa-model_final.pth')\n",
    "\n",
    "        # else:\n",
    "        #     patience_counter += 1\n",
    "        #     if patience_counter >= patience:\n",
    "        #         print(\"Early stopping triggered\")\n",
    "        #         torch.save({\n",
    "        #         'optimizer': optimizer.state_dict(),\n",
    "        #         'model': model.state_dict(),\n",
    "        #     }, '/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/saved_models/aa-model_weighted_balanced_binned_aa_newdata.pth')\n",
    "        #         break  # Early stopping\n",
    "            \n",
    "    print('==='*10)\n",
    "    # torch.save(model.state_dict(), '/mnt/storageG1/lwang/Projects/tb_dr_MIC/saved_models/final_seq_model1-44ep.pt')\n",
    "    save_to_file('trials3.txt', 'aa-training_weighted_balanced_ce-binned-EMB_newdata_corn_corn' ,epoch, lr=lr, fcdr=dense_dropout_rate, l2=weight_decay, cnndr=conv_dropout_rate, \n",
    "                train_loss = train_epoch_loss, test_loss = test_epoch_loss, optimizer=optimizer, model = model)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    x = np.arange(1, epoch+1, 1)\n",
    "    ax.plot(x, train_epoch_loss,label='Training')\n",
    "    ax.plot(x, test_epoch_loss,label='Validation')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(\"Number of Epoch\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_xticks(np.arange(0, epoch+1, 10))\n",
    "    ax.set_title(f'Loss: Learning_rate:{lr}')\n",
    "    # ax_2 = ax.twinx()\n",
    "    # ax_2.plot(history[\"lr\"], \"k--\", lw=1)\n",
    "    # ax_2.set_yscale(\"log\")\n",
    "    # ax.set_ylim(ax.get_ylim()[0], history[\"training_losses\"][0])\n",
    "    ax.grid(axis=\"x\")\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "    fig.savefig(f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/graphs3/aa-loss_lr_{lr}_weighted_balanced-emb.png')\n",
    "    print(f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/graphs3/aa-loss_lr_{lr}_weighted_balanced.png-emb')\n",
    "\n",
    "    #%%\n",
    "    # testing_dataset = Dataset(test_data, test_target, 'EMB_MIC_x','EMB_MIC_y',one_hot_dtype=torch.float, transform=False)\n",
    "    testing_loader1 = DataLoader(dataset=testing_dataset, batch_size=1, num_workers=1, shuffle=True, drop_last=True)\n",
    "\n",
    "    # Ensure the model is on the same device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    ic.disable()\n",
    "    model.eval()\n",
    "    pred_list = []\n",
    "    target_list  = []\n",
    "    mse_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_test, y_test, y_test_res in testing_loader1:\n",
    "            # Move input and target data to the correct device\n",
    "            x_test = x_test.to(device).float()\n",
    "            y_test = y_test.to(device).float()\n",
    "            y_test_res = y_test_res.to(device).float()\n",
    "            \n",
    "            # Forward pass\n",
    "            pred = model(x_test, y_test_res)\n",
    "            \n",
    "            # Append predictions and targets to lists\n",
    "            pred_list.append(np.argmax(pred.detach().cpu().numpy())) \n",
    "            target_list.append(y_test.detach().cpu().numpy())\n",
    "            \n",
    "    # Flatten the target list\n",
    "    target_list = np.array(target_list).flatten()\n",
    "\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, mean_absolute_error\n",
    "    from sklearn.metrics import roc_auc_score, confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "    def calculate_metrics(true_labels, predictions):\n",
    "        \"\"\"\n",
    "        Calculates accuracy, F1 score, confusion matrix, and MAE for the given true and predicted labels.\n",
    "\n",
    "        Parameters:\n",
    "        - true_labels: List or array of true labels\n",
    "        - predictions: List or array of predicted labels\n",
    "\n",
    "        Returns:\n",
    "        - accuracy: Overall accuracy of predictions\n",
    "        - f1: Weighted average F1 score\n",
    "        - conf_matrix: Multiclass confusion matrix\n",
    "        - mae: Mean Absolute Error of predictions\n",
    "        \"\"\"\n",
    "        # Ensure inputs are numpy arrays for consistency\n",
    "        true_labels = np.array(true_labels)\n",
    "        predictions = np.array(predictions)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_score(true_labels, predictions)\n",
    "\n",
    "        # Calculate F1 score\n",
    "        f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "        # Calculate confusion matrix\n",
    "        conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "        # Calculate MAE\n",
    "        mae = mean_absolute_error(true_labels, predictions)\n",
    "\n",
    "        return accuracy, f1, conf_matrix, mae\n",
    "\n",
    "    # Example usage\n",
    "    # true_labels = [0, 1, 2, 1, 0, 2, 1, 0]\n",
    "    # predictions = [0, 2, 2, 1, 0, 0, 1, 0]\n",
    "\n",
    "    accuracy, f1, conf_matrix, mae = calculate_metrics(target_list, pred_list)\n",
    "\n",
    "    print(\"======================\")\n",
    "    # print(\"Model's Named Parameters:\")\n",
    "    # for name, param in model.named_parameters():\n",
    "    #     print(f\"Name: {name}\")\n",
    "    #     print(f\"Shape: {param.size()}\")\n",
    "    #     print(f\"Requires grad: {param.requires_grad}\")\n",
    "    #     print('-----')\n",
    "    print(\"Optimizer details:\")\n",
    "    print(optimizer)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        print(\"Learning rate:\", param_group['lr'])\n",
    "        print(\"Weight decay:\", param_group.get('weight_decay', 'Not set'))\n",
    "        \n",
    "    print(\"======================\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Mae: {mae}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    print(f\"conf_matrix: {conf_matrix}\")\n",
    "    print(\"======================\")\n",
    "    doubling_dilution_accuracy = np.mean([is_within_doubling_dilution(pred, true, target_min, target_max) for pred, true in zip(pred_list, target_list)])\n",
    "    print(\"Doubling Dilution Accuracy:\", doubling_dilution_accuracy)\n",
    "\n",
    "\n",
    "    # Calculate AUC\n",
    "    cutoff = 4\n",
    "    test_target_bi = (target_list >= cutoff).astype(int)\n",
    "    test_predictions_bi = (np.array(pred_list) >= cutoff).astype(int)\n",
    "\n",
    "    auc = roc_auc_score(test_target_bi, test_predictions_bi)\n",
    "    print(\"AUC:\", auc)\n",
    "\n",
    "    # Calculate confusion matrix components\n",
    "    tn, fp, fn, tp = confusion_matrix(test_target_bi, test_predictions_bi).ravel()\n",
    "\n",
    "    # Calculate sensitivity (recall)\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    print(\"Sensitivity:\", sensitivity)\n",
    "\n",
    "    # Calculate specificity\n",
    "    specificity = tn / (tn + fp)\n",
    "    print(\"Specificity:\", specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One cycle lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 50/400 [02:28<17:21,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50\n",
      "Training loss: 0.11537401378154755\n",
      "Validation loss: 0.14441072940826416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 100/400 [04:58<14:56,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100\n",
      "Training loss: 0.11210744082927704\n",
      "Validation loss: 0.1536770612001419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 150/400 [07:28<12:28,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150\n",
      "Training loss: 0.11056072264909744\n",
      "Validation loss: 0.16507422924041748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 200/400 [09:57<09:53,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200\n",
      "Training loss: 0.1097438856959343\n",
      "Validation loss: 0.17116251587867737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 250/400 [12:32<07:39,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250\n",
      "Training loss: 0.10918270796537399\n",
      "Validation loss: 0.1748015433549881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 300/400 [15:02<04:53,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300\n",
      "Training loss: 0.10868095606565475\n",
      "Validation loss: 0.17704497277736664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 350/400 [17:41<02:47,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 350\n",
      "Training loss: 0.10827459394931793\n",
      "Validation loss: 0.18684180080890656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [20:27<00:00,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400\n",
      "Training loss: 0.10818441957235336\n",
      "Validation loss: 0.17728930711746216\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/graphs3/aa-loss_lr_1e-07_weighted_balanced.png-emb\n",
      "======================\n",
      "Optimizer details:\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    base_momentum: 0.85\n",
      "    betas: (0.9499999993756804, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.0004\n",
      "    lr: 4.006243171376002e-08\n",
      "    max_lr: 0.01\n",
      "    max_momentum: 0.95\n",
      "    maximize: False\n",
      "    min_lr: 4e-08\n",
      "    weight_decay: 0\n",
      ")\n",
      "Learning rate: 4.006243171376002e-08\n",
      "Weight decay: 0\n",
      "======================\n",
      "Accuracy: 0.47568523430592397\n",
      "Mae: 0.6578249336870027\n",
      "F1 Score: 0.44584107920478183\n",
      "conf_matrix: [[ 34  66   7   3   1   1]\n",
      " [ 63 285  32   9   5   0]\n",
      " [ 40 188  41  19   3   2]\n",
      " [  4  20   7  75  42   1]\n",
      " [  2   8   0  34  77  16]\n",
      " [  0   3   0   5  12  26]]\n",
      "======================\n",
      "Doubling Dilution Accuracy: 0.8992042440318302\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#input parameter\n",
    "lr = 1e-7\n",
    "epoch = 400\n",
    "conv_dropout_rate=0\n",
    "dense_dropout_rate=0\n",
    "# weight_decay=1e-8\n",
    "weight_decay=0\n",
    "\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience = 8  # How many epochs to wait after last time validation loss improved.\n",
    "patience_counter = 0\n",
    "lmbda = torch.tensor(1e-4, dtype = torch.float32)\n",
    "\n",
    "batch_size = 128\n",
    "# lr = 0.0085\n",
    "# lr = 0.00002\n",
    "lr = lr\n",
    "######################################\n",
    "\n",
    "model = Model(\n",
    "num_classes=6,\n",
    "num_filters=64,\n",
    "num_conv_layers=2,\n",
    "# num_dense_neurons=256, # batch_size = 64\n",
    "num_dense_neurons=128, # batch_size = 64\n",
    "num_dense_layers=2,\n",
    "return_logits=False,\n",
    "conv_dropout_rate=conv_dropout_rate,\n",
    "dense_dropout_rate=dense_dropout_rate\n",
    ").to(device)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True ,num_workers=8, drop_last=True)\n",
    "test_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, num_workers=8, shuffle=True, drop_last=True)\n",
    "\n",
    "criterion = weighted_cross_entropy_loss_fn\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr,  weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01, steps_per_epoch=len(train_loader), epochs=epoch)\n",
    "# model = Model( #! way too memory intensive\n",
    "# num_classes=13,\n",
    "# num_filters=128,\n",
    "# num_conv_layers=2,\n",
    "# num_dense_neurons=64, # batch_size = 64\n",
    "\n",
    "# num_dense_layers=2,\n",
    "# return_logits=True,\n",
    "# conv_dropout_rate=0,\n",
    "# dense_dropout_rate=0\n",
    "# ).to(device)\n",
    "## early stopping\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_padded_batch ,num_workers=8, drop_last=True)\n",
    "# test_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, collate_fn=collate_padded_batch, num_workers=8, shuffle=True, drop_last=True)\n",
    "# criterion = nn.MSELoss()\n",
    "# criterion = masked_weighted_MAE\n",
    "# criterion = masked_weighted_MSE\n",
    "# criterion = weighted_cross_entropy_loss_fn\n",
    "\n",
    "\n",
    "# criterion = masked_MAE\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# scheduler = CyclicLR(optimizer, base_lr=1e-8, max_lr=1e-4, step_size_up=200, mode='triangular', cycle_momentum=False)\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbo\n",
    "#%%\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "import gc; gc.collect()\n",
    "# ic.enable()\n",
    "ic.disable()\n",
    "\n",
    "train_epoch_loss = []\n",
    "test_epoch_loss = []\n",
    "\n",
    "for e in tqdm(range(1, epoch+1)):\n",
    "    model.train()\n",
    "    train_batch_loss = []\n",
    "    test_batch_loss = []\n",
    "    # print(f'Epoch {e}')\n",
    "    for x_train, y_train in train_loader:\n",
    "        x_batch = torch.squeeze(x_train, 0).to(device)\n",
    "        y_batch = y_train.to(device)\n",
    "        x_batch = x_batch.float()\n",
    "        pred = model(x_batch.float())\n",
    "\n",
    "        # break\n",
    "        loss_train = criterion(pred,y_batch)\n",
    "\n",
    "        train_batch_loss.append(loss_train)        \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update the learning rate\n",
    "\n",
    "    train_epoch_loss.append(torch.mean(torch.stack(train_batch_loss)).detach().cpu().numpy())\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # print('>> test')\n",
    "        for x_test, y_test in test_loader:\n",
    "            x_batch = torch.squeeze(x_test, 0).to(device)\n",
    "            x_batch = x_batch.float()\n",
    "            y_batch = y_test.to(device)\n",
    "            # print(x_batch.size())\n",
    "            # y_batch = torch.Tensor.float(y).to(device)\n",
    "            # x_batch = x_batch.permute(0, 3, 1, 2).to(device)\n",
    "            pred = model(x_batch.float())\n",
    "\n",
    "            # pred = pred.unsqueeze(0)\n",
    "            # print(pred[:10])\n",
    "            # print(y_batch[:10])\n",
    "\n",
    "            loss_test = criterion(pred,y_batch)\n",
    "            test_batch_loss.append(loss_test)\n",
    "        test_epoch_loss.append(torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy())\n",
    "    if e % 50 == 0:\n",
    "        print(f'Epoch {e}')\n",
    "        print(f\"Training loss: {torch.mean(torch.stack(train_batch_loss)).detach().cpu().numpy()}\")\n",
    "        print(f\"Validation loss: {torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy()}\") \n",
    "    # scheduler.step(torch.mean(torch.stack(test_batch_loss)))\n",
    "    # print(train_batch_loss)\n",
    "    # print(test_batch_loss)\n",
    "    # print(f\"Training loss: {np.mean(train_batch_loss)}\")\n",
    "    # print(f\"Validation loss: {np.mean(test_batch_loss)}\")\n",
    "    # #! implementing early stopping\n",
    "    # current_val_loss = torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy()\n",
    "    # print(f'Current val loss: {current_val_loss}')\n",
    "    # print(f'Best val loss: {best_val_loss}')\n",
    "    # if current_val_loss < best_val_loss:\n",
    "    #     best_val_loss = current_val_loss\n",
    "    #     patience_counter = 0  # reset patience counter\n",
    "    #     # Save the best model\n",
    "    #     # torch.save(model.state_dict(), '/mnt/storageG1/lwang/Projects/tb_dr_MIC/saved_models/aa-model_final.pth')\n",
    "\n",
    "    # else:\n",
    "    #     patience_counter += 1\n",
    "    #     if patience_counter >= patience:\n",
    "    #         print(\"Early stopping triggered\")\n",
    "    #         torch.save({\n",
    "    #         'optimizer': optimizer.state_dict(),\n",
    "    #         'model': model.state_dict(),\n",
    "    #     }, '/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/saved_models/aa-model_weighted_balanced_binned_aa_newdata.pth')\n",
    "    #         break  # Early stopping\n",
    "        \n",
    "print('==='*10)\n",
    "# torch.save(model.state_dict(), '/mnt/storageG1/lwang/Projects/tb_dr_MIC/saved_models/final_seq_model1-44ep.pt')\n",
    "save_to_file('trials3.txt', 'aa-training_weighted_balanced_ce-binned-EMB_newdata_corn' ,epoch, lr=lr, fcdr=dense_dropout_rate, l2=weight_decay, cnndr=conv_dropout_rate, \n",
    "             train_loss = train_epoch_loss, test_loss = test_epoch_loss, optimizer=optimizer, model = model)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x = np.arange(1, epoch+1, 1)\n",
    "ax.plot(x, train_epoch_loss,label='Training')\n",
    "ax.plot(x, test_epoch_loss,label='Validation')\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Number of Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_xticks(np.arange(0, epoch+1, 10))\n",
    "ax.set_title(f'Loss: Learning_rate:{lr}')\n",
    "# ax_2 = ax.twinx()\n",
    "# ax_2.plot(history[\"lr\"], \"k--\", lw=1)\n",
    "# ax_2.set_yscale(\"log\")\n",
    "# ax.set_ylim(ax.get_ylim()[0], history[\"training_losses\"][0])\n",
    "ax.grid(axis=\"x\")\n",
    "fig.tight_layout()\n",
    "fig.show()\n",
    "fig.savefig(f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/graphs3/aa-loss_lr_{lr}_weighted_balanced-emb.png')\n",
    "print(f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/graphs3/aa-loss_lr_{lr}_weighted_balanced.png-emb')\n",
    "\n",
    "#%%\n",
    "\n",
    "model.eval()  # For inference\n",
    "\n",
    "ic.disable()\n",
    "model.eval()\n",
    "pred_list = []\n",
    "target_list  = []\n",
    "mse_list = []\n",
    "with torch.no_grad():\n",
    "    for x_test, y_test in testing_loader1:\n",
    "        xtest1 = x_test.to(device).float()\n",
    "        ytest1 = y_test.to(device).float()\n",
    "        pred = model(xtest1)\n",
    "        pred_list.append(np.argmax(pred.detach().cpu().numpy())) \n",
    "        target_list.append(y_test.detach().cpu().numpy())\n",
    "target_list = np.array(target_list).flatten()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, mean_absolute_error\n",
    "\n",
    "def calculate_metrics(true_labels, predictions):\n",
    "    \"\"\"\n",
    "    Calculates accuracy, F1 score, confusion matrix, and MAE for the given true and predicted labels.\n",
    "\n",
    "    Parameters:\n",
    "    - true_labels: List or array of true labels\n",
    "    - predictions: List or array of predicted labels\n",
    "\n",
    "    Returns:\n",
    "    - accuracy: Overall accuracy of predictions\n",
    "    - f1: Weighted average F1 score\n",
    "    - conf_matrix: Multiclass confusion matrix\n",
    "    - mae: Mean Absolute Error of predictions\n",
    "    \"\"\"\n",
    "    # Ensure inputs are numpy arrays for consistency\n",
    "    true_labels = np.array(true_labels)\n",
    "    predictions = np.array(predictions)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "\n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "    # Calculate MAE\n",
    "    mae = mean_absolute_error(true_labels, predictions)\n",
    "\n",
    "    return accuracy, f1, conf_matrix, mae\n",
    "\n",
    "# Example usage\n",
    "# true_labels = [0, 1, 2, 1, 0, 2, 1, 0]\n",
    "# predictions = [0, 2, 2, 1, 0, 0, 1, 0]\n",
    "\n",
    "accuracy, f1, conf_matrix, mae = calculate_metrics(target_list, pred_list)\n",
    "\n",
    "print(\"======================\")\n",
    "# print(\"Model's Named Parameters:\")\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(f\"Name: {name}\")\n",
    "#     print(f\"Shape: {param.size()}\")\n",
    "#     print(f\"Requires grad: {param.requires_grad}\")\n",
    "#     print('-----')\n",
    "print(\"Optimizer details:\")\n",
    "print(optimizer)\n",
    "for param_group in optimizer.param_groups:\n",
    "    print(\"Learning rate:\", param_group['lr'])\n",
    "    print(\"Weight decay:\", param_group.get('weight_decay', 'Not set'))\n",
    "    \n",
    "print(\"======================\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Mae: {mae}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"conf_matrix: {conf_matrix}\")\n",
    "print(\"======================\")\n",
    "doubling_dilution_accuracy = np.mean([is_within_doubling_dilution(pred, true, target_min, target_max) for pred, true in zip(pred_list, target_list)])\n",
    "print(\"Doubling Dilution Accuracy:\", doubling_dilution_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cyclical lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input parameter\n",
    "lr = 1e-7\n",
    "epoch = 250\n",
    "conv_dropout_rate=0.05\n",
    "dense_dropout_rate=0.5\n",
    "weight_decay=1e-8\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=1e-9, max_lr=0.001)\n",
    "######################################\n",
    "\n",
    "model = Model(\n",
    "num_classes=3,\n",
    "num_filters=64,\n",
    "num_conv_layers=2,\n",
    "# num_dense_neurons=256, # batch_size = 64\n",
    "num_dense_neurons=128, # batch_size = 64\n",
    "num_dense_layers=2,\n",
    "return_logits=False,\n",
    "conv_dropout_rate=conv_dropout_rate,\n",
    "dense_dropout_rate=dense_dropout_rate\n",
    ").to(device)\n",
    "\n",
    "# model = Model( #! way too memory intensive\n",
    "# num_classes=13,\n",
    "# num_filters=128,\n",
    "# num_conv_layers=2,\n",
    "# num_dense_neurons=64, # batch_size = 64\n",
    "\n",
    "# num_dense_layers=2,\n",
    "# return_logits=True,\n",
    "# conv_dropout_rate=0,\n",
    "# dense_dropout_rate=0\n",
    "# ).to(device)\n",
    "## early stopping\n",
    "best_val_loss = float('inf')\n",
    "patience = 8  # How many epochs to wait after last time validation loss improved.\n",
    "patience_counter = 0\n",
    "lmbda = torch.tensor(1e-4, dtype = torch.float32)\n",
    "\n",
    "batch_size = 128\n",
    "# lr = 0.0085\n",
    "# lr = 0.00002\n",
    "lr = lr\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True ,num_workers=8, drop_last=True)\n",
    "test_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, num_workers=8, shuffle=True, drop_last=True)\n",
    "\n",
    "# train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_padded_batch ,num_workers=8, drop_last=True)\n",
    "# test_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, collate_fn=collate_padded_batch, num_workers=8, shuffle=True, drop_last=True)\n",
    "# criterion = nn.MSELoss()\n",
    "# criterion = masked_weighted_MAE\n",
    "# criterion = masked_weighted_MSE\n",
    "# criterion = weighted_cross_entropy_loss_fn\n",
    "# criterion = masked_MAE\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr,  weight_decay=weight_decay)\n",
    "# scheduler = CyclicLR(optimizer, base_lr=1e-8, max_lr=1e-4, step_size_up=200, mode='triangular', cycle_momentum=False)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbo\n",
    "#%%\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "import gc; gc.collect()\n",
    "# ic.enable()\n",
    "ic.disable()\n",
    "\n",
    "train_epoch_loss = []\n",
    "test_epoch_loss = []\n",
    "\n",
    "for e in tqdm(range(1, epoch+1)):\n",
    "    model.train()\n",
    "    train_batch_loss = []\n",
    "    test_batch_loss = []\n",
    "    # print(f'Epoch {e}')\n",
    "    for x_train, y_train in train_loader:\n",
    "        x_batch = torch.squeeze(x_train, 0).to(device)\n",
    "        y_batch = y_train.to(device)\n",
    "        x_batch = x_batch.float()\n",
    "        pred = model(x_batch.float())\n",
    "\n",
    "        # break\n",
    "        loss_train = criterion(pred,y_batch)\n",
    "\n",
    "        train_batch_loss.append(loss_train)\n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        # scheduler.step()  # Update the learning rate\n",
    "\n",
    "    train_epoch_loss.append(torch.mean(torch.stack(train_batch_loss)).detach().cpu().numpy())\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # print('>> test')\n",
    "        for x_test, y_test in test_loader:\n",
    "            x_batch = torch.squeeze(x_test, 0).to(device)\n",
    "            x_batch = x_batch.float()\n",
    "            y_batch = y_test.to(device)\n",
    "            # print(x_batch.size())\n",
    "            # y_batch = torch.Tensor.float(y).to(device)\n",
    "            # x_batch = x_batch.permute(0, 3, 1, 2).to(device)\n",
    "            pred = model(x_batch.float())\n",
    "            loss_test = loss_corn(pred, y_batch, 3, class_weights)\n",
    "\n",
    "            # pred = pred.unsqueeze(0)\n",
    "            # print(pred[:10])\n",
    "            # print(y_batch[:10])\n",
    "\n",
    "            test_batch_loss.append(loss_test)\n",
    "        test_epoch_loss.append(torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy())\n",
    "\n",
    "    print(f'Epoch {e}')\n",
    "    print(f\"Training loss: {torch.mean(torch.stack(train_batch_loss)).detach().cpu().numpy()}\")\n",
    "    print(f\"Validation loss: {torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy()}\") \n",
    "    # scheduler.step(torch.mean(torch.stack(test_batch_loss)))\n",
    "    # print(train_batch_loss)\n",
    "    # print(test_batch_loss)\n",
    "    # print(f\"Training loss: {np.mean(train_batch_loss)}\")\n",
    "    # print(f\"Validation loss: {np.mean(test_batch_loss)}\")\n",
    "    # #! implementing early stopping\n",
    "    # current_val_loss = torch.mean(torch.stack(test_batch_loss)).detach().cpu().numpy()\n",
    "    # print(f'Current val loss: {current_val_loss}')\n",
    "    # print(f'Best val loss: {best_val_loss}')\n",
    "    # if current_val_loss < best_val_loss:\n",
    "    #     best_val_loss = current_val_loss\n",
    "    #     patience_counter = 0  # reset patience counter\n",
    "    #     # Save the best model\n",
    "    #     # torch.save(model.state_dict(), '/mnt/storageG1/lwang/Projects/tb_dr_MIC/saved_models/aa-model_final.pth')\n",
    "\n",
    "    # else:\n",
    "    #     patience_counter += 1\n",
    "    #     if patience_counter >= patience:\n",
    "    #         print(\"Early stopping triggered\")\n",
    "    #         torch.save({\n",
    "    #         'optimizer': optimizer.state_dict(),\n",
    "    #         'model': model.state_dict(),\n",
    "    #     }, '/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/saved_models/aa-model_weighted_balanced_binned_aa_newdata.pth')\n",
    "    #         break  # Early stopping\n",
    "        \n",
    "print('==='*10)\n",
    "# torch.save(model.state_dict(), '/mnt/storageG1/lwang/Projects/tb_dr_MIC/saved_models/final_seq_model1-44ep.pt')\n",
    "save_to_file('trials3.txt', 'aa-training_weighted_balanced_ce-binned-EMB_newdata_corn' ,epoch, lr=lr, fcdr=dense_dropout_rate, l2=weight_decay, cnndr=conv_dropout_rate, \n",
    "             train_loss = train_epoch_loss, test_loss = test_epoch_loss, optimizer=optimizer, model = model)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x = np.arange(1, epoch+1, 1)\n",
    "ax.plot(x, train_epoch_loss,label='Training')\n",
    "# ax.plot(x, test_epoch_loss,label='Validation')\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Number of Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_xticks(np.arange(0, epoch+1, 10))\n",
    "ax.set_title(f'Loss: Learning_rate:{lr}')\n",
    "# ax_2 = ax.twinx()\n",
    "# ax_2.plot(history[\"lr\"], \"k--\", lw=1)\n",
    "# ax_2.set_yscale(\"log\")\n",
    "# ax.set_ylim(ax.get_ylim()[0], history[\"training_losses\"][0])\n",
    "ax.grid(axis=\"x\")\n",
    "fig.tight_layout()\n",
    "fig.show()\n",
    "fig.savefig(f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/graphs3/aa-loss_lr_{lr}_weighted_balanced-emb.png')\n",
    "print(f'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/graphs3/aa-loss_lr_{lr}_weighted_balanced.png-emb')\n",
    "\n",
    "#%%\n",
    "testing_dataset = Dataset(test_data, test_target, one_hot_dtype=torch.float, transform=False)\n",
    "testing_loader1 = DataLoader(dataset=testing_dataset, batch_size=1, collate_fn=collate_padded_batch, num_workers=1, shuffle=True, drop_last=True)\n",
    "\n",
    "model.eval()  # For inference\n",
    "\n",
    "ic.disable()\n",
    "model.eval()\n",
    "pred_list = []\n",
    "target_list  = []\n",
    "mse_list = []\n",
    "with torch.no_grad():\n",
    "    for x_test, y_test in testing_loader1:\n",
    "        xtest1 = x_test.to(device).float()\n",
    "        ytest1 = y_test.to(device).float()\n",
    "        pred = model(xtest1)\n",
    "        pred_list.append(np.argmax(pred.detach().cpu().numpy())) \n",
    "        target_list.append(y_test.detach().cpu().numpy())\n",
    "target_list = np.array(target_list).flatten()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, mean_absolute_error\n",
    "\n",
    "def calculate_metrics(true_labels, predictions):\n",
    "    \"\"\"\n",
    "    Calculates accuracy, F1 score, confusion matrix, and MAE for the given true and predicted labels.\n",
    "\n",
    "    Parameters:\n",
    "    - true_labels: List or array of true labels\n",
    "    - predictions: List or array of predicted labels\n",
    "\n",
    "    Returns:\n",
    "    - accuracy: Overall accuracy of predictions\n",
    "    - f1: Weighted average F1 score\n",
    "    - conf_matrix: Multiclass confusion matrix\n",
    "    - mae: Mean Absolute Error of predictions\n",
    "    \"\"\"\n",
    "    # Ensure inputs are numpy arrays for consistency\n",
    "    true_labels = np.array(true_labels)\n",
    "    predictions = np.array(predictions)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "\n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "    # Calculate MAE\n",
    "    mae = mean_absolute_error(true_labels, predictions)\n",
    "\n",
    "    return accuracy, f1, conf_matrix, mae\n",
    "\n",
    "# Example usage\n",
    "# true_labels = [0, 1, 2, 1, 0, 2, 1, 0]\n",
    "# predictions = [0, 2, 2, 1, 0, 0, 1, 0]\n",
    "\n",
    "accuracy, f1, conf_matrix, mae = calculate_metrics(target_list, pred_list)\n",
    "\n",
    "print(\"======================\")\n",
    "# print(\"Model's Named Parameters:\")\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(f\"Name: {name}\")\n",
    "#     print(f\"Shape: {param.size()}\")\n",
    "#     print(f\"Requires grad: {param.requires_grad}\")\n",
    "#     print('-----')\n",
    "print(\"Optimizer details:\")\n",
    "print(optimizer)\n",
    "for param_group in optimizer.param_groups:\n",
    "    print(\"Learning rate:\", param_group['lr'])\n",
    "    print(\"Weight decay:\", param_group.get('weight_decay', 'Not set'))\n",
    "    \n",
    "print(\"======================\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Mae: {mae}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"conf_matrix: {conf_matrix}\")\n",
    "print(\"======================\")\n",
    "doubling_dilution_accuracy = np.mean([is_within_doubling_dilution(pred, true, target_min, target_max) for pred, true in zip(pred_list, target_list)])\n",
    "print(\"Doubling Dilution Accuracy:\", doubling_dilution_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_corn(logits, y_train, num_classes):\n",
    "    sets = []\n",
    "    for i in range(num_classes-1):\n",
    "        label_mask = y_train > i-1\n",
    "        label_tensor = (y_train[label_mask] > i).to(torch.int64)\n",
    "        sets.append((label_mask, label_tensor))\n",
    "\n",
    "    num_examples = 0\n",
    "    losses = 0.\n",
    "    for task_index, s in enumerate(sets):\n",
    "        train_examples = s[0]\n",
    "        train_labels = s[1]\n",
    "\n",
    "        if len(train_labels) < 1:\n",
    "            continue\n",
    "\n",
    "        num_examples += len(train_labels)\n",
    "        pred = logits[train_examples, task_index]\n",
    "\n",
    "        loss = -torch.sum(F.logsigmoid(pred)*train_labels\n",
    "                          + (F.logsigmoid(pred) - pred)*(1-train_labels)\n",
    "                          )\n",
    "        losses += loss\n",
    "    return losses/num_examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred  = torch.tensor([[0.0000, 0.5111],\n",
    "        [0.1329, 1.1051]], device='cuda:0')\n",
    "target = torch.tensor([0, 0], device='cuda:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7275, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "out = loss_corn(pred, target, 3)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost with snps and fed in res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# def is_within_doubling_dilution(pred, target, target_min, target_max):\n",
    "#     # Ensure target_min and target_max are scalars\n",
    "#     target_min = target_min.item() if isinstance(target_min, np.ndarray) or isinstance(target_min, pd.Series) else target_min\n",
    "#     target_max = target_max.item() if isinstance(target_max, np.ndarray) or isinstance(target_max, pd.Series) else target_max\n",
    "\n",
    "#     # Create a range based on the scalar values of target_min and target_max\n",
    "#     dilution_range = np.arange(target_min - 1, target_max + 2, 1)\n",
    "    \n",
    "#     # Find the index of the target value\n",
    "#     index = np.where(dilution_range == target)[0][0]  # Use np.where to find the index\n",
    "    \n",
    "#     # Check if prediction is within the acceptable range\n",
    "#     return dilution_range[index - 1] <= pred <= dilution_range[index + 1]\n",
    "\n",
    "# Example usage\n",
    "target_min, target_max = cryptic_drs.min().values, cryptic_drs.max()\n",
    "\n",
    "# Load the data\n",
    "cryptic_drs = np.load('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/individual_models/1473_sample_drs_cryptic_emb.npy')\n",
    "cryptic_snps = np.load('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/individual_models/1473_snps_cryptic_emb.npy')\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "cryptic_drs = pd.DataFrame(cryptic_drs)\n",
    "\n",
    "# Combine the features and target variable\n",
    "data = cryptic_snps\n",
    "target = cryptic_drs\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the XGBoost model\n",
    "model = xgb.XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "target_min, target_max = cryptic_drs.min().values, cryptic_drs.max().values\n",
    "\n",
    "doubling_dilution_accuracy = np.mean([is_within_doubling_dilution(pred, true, target_min, target_max) for pred, true in zip(y_pred, y_test)])\n",
    "print(f\"Doubling Dilution Accuracy: {doubling_dilution_accuracy * 100:.2f}%\")\n",
    "\n",
    "#testing\n",
    "cutoff = 4\n",
    "test_target_bi = (np.squeeze(np.array(y_test)) >= cutoff).astype(int) #(target_mic_list  >= cutoff).astype(int)\n",
    "test_predictions_bi = (np.squeeze(np.array(y_pred)) >= cutoff).astype(int)  #(np.array(pred_mic_list) >= cutoff).astype(int)\n",
    "\n",
    "auc = roc_auc_score(test_target_bi, test_predictions_bi)\n",
    "print(\"AUC:\", auc)\n",
    "\n",
    "# Calculate confusion matrix components\n",
    "tn, fp, fn, tp = confusion_matrix(test_target_bi, test_predictions_bi).ravel()\n",
    "\n",
    "# Calculate sensitivity (recall)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "\n",
    "# Calculate specificity\n",
    "specificity = tn / (tn + fp)\n",
    "print(\"Specificity:\", specificity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
