{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/nn_model_script_emb_test.py - starting\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fd488169950>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%\n",
    "print('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/nn_model_script_emb_test.py - starting')\n",
    "\n",
    "from array import array\n",
    "from cmath import nan\n",
    "from pyexpat import model\n",
    "import statistics\n",
    "from tkinter.ttk import Separator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch    \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchviz import make_dot\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import variable\n",
    "from itertools import chain\n",
    "from sklearn import metrics as met\n",
    "import pickle\n",
    "from icecream import ic\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from importlib import reload\n",
    "# import util\n",
    "# import model_torch_simple\n",
    "# from torchmetrics import Accuracy\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from icecream import ic\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#%%\n",
    "seed = 42\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(seed)\n",
    "# torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# train_data = np.loadtxt('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_emb/aa_data_train_gene.csv', delimiter = ',')\n",
    "# train_target = pd.read_csv('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_emb/mic_aa_train_hml.csv')\n",
    "# train_target = train_target[['EMB_MIC']]\n",
    "# # don't touch test data, split out validation data from training data during training\n",
    "# # test_data = np.loadtxt('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_EMB/aa_data_test_pca4k.csv', delimiter = ',')\n",
    "# test_data = np.loadtxt('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_emb/aa_data_test_gene.csv', delimiter = ',')\n",
    "# test_target = pd.read_csv('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_emb/mic_aa_test_hml.csv')\n",
    "# test_target = test_target[['EMB_MIC']]\n",
    "\n",
    "# all_data = np.concatenate((train_data, test_data), axis=0)\n",
    "# all_target = pd.concat((train_target, test_target), axis=0)\n",
    "\n",
    "# train_data, test_data, train_target, test_target = train_test_split(all_data, all_target, test_size=0.2, random_state=42, stratify=all_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(cryptic, gene_list):\n",
    "    # overlap = set(variants['sample_id']).intersection(set(cryptic['ENA_RUN'].to_list()))\n",
    "    # variants = variants[variants['drugs'].isin(['ethambutol'])]\n",
    "    # variants = variants[variants['sample_id'].isin(overlap)]\n",
    "    # variants['SNP'] = variants['gene'] + '-'+ variants['change']\n",
    "\n",
    "    variants = pd.read_csv('../variants_full.csv')\n",
    "    variants = variants[variants['gene'] != 'PPE35']\n",
    "    variants = variants[variants['type'] != 'synonymous_variant']\n",
    "    overlap = set(variants['sample_id']).intersection(set(cryptic['ENA_RUN'].to_list()))\n",
    "    # variants = variants[variants['drugs'].isin(['ethambutol'])]\n",
    "    variants = variants[variants['gene'].isin(gene_list)]\n",
    "    variants = variants[variants['sample_id'].isin(overlap)]\n",
    "    variants['SNP'] = variants['gene'] + '-'+ variants['change']\n",
    "\n",
    "    def compare_snp_lists_with_values_optimized(set_list, query_list, values_list):\n",
    "        # Create a dictionary from query_list and values_list for direct mapping\n",
    "        query_dict = dict(zip(query_list, values_list))\n",
    "        \n",
    "        # Use list comprehension to build the output list directly\n",
    "        output_list = [query_dict.get(snp, 0) for snp in set_list]\n",
    "        \n",
    "        return output_list\n",
    "\n",
    "    # Example usage\n",
    "    # set_list = ['SNP1', 'SNP2', 'SNP3', 'SNP4']\n",
    "    # query_list = ['SNP2', 'SNP4']\n",
    "    # values_list = [5, 10]  # Corresponding values for 'SNP2' and 'SNP4'\n",
    "    # output_list = compare_snp_lists_with_values_optimized(set_list, query_list, values_list)\n",
    "    # print(output_list)  # Expected output: [0, 5, 0, 10]# Getting all snp data\n",
    "\n",
    "    aa = []\n",
    "    all_snp = variants['SNP'].unique() # here is a list of all snps values title for the row in the final table \n",
    "    for x in tqdm(variants['sample_id'].unique()):\n",
    "        aa.append(compare_snp_lists_with_values_optimized(all_snp, variants[variants['sample_id']==x]['SNP'].to_list(), variants[variants['sample_id']==x]['freq'].to_list()))\n",
    "        # print('SNP')\n",
    "        \n",
    "    aa_array = np.array(aa)\n",
    "    aa_array[aa_array < 0.8] = 0\n",
    "    aa_array[aa_array >= 0.8] = 1\n",
    "\n",
    "    mic_aa = cryptic[cryptic['ENA_RUN'].isin(variants['sample_id'].unique())]#.iloc[:,14:27]\n",
    "    # mic_aa['wgs_id'] = pd.Categorical(mic_aa['ENA_RUN'], categories=variants['sample_id'].unique().tolist(), ordered=True)\n",
    "    # mic_aa = mic_aa.sort_values('ENA_RUN')\n",
    "    mic_aa.ENA_RUN = mic_aa.ENA_RUN.astype('category')\n",
    "    mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(variants['sample_id'].unique().tolist())\n",
    "    mic_aa = mic_aa.sort_values([\"ENA_RUN\"])  ## 'sort' changed to 'sort_values'\n",
    "\n",
    "    return aa_array, mic_aa\n",
    "\n",
    "def data_split(aa_array, encoded_mic):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Perform stratified train-test split\n",
    "    train_data, test_data, train_target, test_target = train_test_split(\n",
    "        aa_array,\n",
    "        encoded_mic,\n",
    "        test_size=0.1,  # 10% for testing\n",
    "        stratify=encoded_mic,  # Ensures the proportion of each class is preserved\n",
    "        random_state=42  # For reproducibility\n",
    "    )\n",
    "    return train_data, test_data, train_target, test_target\n",
    "\n",
    "def is_within_doubling_dilution(pred, target, target_min, target_max):\n",
    "    _ = np.arange(target_min-1, target_max+2, 1)\n",
    "    index = [i for i, x in enumerate(_) if x == target][0]\n",
    "    return (_[index-1] <= pred <= _[index+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep_(cryptic, gene_list):\n",
    "    # overlap = set(variants['sample_id']).intersection(set(cryptic['ENA_RUN'].to_list()))\n",
    "    # variants = variants[variants['drugs'].isin(['ethambutol'])]\n",
    "    # variants = variants[variants['sample_id'].isin(overlap)]\n",
    "    # variants['SNP'] = variants['gene'] + '-'+ variants['change']\n",
    "    \n",
    "    variants = pd.read_csv('../variants_full.csv')\n",
    "    variants = variants[variants['gene'] != 'PPE35']\n",
    "    variants = variants[variants['type'] != 'synonymous_variant']\n",
    "    variants = variants[variants['type'] != 'non_coding_transcript_exon_variant']\n",
    "\n",
    "    overlap = set(variants['sample_id']).intersection(set(cryptic['ENA_RUN'].to_list()))\n",
    "    # variants = variants[variants['drugs'].isin(['ethambutol'])]\n",
    "    variants = variants[variants['gene'].isin(gene_list)]\n",
    "    variants = variants[variants['sample_id'].isin(overlap)]\n",
    "    variants['SNP'] = variants['gene'] + '-'+ variants['change']\n",
    "    # print(variants.shape)\n",
    "    # print(variants['sample_id'].unique().shape)\n",
    "\n",
    "    def compare_snp_lists_with_values_optimized(set_list, query_list, values_list):\n",
    "        # Create a dictionary from query_list and values_list for direct mapping\n",
    "        query_dict = dict(zip(query_list, values_list))\n",
    "        \n",
    "        # Use list comprehension to build the output list directly\n",
    "        output_list = [query_dict.get(snp, 0) for snp in set_list]\n",
    "        \n",
    "        return output_list\n",
    "\n",
    "    # Example usage\n",
    "    # set_list = ['SNP1', 'SNP2', 'SNP3', 'SNP4']\n",
    "    # query_list = ['SNP2', 'SNP4']\n",
    "    # values_list = [5, 10]  # Corresponding values for 'SNP2' and 'SNP4'\n",
    "    # output_list = compare_snp_lists_with_values_optimized(set_list, query_list, values_list)\n",
    "    # print(output_list)  # Expected output: [0, 5, 0, 10]# Getting all snp data\n",
    "\n",
    "    aa = []\n",
    "    all_snp = variants['SNP'].unique() # here is a list of all snps values title for the row in the final table \n",
    "    for x in tqdm(overlap):\n",
    "    # for x in tqdm(variants['sample_id'].unique()):\n",
    "        if x in variants['sample_id'].tolist():\n",
    "            aa.append(compare_snp_lists_with_values_optimized(all_snp, variants[variants['sample_id']==x]['SNP'].to_list(), variants[variants['sample_id']==x]['freq'].to_list()))\n",
    "        else:\n",
    "            aa.append([0]*len(all_snp))\n",
    "            \n",
    "        # print('SNP')\n",
    "        \n",
    "    aa_array = np.array(aa)\n",
    "    aa_array[aa_array < 0.8] = 0\n",
    "    aa_array[aa_array >= 0.8] = 1\n",
    "\n",
    "    mic_aa = cryptic[cryptic['ENA_RUN'].isin(overlap)]#.iloc[:,14:27]\n",
    "    # mic_aa = cryptic[cryptic['ENA_RUN'].isin(variants['sample_id'].unique())]#.iloc[:,14:27]\n",
    "    # print(mic_aa.shape)\n",
    "    # mic_aa['wgs_id'] = pd.Categorical(mic_aa['ENA_RUN'], categories=variants['sample_id'].unique().tolist(), ordered=True)\n",
    "    # mic_aa = mic_aa.sort_values('ENA_RUN')\n",
    "    mic_aa.ENA_RUN = mic_aa.ENA_RUN.astype('category')\n",
    "    mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(overlap)\n",
    "    # mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(variants['sample_id'].unique().tolist())\n",
    "    mic_aa = mic_aa.sort_values([\"ENA_RUN\"])  ## 'sort' changed to 'sort_values'\n",
    "    # print(mic_aa.shape)\n",
    "\n",
    "    return aa_array, mic_aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_58524/693333269.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb.loc[i, f'{x}'] = '16'\n",
      "/tmp/ipykernel_58524/693333269.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emb['EMB_MIC'] = df_emb['EMB_MIC'].astype('float')\n",
      "100%|██████████| 11362/11362 [01:04<00:00, 175.33it/s]\n",
      "/tmp/ipykernel_58524/619452980.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.astype('category')\n",
      "/tmp/ipykernel_58524/619452980.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mic_aa.ENA_RUN = mic_aa.ENA_RUN.cat.set_categories(overlap)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('../CRyPTIC_reuse_table_20231208.csv')\n",
    "gene_list = ['embB', 'embA', 'embC']\n",
    "df_emb = df[df['EMB_MIC'].isin(['>8','8.0', '4.0', '2.0', '1.0', '0.5'])]\n",
    "# df_emb = df_emb[~df_emb['ENA_RUN'].isin(to_be_dropped)]\n",
    "for i, row in df_emb.iterrows():\n",
    "    x = 'EMB_MIC'\n",
    "    if row[x] == '>8' :\n",
    "        df_emb.loc[i, f'{x}'] = '16'\n",
    "    elif row[x] == '<=0.25':\n",
    "        df_emb.loc[i, f'{x}'] = '0.125'\n",
    "        \n",
    "df_emb['EMB_MIC'] = df_emb['EMB_MIC'].astype('float') \n",
    "# df_emb = df_emb[~df_emb['ENA_RUN'].isin(to_be_dropped)]\n",
    "\n",
    "# variants = pd.read_csv('variants_full.csv')\n",
    "# variants = variants[variants['type'] != 'synonymous_variant']\n",
    "# df_emb = df_emb[~df_emb['EMB_PHENOTYPE_QUALITY'].isin(['LOW','MEDIUM'])]  # remove low and med quality\n",
    "# df_emb = df_emb[~df_emb['EMB_PHENOTYPE_QUALITY'].isin(['MEDIUM'])]  # remove low and med quality\n",
    "# df_emb = df_emb[df_emb['ENA_RUN'].isin(samples)]\n",
    "cryptic = df_emb\n",
    "aa_array, mic_aa = data_prep_(cryptic, gene_list)\n",
    "# encoded_mic = np.array([0 if value < 4 else 1 for value in mic_aa['EMB_MIC'].to_list()])\n",
    "\n",
    "encoded_mic = mic_aa['EMB_MIC'].to_list()\n",
    "\n",
    "# train_data, test_data, train_target, test_target = data_split(aa_array, encoded_mic)\n",
    "\n",
    "mic_series = np.log2(mic_aa['EMB_MIC'])\n",
    "mic_series += 1\n",
    "sample_ids = mic_aa['ENA_RUN']\n",
    "\n",
    "mic_series_bi = mic_aa['EMB_MIC'].apply(lambda x: 1 if x >= 8 else 0)\n",
    "mic_series_sir = mic_aa['EMB_MIC'].apply(lambda x: 2 if x >= 8 else (0 if x <= 2 else 1))\n",
    "mic_series_all = pd.merge(mic_series, mic_series_bi,left_index=True, right_index=True)\n",
    "mic_series_all = pd.merge(mic_series_all, mic_series_sir,left_index=True, right_index=True)\n",
    "train_data, test_data, train_target, test_target = data_split(aa_array, mic_series_all)\n",
    "target_min, target_max = mic_series.min(), mic_series.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1.0: 3571, 2.0: 2661, 3.0: 2000, 4.0: 2000, 0.0: 2000, 5.0: 2000})\n",
      "(14232,)\n",
      "(14232, 1710)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Assuming train_data is your feature array and train_target['EMB_MIC_x'] is your target array\n",
    "X = train_data\n",
    "y = train_target['EMB_MIC_x']\n",
    "\n",
    "target_counts = {\n",
    "    1.0: 3571,  # Keep the majority class as is\n",
    "    2.0: 2661,  # Bring other classes closer\n",
    "    3.0: 2000,\n",
    "    4.0: 2000,\n",
    "    0.0: 2000,\n",
    "    5.0: 2000\n",
    "}\n",
    "# Initialize the RandomOverSampler\n",
    "ros= RandomOverSampler(sampling_strategy=target_counts, random_state=42)\n",
    "# ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Fit and resample the data\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# Verify the new class distribution\n",
    "from collections import Counter\n",
    "print(Counter(y_resampled))\n",
    "print(y_resampled.shape)\n",
    "print(X_resampled.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic_series_bi = mic_aa['EMB_MIC'].apply(lambda x: 1 if x >= 8 else 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### no res feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.47845206684256814\n",
      "Doubling Dilution Accuracy: 92.44%\n",
      "AUC: 0.7922294394611128\n",
      "Sensitivity: 0.6557377049180327\n",
      "Specificity: 0.9287211740041929\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, accuracy_score\n",
    "\n",
    "# train_data = np.column_stack((train_data, train_target['EMB_MIC_y'].values))\n",
    "# test_data = np.column_stack((test_data, test_target['EMB_MIC_y'].values))\n",
    "train_target_x = train_target['EMB_MIC_x'].values\n",
    "test_target_x = test_target['EMB_MIC_x'].values\n",
    "\n",
    "def is_within_doubling_dilution(pred, target, target_min, target_max):\n",
    "    _ = np.arange(target_min-1, target_max+2, 1)\n",
    "    index = [i for i, x in enumerate(_) if x == target][0]\n",
    "    return (_[index-1] <= pred <= _[index+1])\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_data, test_data, train_target_x, test_target_x\n",
    "\n",
    "# Create the XGBoost model\n",
    "model = xgb.XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "target_min, target_max = y_train.min(), y_train.max()\n",
    "\n",
    "doubling_dilution_accuracy = np.mean([is_within_doubling_dilution(pred, true, target_min, target_max) for pred, true in zip(y_pred, y_test)])\n",
    "print(f\"Doubling Dilution Accuracy: {doubling_dilution_accuracy * 100:.2f}%\")\n",
    "\n",
    "#testing\n",
    "cutoff = 4\n",
    "test_target_bi = (np.squeeze(np.array(y_test)) >= cutoff).astype(int) #(target_mic_list  >= cutoff).astype(int)\n",
    "test_predictions_bi = (np.squeeze(np.array(y_pred)) >= cutoff).astype(int)  #(np.array(pred_mic_list) >= cutoff).astype(int)\n",
    "\n",
    "auc = roc_auc_score(test_target_bi, test_predictions_bi)\n",
    "print(\"AUC:\", auc)\n",
    "\n",
    "# Calculate confusion matrix components\n",
    "tn, fp, fn, tp = confusion_matrix(test_target_bi, test_predictions_bi).ravel()\n",
    "\n",
    "# Calculate sensitivity (recall)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "\n",
    "# Calculate specificity\n",
    "specificity = tn / (tn + fp)\n",
    "print(\"Specificity:\", specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 1.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "1 0\n",
      "2 5.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "1 0\n",
      "3 5.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "dr pred problem\n",
      "1 0\n",
      "1 5.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "1 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "1 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "1 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 1.0\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 1.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 2.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "1 0\n",
      "3 5.0\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 2.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 1.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 1\n",
      "5 1.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 2.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 2.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "1 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 2.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 0.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 2.0\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "1 4.0\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "1 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 2.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 0.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "1 0\n",
      "1 5.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "1 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 1.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "1 0\n",
      "1 5.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "1 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "1 4.0\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "1 0\n",
      "3 5.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 0.0\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 1.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 1.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 0.0\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 2.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 2.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 1\n",
      "5 3.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "1 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 0.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "3 4.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "dr pred problem\n",
      "0 0\n",
      "4 3.0\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n",
      "=========\n"
     ]
    }
   ],
   "source": [
    "for x, y in zip(X_test, y_test):\n",
    "    print('=========')\n",
    "    y_pred = model.predict([x])\n",
    "    if is_within_doubling_dilution(y_pred, y, target_min, target_max):\n",
    "        pass\n",
    "    else:\n",
    "        pass\n",
    "        # print('not within doubling dilution')\n",
    "        # print(y_pred[0], y)\n",
    "    if int(y>=4) != int(y_pred[0]>=4):\n",
    "        print('dr pred problem')\n",
    "        print(int(y>4), int(y_pred[0]>4))\n",
    "        print(y_pred[0], y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "di_error mic_error\n",
      "0 0\n"
     ]
    }
   ],
   "source": [
    "di_error = 0\n",
    "mic_error = 0\n",
    "for y_p, y in zip(y_pred, y_test):\n",
    "    # print('=========')\n",
    "    if is_within_doubling_dilution(y_p, y, target_min, target_max):\n",
    "        pass\n",
    "    else:\n",
    "        mic_error += 1\n",
    "        # print('not within doubling dilution')\n",
    "        # print(y_p[0], y)\n",
    "    if int(y>=4) != int(y_p>=4):\n",
    "        # print('dr pred problem')\n",
    "        # print(int(y>4), int(y_p>4))\n",
    "        # print(y_p, y)\n",
    "        if int(y>=4) != int(y_p>=4):\n",
    "            di_error += 1\n",
    "print('di_error', 'mic_error')\n",
    "print(di_error, mic_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bi dr pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8927000879507476\n",
      "AUC: 0.8079870777056054\n",
      "Sensitivity: 0.6830601092896175\n",
      "Specificity: 0.9329140461215933\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, accuracy_score\n",
    "\n",
    "# train_data = np.column_stack((train_data, train_target['EMB_MIC_y'].values))\n",
    "# test_data = np.column_stack((test_data, test_target['EMB_MIC_y'].values))\n",
    "train_target_y = train_target['EMB_MIC_y'].values\n",
    "test_target_y = test_target['EMB_MIC_y'].values\n",
    "\n",
    "def is_within_doubling_dilution(pred, target, target_min, target_max):\n",
    "    _ = np.arange(target_min-1, target_max+2, 1)\n",
    "    index = [i for i, x in enumerate(_) if x == target][0]\n",
    "    return (_[index-1] <= pred <= _[index+1])\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_data, test_data, train_target_y, test_target_y\n",
    "\n",
    "# Create the XGBoost model\n",
    "model_bi = xgb.XGBClassifier()\n",
    "model_bi.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model_bi.predict(X_test)\n",
    "\n",
    "# Evaluate the model_bi\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "#testing\n",
    "cutoff = 4\n",
    "test_target_bi = y_test.astype(int) #(target_mic_list  >= cutoff).astype(int)\n",
    "test_predictions_bi = y_pred.astype(int)  #(np.array(pred_mic_list) >= cutoff).astype(int)\n",
    "\n",
    "auc = roc_auc_score(test_target_bi, test_predictions_bi)\n",
    "print(\"AUC:\", auc)\n",
    "\n",
    "# Calculate confusion matrix components\n",
    "tn, fp, fn, tp = confusion_matrix(test_target_bi, test_predictions_bi).ravel()\n",
    "\n",
    "# Calculate sensitivity (recall)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "\n",
    "# Calculate specificity\n",
    "specificity = tn / (tn + fp)\n",
    "print(\"Specificity:\", specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIR pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8337730870712401\n",
      "Sensitivity: 0.7049180327868853\n",
      "Specificity: 0.9308176100628931\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "# train_data = np.column_stack((train_data, train_target['EMB_MIC_y'].values))\n",
    "# test_data = np.column_stack((test_data, test_target['EMB_MIC_y'].values))\n",
    "train_target_z = train_target['EMB_MIC'].values\n",
    "test_target_z = test_target['EMB_MIC'].values\n",
    "\n",
    "def is_within_doubling_dilution(pred, target, target_min, target_max):\n",
    "    _ = np.arange(target_min-1, target_max+2, 1)\n",
    "    index = [i for i, x in enumerate(_) if x == target][0]\n",
    "    return (_[index-1] <= pred <= _[index+1])\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_data, test_data, train_target_z, test_target_z\n",
    "\n",
    "# Create the XGBoost model\n",
    "model_sir = xgb.XGBClassifier()\n",
    "model_sir.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model_sir.predict(X_test)\n",
    "\n",
    "# Evaluate the model_sir\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "#testing\n",
    "# cutoff = 4\n",
    "# test_target_sir = y_test.astype(int) #(target_mic_list  >= cutoff).astype(int)\n",
    "# test_predictions_sir = y_pred.astype(int)  #(np.array(pred_mic_list) >= cutoff).astype(int)\n",
    "\n",
    "cutoff = 2\n",
    "test_target_sir = (np.squeeze(np.array(y_test)) >= cutoff).astype(int) #(target_mic_list  >= cutoff).astype(int)\n",
    "test_predictions_sir = (np.squeeze(np.array(y_pred)) >= cutoff).astype(int)  #(np.array(pred_mic_list) >= cutoff).astype(int)\n",
    "\n",
    "# auc = roc_auc_score(test_target_sir, test_predictions_sir)\n",
    "# print(\"AUC:\", auc)\n",
    "\n",
    "# Calculate confusion matrix components\n",
    "tn, fp, fn, tp = confusion_matrix(test_target_sir, test_predictions_sir).ravel()\n",
    "\n",
    "# Calculate sensitivity (recall)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "\n",
    "# Calculate specificity\n",
    "specificity = tn / (tn + fp)\n",
    "print(\"Specificity:\", specificity)\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    # Annotate the confusion matrix with the values\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, f'{cm[i, j]}', horizontalalignment='center', color='black')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "\n",
    "# Get the unique labels from y_true for the class labels\n",
    "class_names = unique_labels(y_test, y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plot_confusion_matrix(conf_matrix, classes=class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### corrective ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### no res feed + bi dr pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_data, test_data, train_target_x, test_target_x\n",
    "\n",
    "pred_list = []\n",
    "true_list = []\n",
    "for x, y in zip(X_test, y_test):\n",
    "    y_pred = model.predict([x])[0]\n",
    "    y_pred_bi = model_bi.predict([x])[0]\n",
    "    if y_pred == 4 and y_pred_bi == 0:\n",
    "        y_pred = 3\n",
    "    elif y_pred == 3 and y_pred_bi == 1:\n",
    "        y_pred =4\n",
    "    pred_list.append(y_pred)\n",
    "    true_list.append(y)\n",
    "    # print('=========')\n",
    "    # y_pred = model.predict([x])\n",
    "    # if is_within_doubling_dilution(y_pred, y, target_min, target_max):\n",
    "    #     pass\n",
    "    # else:\n",
    "    #     print('not within doubling dilution')\n",
    "    #     print(y_pred[0], y)\n",
    "    # if int(y>4) != int(y_pred[0]>4):\n",
    "    #     print('dr pred problem')\n",
    "    #     print(int(y>4), int(y_pred[0]>4))\n",
    "    #     print(y_pred[0], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pred_list\n",
    "y_test = true_list\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "target_min, target_max = y_train.min(), y_train.max()\n",
    "\n",
    "doubling_dilution_accuracy = np.mean([is_within_doubling_dilution(pred, true, target_min, target_max) for pred, true in zip(y_pred, y_test)])\n",
    "print(f\"Doubling Dilution Accuracy: {doubling_dilution_accuracy * 100:.2f}%\")\n",
    "\n",
    "#testing\n",
    "cutoff = 4\n",
    "test_target_bi = (np.squeeze(np.array(y_test)) >= cutoff).astype(int) #(target_mic_list  >= cutoff).astype(int)\n",
    "test_predictions_bi = (np.squeeze(np.array(y_pred)) >= cutoff).astype(int)  #(np.array(pred_mic_list) >= cutoff).astype(int)\n",
    "\n",
    "auc = roc_auc_score(test_target_bi, test_predictions_bi)\n",
    "print(\"AUC:\", auc)\n",
    "\n",
    "# Calculate confusion matrix components\n",
    "tn, fp, fn, tp = confusion_matrix(test_target_bi, test_predictions_bi).ravel()\n",
    "\n",
    "# Calculate sensitivity (recall)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "\n",
    "# Calculate specificity\n",
    "specificity = tn / (tn + fp)\n",
    "print(\"Specificity:\", specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di_error = 0\n",
    "mic_error = 0\n",
    "for y_pred, y in zip(pred_list, true_list):\n",
    "    # print('=========')\n",
    "    if is_within_doubling_dilution(y_pred, y, target_min, target_max):\n",
    "        pass\n",
    "    else:\n",
    "        mic_error += 1\n",
    "\n",
    "        # print('not within doubling dilution')\n",
    "        # print(y_pred[0], y)\n",
    "    if int(y>=4) != int(y_pred>=4):\n",
    "        print(int(y>=4) == int(y_pred>=4))\n",
    "        print('dr pred problem')\n",
    "        print(int(y>=4), int(y_pred>=4))\n",
    "        print(y_pred, y)\n",
    "        di_error += 1   \n",
    "            \n",
    "print('di_error', 'mic_error')\n",
    "print(di_error, mic_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "di_error mic_error\n",
      "123 84\n"
     ]
    }
   ],
   "source": [
    "di_error = 0\n",
    "mic_error = 0\n",
    "for y_pred, y in zip(pred_list, true_list):\n",
    "    # print('=========')\n",
    "    if is_within_doubling_dilution(y_pred, y, target_min, target_max):\n",
    "        pass\n",
    "    else:\n",
    "        mic_error += 1\n",
    "\n",
    "        # print('not within doubling dilution')\n",
    "        # print(y_pred[0], y)\n",
    "    if int(y>=4) != int(y_pred>=4):\n",
    "        # print(int(y>=4) == int(y_pred>=4))\n",
    "        # print('dr pred problem')\n",
    "        # print(int(y>=4), int(y_pred>=4))\n",
    "        # print(y_pred, y)\n",
    "        di_error += 1   \n",
    "            \n",
    "print('di_error', 'mic_error')\n",
    "print(di_error, mic_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### no res feed + bi dr pred + SIR pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic_series_sir = mic_aa['EMB_MIC'].apply(lambda x: 2 if x >= 8 else (0 if x <= 2 else 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true4pred3 = 0\n",
    "true3pred4 = 0\n",
    "for x, y in zip(X_test, y_test):\n",
    "    y_pred = model.predict([x])[0]\n",
    "    y_pred_bi = model_bi.predict([x])[0]\n",
    "    y_pred_sir = model_sir.predict([x])[0]\n",
    "    if y_pred != y:\n",
    "        if y_pred >= 4 and y_pred_bi == 0:\n",
    "            print('y_pred >= 4 and y_pred_bi == 0')\n",
    "            print(y_pred, y_pred_bi, y_pred_sir)\n",
    "            print(y)\n",
    "        elif y_pred <= 4 and y_pred_bi == 1:\n",
    "            print('y_pred <= 3 and y_pred_bi == 1')\n",
    "            print(y_pred, y_pred_bi, y_pred_sir)\n",
    "            print(y)\n",
    "    if y_pred == 4 and y == 3:\n",
    "        true4pred3 += 1\n",
    "    elif y_pred == 3 and y == 4:\n",
    "        true3pred4 += 1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_data, test_data, train_target_x, test_target_x\n",
    "\n",
    "pred_list = []\n",
    "true_list = []\n",
    "for x, y in zip(X_test, y_test):\n",
    "    y_pred = model.predict([x])[0]\n",
    "    y_pred_bi = model_bi.predict([x])[0]\n",
    "    y_pred_sir = model_sir.predict([x])[0]\n",
    "    \n",
    "    if y_pred_sir == 2 and y_pred == 3:\n",
    "        y_pred = 4\n",
    "    if y_pred_sir == 1 and y_pred == 4:\n",
    "        y_pred = 3\n",
    "        \n",
    "    if y_pred == 4 and y_pred_bi == 0:\n",
    "        y_pred = 3\n",
    "    elif y_pred == 3 and y_pred_bi == 1:\n",
    "        y_pred =4\n",
    "    pred_list.append(y_pred)\n",
    "    true_list.append(y)\n",
    "    # print('=========')\n",
    "    # y_pred = model.predict([x])\n",
    "    # if is_within_doubling_dilution(y_pred, y, target_min, target_max):\n",
    "    #     pass\n",
    "    # else:\n",
    "    #     print('not within doubling dilution')\n",
    "    #     print(y_pred[0], y)\n",
    "    # if int(y>4) != int(y_pred[0]>4):\n",
    "    #     print('dr pred problem')\n",
    "    #     print(int(y>4), int(y_pred[0]>4))\n",
    "    #     print(y_pred[0], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.48284960422163586\n",
      "Doubling Dilution Accuracy: 92.61%\n",
      "AUC: 0.8052548372684468\n",
      "Sensitivity: 0.6775956284153005\n",
      "Specificity: 0.9329140461215933\n"
     ]
    }
   ],
   "source": [
    "y_pred = pred_list\n",
    "y_test = true_list\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "target_min, target_max = y_train.min(), y_train.max()\n",
    "\n",
    "doubling_dilution_accuracy = np.mean([is_within_doubling_dilution(pred, true, target_min, target_max) for pred, true in zip(y_pred, y_test)])\n",
    "print(f\"Doubling Dilution Accuracy: {doubling_dilution_accuracy * 100:.2f}%\")\n",
    "\n",
    "#testing\n",
    "cutoff = 4\n",
    "test_target_bi = (np.squeeze(np.array(y_test)) >= cutoff).astype(int) #(target_mic_list  >= cutoff).astype(int)\n",
    "test_predictions_bi = (np.squeeze(np.array(y_pred)) >= cutoff).astype(int)  #(np.array(pred_mic_list) >= cutoff).astype(int)\n",
    "\n",
    "auc = roc_auc_score(test_target_bi, test_predictions_bi)\n",
    "print(\"AUC:\", auc)\n",
    "\n",
    "# Calculate confusion matrix components\n",
    "tn, fp, fn, tp = confusion_matrix(test_target_bi, test_predictions_bi).ravel()\n",
    "\n",
    "# Calculate sensitivity (recall)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "# Calculate specificity\n",
    "specificity = tn / (tn + fp)\n",
    "print(\"Specificity:\", specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with res feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.47845206684256814\n",
      "Doubling Dilution Accuracy: 92.44%\n",
      "AUC: 0.7922294394611128\n",
      "Sensitivity: 0.6557377049180327\n",
      "Specificity: 0.9287211740041929\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, accuracy_score\n",
    "\n",
    "train_target_x = train_target['EMB_MIC_x'].values\n",
    "test_target_x = test_target['EMB_MIC_x'].values\n",
    "\n",
    "def is_within_doubling_dilution(pred, target, target_min, target_max):\n",
    "    _ = np.arange(target_min-1, target_max+2, 1)\n",
    "    index = [i for i, x in enumerate(_) if x == target][0]\n",
    "    return (_[index-1] <= pred <= _[index+1])\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_data, test_data, train_target_x, test_target_x\n",
    "\n",
    "# Create the XGBoost model\n",
    "model = xgb.XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "target_min, target_max = y_train.min(), y_train.max()\n",
    "\n",
    "doubling_dilution_accuracy = np.mean([is_within_doubling_dilution(pred, true, target_min, target_max) for pred, true in zip(y_pred, y_test)])\n",
    "print(f\"Doubling Dilution Accuracy: {doubling_dilution_accuracy * 100:.2f}%\")\n",
    "\n",
    "#testing\n",
    "cutoff = 4\n",
    "test_target_bi = (np.squeeze(np.array(y_test)) >= cutoff).astype(int) #(target_mic_list  >= cutoff).astype(int)\n",
    "test_predictions_bi = (np.squeeze(np.array(y_pred)) >= cutoff).astype(int)  #(np.array(pred_mic_list) >= cutoff).astype(int)\n",
    "\n",
    "auc = roc_auc_score(test_target_bi, test_predictions_bi)\n",
    "print(\"AUC:\", auc)\n",
    "\n",
    "# Calculate confusion matrix components\n",
    "tn, fp, fn, tp = confusion_matrix(test_target_bi, test_predictions_bi).ravel()\n",
    "\n",
    "# Calculate sensitivity (recall)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "\n",
    "# Calculate specificity\n",
    "specificity = tn / (tn + fp)\n",
    "print(\"Specificity:\", specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with res feed + bi dr pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_data, test_data, train_target_x, test_target_x\n",
    "\n",
    "pred_list = []\n",
    "true_list = []\n",
    "for x, y in zip(X_test, y_test):\n",
    "    y_pred = model.predict([x])[0]\n",
    "    y_pred_bi = model_bi.predict([x])[0]\n",
    "    if y_pred == 4 and y_pred_bi == 0:\n",
    "        y_pred = 3\n",
    "    elif y_pred == 3 and y_pred_bi == 1:\n",
    "        y_pred =4\n",
    "    pred_list.append(y_pred)\n",
    "    true_list.append(y)\n",
    "    # print('=========')\n",
    "    # y_pred = model.predict([x])\n",
    "    # if is_within_doubling_dilution(y_pred, y, target_min, target_max):\n",
    "    #     pass\n",
    "    # else:\n",
    "    #     print('not within doubling dilution')\n",
    "    #     print(y_pred[0], y)\n",
    "    # if int(y>4) != int(y_pred[0]>4):\n",
    "    #     print('dr pred problem')\n",
    "    #     print(int(y>4), int(y_pred[0]>4))\n",
    "    #     print(y_pred[0], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5153913808267371\n",
      "Doubling Dilution Accuracy: 94.37%\n",
      "AUC: 0.8331786782142488\n",
      "Sensitivity: 0.7103825136612022\n",
      "Specificity: 0.9559748427672956\n"
     ]
    }
   ],
   "source": [
    "y_pred = pred_list\n",
    "y_test = true_list\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "target_min, target_max = y_train.min(), y_train.max()\n",
    "\n",
    "doubling_dilution_accuracy = np.mean([is_within_doubling_dilution(pred, true, target_min, target_max) for pred, true in zip(y_pred, y_test)])\n",
    "print(f\"Doubling Dilution Accuracy: {doubling_dilution_accuracy * 100:.2f}%\")\n",
    "\n",
    "#testing\n",
    "cutoff = 4\n",
    "test_target_bi = (np.squeeze(np.array(y_test)) >= cutoff).astype(int) #(target_mic_list  >= cutoff).astype(int)\n",
    "test_predictions_bi = (np.squeeze(np.array(y_pred)) >= cutoff).astype(int)  #(np.array(pred_mic_list) >= cutoff).astype(int)\n",
    "\n",
    "auc = roc_auc_score(test_target_bi, test_predictions_bi)\n",
    "print(\"AUC:\", auc)\n",
    "\n",
    "# Calculate confusion matrix components\n",
    "tn, fp, fn, tp = confusion_matrix(test_target_bi, test_predictions_bi).ravel()\n",
    "\n",
    "# Calculate sensitivity (recall)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "\n",
    "# Calculate specificity\n",
    "specificity = tn / (tn + fp)\n",
    "print(\"Specificity:\", specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1437 snps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Failed to interpret file '/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/individual_models/1473_snps_cryptic_emb.npy' as a pickle",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/mnt/storageG1/lwang/miniconda3/envs/ml-workshop/lib/python3.9/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_39791/3039731498.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Load the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mcryptic_drs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/individual_models/1473_sample_drs_cryptic_emb.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mcryptic_snps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/individual_models/1473_snps_cryptic_emb.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Example usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storageG1/lwang/miniconda3/envs/ml-workshop/lib/python3.9/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m                 raise IOError(\n\u001b[0m\u001b[1;32m    451\u001b[0m                     \"Failed to interpret file %s as a pickle\" % repr(file)) from e\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Failed to interpret file '/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/individual_models/1473_snps_cryptic_emb.npy' as a pickle"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# def is_within_doubling_dilution(pred, target, target_min, target_max):\n",
    "#     # Ensure target_min and target_max are scalars\n",
    "#     target_min = target_min.item() if isinstance(target_min, np.ndarray) or isinstance(target_min, pd.Series) else target_min\n",
    "#     target_max = target_max.item() if isinstance(target_max, np.ndarray) or isinstance(target_max, pd.Series) else target_max\n",
    "\n",
    "#     # Create a range based on the scalar values of target_min and target_max\n",
    "#     dilution_range = np.arange(target_min - 1, target_max + 2, 1)\n",
    "    \n",
    "#     # Find the index of the target value\n",
    "#     index = np.where(dilution_range == target)[0][0]  # Use np.where to find the index\n",
    "    \n",
    "#     # Check if prediction is within the acceptable range\n",
    "#     return dilution_range[index - 1] <= pred <= dilution_range[index + 1]\n",
    "\n",
    "\n",
    "\n",
    "# Load the data\n",
    "cryptic_drs = np.load('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/individual_models/1473_sample_drs_cryptic_emb.npy', allow_pickle=True)\n",
    "cryptic_snps = np.load('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/individual_models/1473_snps_cryptic_emb.npy', allow_pickle=True)\n",
    "\n",
    "# Example usage\n",
    "target_min, target_max = cryptic_drs.min().values, cryptic_drs.max().values\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "cryptic_drs = pd.DataFrame(cryptic_drs)\n",
    "\n",
    "# Combine the features and target variable\n",
    "data = cryptic_snps\n",
    "target = cryptic_drs\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the XGBoost model\n",
    "model = xgb.XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "target_min, target_max = cryptic_drs.min().values, cryptic_drs.max().values\n",
    "\n",
    "doubling_dilution_accuracy = np.mean([is_within_doubling_dilution(pred, true, target_min, target_max) for pred, true in zip(y_pred, y_test)])\n",
    "print(f\"Doubling Dilution Accuracy: {doubling_dilution_accuracy * 100:.2f}%\")\n",
    "\n",
    "#testing\n",
    "cutoff = 4\n",
    "test_target_bi = (np.squeeze(np.array(y_test)) >= cutoff).astype(int) #(target_mic_list  >= cutoff).astype(int)\n",
    "test_predictions_bi = (np.squeeze(np.array(y_pred)) >= cutoff).astype(int)  #(np.array(pred_mic_list) >= cutoff).astype(int)\n",
    "\n",
    "auc = roc_auc_score(test_target_bi, test_predictions_bi)\n",
    "print(\"AUC:\", auc)\n",
    "\n",
    "# Calculate confusion matrix components\n",
    "tn, fp, fn, tp = confusion_matrix(test_target_bi, test_predictions_bi).ravel()\n",
    "\n",
    "# Calculate sensitivity (recall)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "\n",
    "# Calculate specificity\n",
    "specificity = tn / (tn + fp)\n",
    "print(\"Specificity:\", specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_39791/553292189.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/individual_models/1473_snps_cryptic_emb.npy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data loaded successfully with pickle.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "file_path = '/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/individual_models/1473_snps_cryptic_emb.npy'\n",
    "with open(file_path, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "print(\"Data loaded successfully with pickle.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
